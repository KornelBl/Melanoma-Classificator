{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kopia notatnika Untitled",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "takW5YtZd2w4",
        "pycharm": {
          "is_executing": false
        },
        "outputId": "487cc81f-9b60-4d53-91c4-8226b3af3aa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os, re, time, json, math\n",
        "import datetime\n",
        "import PIL.Image, PIL.ImageFont, PIL.ImageDraw\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import google\n",
        "from matplotlib import pyplot as plt\n",
        "print(\"Tensorflow version \" + tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3wLMTBEUOw_",
        "pycharm": {
          "is_executing": false
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "from tf_records_generator import get_dataset, count_data_items\n",
        "from efficientNet_B0 import EffNet0, freeze_blocks\n",
        "from log_files import save_config, save_fold_iter_history, get_log_dir, save_logs_pickle, generate_columns\n",
        "from kfold import get_kfold_split, get_repeated_kfold_split\n",
        "from clr_schedule import CyclicLR\n",
        "from schedules import LR_test_schedule\n",
        "from callbacks import CustomStopper"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-tkqnadn5x2",
        "pycharm": {
          "is_executing": false
        }
      },
      "source": [
        "CONFIG = dict(\n",
        "    log_prefix = \"FINAL200_\",\n",
        "    effnet_version = 0,\n",
        "    input_shape=(256, 256, 3),\n",
        "    image_resolution=256,\n",
        "    trainable_base=False,\n",
        "    time=datetime.datetime.now().strftime(\"_%d_%m_%Y_%H_%M\"),\n",
        "    use_patient_data=True,\n",
        "    inner_blocks_frozen=4,\n",
        "\n",
        "    k_fold = 3,\n",
        "    kfold_repeats = 5,\n",
        "\n",
        "    patience = 16,\n",
        "    min_epochs = 32,\n",
        "\n",
        "    lr_min=0.000003,\n",
        "    lr_max=0.0001,\n",
        "    lr_decay=None,\n",
        "    clr_step_coefficient = 8,\n",
        "    \n",
        "    replicas=8,\n",
        "    steps_per_epoch=None,\n",
        "    validation_steps=None,\n",
        "    batch_size=32,\n",
        "    epochs=100,\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    \n",
        "    output_bias=np.log([584/32542]),\n",
        "    weight_for_0 = (1 / 32542)*(32542+584)/2.0,\n",
        "    weight_for_1 = (1 / 584)*(32542+584)/2.0\n",
        ")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ps8i099nqD0",
        "pycharm": {
          "is_executing": false
        }
      },
      "source": [
        "IS_COLAB_BACKEND = 'COLAB_GPU' in os.environ  # this is always set on Colab, the value is 0 or 1 depending on GPU presence\n",
        "if IS_COLAB_BACKEND:\n",
        "  from google.colab import auth\n",
        "  # Authenticates the Colab machine and also the TPU using your\n",
        "  # credentials so that they can access your private GCS buckets.\n",
        "  auth.authenticate_user()\n",
        "  data_dir = 'gs://dataset_files/'\n",
        "else:\n",
        "  data_dir = 'dataset/'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS5omUmCnxAs",
        "pycharm": {
          "is_executing": false
        },
        "outputId": "c9d333f1-a4c1-40a8-9506-4928596d7d7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Detect hardware\n",
        "try:\n",
        "  tpu_resolver = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
        "except ValueError:\n",
        "  tpu_resolver = None\n",
        "  gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
        "\n",
        "# Select appropriate distribution strategy\n",
        "if tpu_resolver:\n",
        "  tf.config.experimental_connect_to_cluster(tpu_resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu_resolver)\n",
        "  strategy = tf.distribute.TPUStrategy(tpu_resolver)\n",
        "  print('Running on TPU ', tpu_resolver.cluster_spec().as_dict()['worker'])\n",
        "elif len(gpus) > 1:\n",
        "  strategy = tf.distribute.MirroredStrategy([gpu.name for gpu in gpus])\n",
        "  print('Running on multiple GPUs ', [gpu.name for gpu in gpus])\n",
        "elif len(gpus) == 1:\n",
        "  strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "  print('Running on single GPU ', gpus[0].name)\n",
        "else:\n",
        "  strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "  print('Running on CPU')\n",
        "  \n",
        "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)\n",
        "CONFIG[\"replicas\"] = strategy.num_replicas_in_sync\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.28.151.34:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.28.151.34:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running on TPU  ['10.28.151.34:8470']\n",
            "Number of accelerators:  8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZm9JTxir68V",
        "pycharm": {
          "is_executing": false
        }
      },
      "source": [
        "path = data_dir + str(CONFIG[\"image_resolution\"])\n",
        "files_train = np.sort(np.array(tf.io.gfile.glob(path + '/train*.tfrec')))\n",
        "files_test = np.sort(np.array(tf.io.gfile.glob(path + '/test*.tfrec')))\n",
        "\n",
        "\n",
        "test_ds = get_dataset(files_test, CONFIG)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC-WNOmKUIuB",
        "pycharm": {
          "is_executing": false
        }
      },
      "source": [
        "def make_model(config:dict, strategy)    :\n",
        "    with strategy.scope():\n",
        "      model = EffNet0(config=config, trainable_base=config['trainable_base'])\n",
        "\n",
        "      model.compile(optimizer=keras.optimizers.Adam(), loss=config[\"loss\"], \n",
        "                    metrics=[\n",
        "                                  keras.metrics.TruePositives(name='tp'),\n",
        "                                  keras.metrics.FalsePositives(name='fp'),\n",
        "                                  keras.metrics.TrueNegatives(name='tn'),\n",
        "                                  keras.metrics.FalseNegatives(name='fn'), \n",
        "                                  keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "                                  keras.metrics.Precision(name='precision'),\n",
        "                                  keras.metrics.Recall(name='recall'),\n",
        "                                  keras.metrics.AUC(name='auc'),\n",
        "                            ]\n",
        "    )\n",
        "    return model\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": false
        },
        "id": "Y5E4-HaXAAmN",
        "outputId": "8cf309d3-552a-44d3-999c-85fa1db4bf11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#kfold_split = get_kfold_split(files_train,CONFIG['k_fold'])\n",
        "kfold_split = get_repeated_kfold_split(files_train,CONFIG['k_fold'], CONFIG['kfold_repeats'])\n",
        "save_config(CONFIG)\n",
        "logs = pd.DataFrame()\n",
        "log_dir = get_log_dir(CONFIG)\n",
        "for iter, files in kfold_split.items():\n",
        "    train_ds = get_dataset(files['train'],CONFIG, patient_info=True,repeat=True) \n",
        "    val_ds = get_dataset(files['validation'], CONFIG, patient_info=True,repeat=True)\n",
        "    if CONFIG['steps_per_epoch'] is None:\n",
        "        CONFIG['steps_per_epoch'] = math.ceil(count_data_items(files[\"train\"])/(CONFIG[\"batch_size\"]*CONFIG[\"replicas\"]))\n",
        "    if CONFIG['validation_steps'] is None:\n",
        "        CONFIG['validation_steps'] = math.ceil(count_data_items(files[\"validation\"])/(CONFIG[\"batch_size\"]*CONFIG[\"replicas\"]))\n",
        "\n",
        "    clr = CyclicLR(base_lr=CONFIG[\"lr_min\"], max_lr=CONFIG[\"lr_max\"],\n",
        "                                step_size=CONFIG['steps_per_epoch']*CONFIG['clr_step_coefficient'], mode='triangular')\n",
        "    stopper = CustomStopper(monitor='val_auc',patience=CONFIG['patience'],start_epoch=CONFIG['min_epochs'])\n",
        "\n",
        "    tb_callback = keras.callbacks.TensorBoard(log_dir=os.path.join(log_dir,f\"tb_{iter}\"))\n",
        "    model = make_model(CONFIG, strategy=strategy)\n",
        "    history = model.fit(train_ds,class_weight={0:CONFIG[\"weight_for_0\"],1:CONFIG[\"weight_for_1\"]},\n",
        "                        validation_data=val_ds,validation_batch_size=CONFIG[\"batch_size\"]*CONFIG[\"replicas\"],\n",
        "                        batch_size=CONFIG[\"batch_size\"]*CONFIG[\"replicas\"], epochs=CONFIG[\"epochs\"],\n",
        "                        steps_per_epoch=CONFIG['steps_per_epoch'],validation_steps=CONFIG['validation_steps'],\n",
        "                        callbacks=[clr,stopper])\n",
        "    \n",
        "    if logs.empty:\n",
        "        logs = generate_columns(logs,history.history)\n",
        "    logs = logs.append(history.history, ignore_index=True)\n",
        "    \n",
        "save_logs_pickle(logs,CONFIG)\n",
        "\n",
        "\n",
        "zip_name = os.path.basename(log_dir) + '.zip'\n",
        "!zip -r $zip_name $log_dir\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            " 2/86 [..............................] - ETA: 5s - loss: 1.9913 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 503.0000 - fn: 9.0000 - accuracy: 0.9824 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4763WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0112s vs `on_train_batch_end` time: 0.1086s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0112s vs `on_train_batch_end` time: 0.1086s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "86/86 [==============================] - ETA: 0s - loss: 1.8827 - tp: 2.0000 - fp: 12.0000 - tn: 21616.0000 - fn: 386.0000 - accuracy: 0.9819 - precision: 0.1429 - recall: 0.0052 - auc: 0.5443WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0045s vs `on_test_batch_end` time: 0.0561s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0045s vs `on_test_batch_end` time: 0.0561s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r86/86 [==============================] - 24s 284ms/step - loss: 1.8827 - tp: 2.0000 - fp: 12.0000 - tn: 21616.0000 - fn: 386.0000 - accuracy: 0.9819 - precision: 0.1429 - recall: 0.0052 - auc: 0.5443 - val_loss: 0.0897 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 10813.0000 - val_fn: 195.0000 - val_accuracy: 0.9823 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5135\n",
            "Epoch 2/100\n",
            "86/86 [==============================] - 15s 173ms/step - loss: 1.4262 - tp: 32.0000 - fp: 813.0000 - tn: 20810.0000 - fn: 361.0000 - accuracy: 0.9467 - precision: 0.0379 - recall: 0.0814 - auc: 0.6499 - val_loss: 0.0847 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 10813.0000 - val_fn: 195.0000 - val_accuracy: 0.9823 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7007\n",
            "Epoch 3/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.9700 - tp: 164.0000 - fp: 4332.0000 - tn: 17291.0000 - fn: 229.0000 - accuracy: 0.7928 - precision: 0.0365 - recall: 0.4173 - auc: 0.6850 - val_loss: 0.0868 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 10813.0000 - val_fn: 195.0000 - val_accuracy: 0.9823 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7223\n",
            "Epoch 4/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.7616 - tp: 223.0000 - fp: 6145.0000 - tn: 15481.0000 - fn: 167.0000 - accuracy: 0.7133 - precision: 0.0350 - recall: 0.5718 - auc: 0.7080 - val_loss: 0.1049 - val_tp: 2.0000 - val_fp: 66.0000 - val_tn: 10747.0000 - val_fn: 193.0000 - val_accuracy: 0.9765 - val_precision: 0.0294 - val_recall: 0.0103 - val_auc: 0.6891\n",
            "Epoch 5/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.7041 - tp: 215.0000 - fp: 5258.0000 - tn: 16368.0000 - fn: 175.0000 - accuracy: 0.7532 - precision: 0.0393 - recall: 0.5513 - auc: 0.7305 - val_loss: 0.1970 - val_tp: 6.0000 - val_fp: 201.0000 - val_tn: 10612.0000 - val_fn: 189.0000 - val_accuracy: 0.9646 - val_precision: 0.0290 - val_recall: 0.0308 - val_auc: 0.5846\n",
            "Epoch 6/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.6577 - tp: 238.0000 - fp: 6453.0000 - tn: 15173.0000 - fn: 152.0000 - accuracy: 0.7000 - precision: 0.0356 - recall: 0.6103 - auc: 0.7285 - val_loss: 0.1220 - val_tp: 6.0000 - val_fp: 108.0000 - val_tn: 10705.0000 - val_fn: 189.0000 - val_accuracy: 0.9730 - val_precision: 0.0526 - val_recall: 0.0308 - val_auc: 0.6917\n",
            "Epoch 7/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.6895 - tp: 240.0000 - fp: 6648.0000 - tn: 14979.0000 - fn: 149.0000 - accuracy: 0.6913 - precision: 0.0348 - recall: 0.6170 - auc: 0.7240 - val_loss: 0.3541 - val_tp: 48.0000 - val_fp: 1164.0000 - val_tn: 9649.0000 - val_fn: 147.0000 - val_accuracy: 0.8809 - val_precision: 0.0396 - val_recall: 0.2462 - val_auc: 0.6463\n",
            "Epoch 8/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.6096 - tp: 259.0000 - fp: 6463.0000 - tn: 15162.0000 - fn: 132.0000 - accuracy: 0.7004 - precision: 0.0385 - recall: 0.6624 - auc: 0.7525 - val_loss: 0.7123 - val_tp: 170.0000 - val_fp: 5245.0000 - val_tn: 5568.0000 - val_fn: 25.0000 - val_accuracy: 0.5213 - val_precision: 0.0314 - val_recall: 0.8718 - val_auc: 0.7847\n",
            "Epoch 9/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.6223 - tp: 266.0000 - fp: 7095.0000 - tn: 14529.0000 - fn: 126.0000 - accuracy: 0.6720 - precision: 0.0361 - recall: 0.6786 - auc: 0.7337 - val_loss: 0.5734 - val_tp: 126.0000 - val_fp: 2841.0000 - val_tn: 7972.0000 - val_fn: 69.0000 - val_accuracy: 0.7356 - val_precision: 0.0425 - val_recall: 0.6462 - val_auc: 0.7682\n",
            "Epoch 10/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5892 - tp: 265.0000 - fp: 7218.0000 - tn: 14406.0000 - fn: 127.0000 - accuracy: 0.6664 - precision: 0.0354 - recall: 0.6760 - auc: 0.7531 - val_loss: 0.6083 - val_tp: 145.0000 - val_fp: 4196.0000 - val_tn: 6617.0000 - val_fn: 50.0000 - val_accuracy: 0.6143 - val_precision: 0.0334 - val_recall: 0.7436 - val_auc: 0.7744\n",
            "Epoch 11/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5767 - tp: 271.0000 - fp: 7263.0000 - tn: 14361.0000 - fn: 121.0000 - accuracy: 0.6646 - precision: 0.0360 - recall: 0.6913 - auc: 0.7595 - val_loss: 0.2885 - val_tp: 49.0000 - val_fp: 494.0000 - val_tn: 10319.0000 - val_fn: 146.0000 - val_accuracy: 0.9419 - val_precision: 0.0902 - val_recall: 0.2513 - val_auc: 0.7929\n",
            "Epoch 12/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.6026 - tp: 265.0000 - fp: 7140.0000 - tn: 14480.0000 - fn: 131.0000 - accuracy: 0.6697 - precision: 0.0358 - recall: 0.6692 - auc: 0.7511 - val_loss: 0.2943 - val_tp: 67.0000 - val_fp: 907.0000 - val_tn: 9906.0000 - val_fn: 128.0000 - val_accuracy: 0.9060 - val_precision: 0.0688 - val_recall: 0.3436 - val_auc: 0.7761\n",
            "Epoch 13/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5791 - tp: 277.0000 - fp: 6561.0000 - tn: 15062.0000 - fn: 116.0000 - accuracy: 0.6967 - precision: 0.0405 - recall: 0.7048 - auc: 0.7794 - val_loss: 0.3047 - val_tp: 58.0000 - val_fp: 697.0000 - val_tn: 10116.0000 - val_fn: 137.0000 - val_accuracy: 0.9242 - val_precision: 0.0768 - val_recall: 0.2974 - val_auc: 0.8027\n",
            "Epoch 14/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5716 - tp: 276.0000 - fp: 6348.0000 - tn: 15278.0000 - fn: 114.0000 - accuracy: 0.7065 - precision: 0.0417 - recall: 0.7077 - auc: 0.7841 - val_loss: 0.2391 - val_tp: 60.0000 - val_fp: 636.0000 - val_tn: 10177.0000 - val_fn: 135.0000 - val_accuracy: 0.9300 - val_precision: 0.0862 - val_recall: 0.3077 - val_auc: 0.7932\n",
            "Epoch 15/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5611 - tp: 273.0000 - fp: 6506.0000 - tn: 15119.0000 - fn: 118.0000 - accuracy: 0.6991 - precision: 0.0403 - recall: 0.6982 - auc: 0.7836 - val_loss: 0.2148 - val_tp: 44.0000 - val_fp: 447.0000 - val_tn: 10366.0000 - val_fn: 151.0000 - val_accuracy: 0.9457 - val_precision: 0.0896 - val_recall: 0.2256 - val_auc: 0.7944\n",
            "Epoch 16/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5429 - tp: 284.0000 - fp: 6676.0000 - tn: 14949.0000 - fn: 107.0000 - accuracy: 0.6919 - precision: 0.0408 - recall: 0.7263 - auc: 0.7925 - val_loss: 0.2329 - val_tp: 60.0000 - val_fp: 611.0000 - val_tn: 10202.0000 - val_fn: 135.0000 - val_accuracy: 0.9322 - val_precision: 0.0894 - val_recall: 0.3077 - val_auc: 0.7905\n",
            "Epoch 17/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5425 - tp: 290.0000 - fp: 6816.0000 - tn: 14808.0000 - fn: 102.0000 - accuracy: 0.6858 - precision: 0.0408 - recall: 0.7398 - auc: 0.7950 - val_loss: 0.3597 - val_tp: 100.0000 - val_fp: 1618.0000 - val_tn: 9195.0000 - val_fn: 95.0000 - val_accuracy: 0.8444 - val_precision: 0.0582 - val_recall: 0.5128 - val_auc: 0.7911\n",
            "Epoch 18/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5352 - tp: 286.0000 - fp: 6525.0000 - tn: 15099.0000 - fn: 106.0000 - accuracy: 0.6988 - precision: 0.0420 - recall: 0.7296 - auc: 0.8018 - val_loss: 0.3384 - val_tp: 93.0000 - val_fp: 1196.0000 - val_tn: 9617.0000 - val_fn: 102.0000 - val_accuracy: 0.8821 - val_precision: 0.0721 - val_recall: 0.4769 - val_auc: 0.7976\n",
            "Epoch 19/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5536 - tp: 267.0000 - fp: 6900.0000 - tn: 14725.0000 - fn: 124.0000 - accuracy: 0.6810 - precision: 0.0373 - recall: 0.6829 - auc: 0.7788 - val_loss: 0.3403 - val_tp: 91.0000 - val_fp: 1280.0000 - val_tn: 9533.0000 - val_fn: 104.0000 - val_accuracy: 0.8743 - val_precision: 0.0664 - val_recall: 0.4667 - val_auc: 0.7907\n",
            "Epoch 20/100\n",
            "86/86 [==============================] - 15s 173ms/step - loss: 0.5662 - tp: 275.0000 - fp: 6742.0000 - tn: 14879.0000 - fn: 120.0000 - accuracy: 0.6883 - precision: 0.0392 - recall: 0.6962 - auc: 0.7766 - val_loss: 0.3288 - val_tp: 88.0000 - val_fp: 1087.0000 - val_tn: 9726.0000 - val_fn: 107.0000 - val_accuracy: 0.8915 - val_precision: 0.0749 - val_recall: 0.4513 - val_auc: 0.7913\n",
            "Epoch 21/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5610 - tp: 277.0000 - fp: 6664.0000 - tn: 14961.0000 - fn: 114.0000 - accuracy: 0.6921 - precision: 0.0399 - recall: 0.7084 - auc: 0.7801 - val_loss: 0.4693 - val_tp: 117.0000 - val_fp: 2113.0000 - val_tn: 8700.0000 - val_fn: 78.0000 - val_accuracy: 0.8010 - val_precision: 0.0525 - val_recall: 0.6000 - val_auc: 0.7768\n",
            "Epoch 22/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5634 - tp: 282.0000 - fp: 6718.0000 - tn: 14905.0000 - fn: 111.0000 - accuracy: 0.6898 - precision: 0.0403 - recall: 0.7176 - auc: 0.7799 - val_loss: 0.4357 - val_tp: 126.0000 - val_fp: 2425.0000 - val_tn: 8388.0000 - val_fn: 69.0000 - val_accuracy: 0.7734 - val_precision: 0.0494 - val_recall: 0.6462 - val_auc: 0.7965\n",
            "Epoch 23/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5864 - tp: 282.0000 - fp: 6455.0000 - tn: 15165.0000 - fn: 114.0000 - accuracy: 0.7016 - precision: 0.0419 - recall: 0.7121 - auc: 0.7800 - val_loss: 0.6300 - val_tp: 132.0000 - val_fp: 3435.0000 - val_tn: 7378.0000 - val_fn: 63.0000 - val_accuracy: 0.6822 - val_precision: 0.0370 - val_recall: 0.6769 - val_auc: 0.7415\n",
            "Epoch 24/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.6248 - tp: 253.0000 - fp: 6138.0000 - tn: 15487.0000 - fn: 138.0000 - accuracy: 0.7149 - precision: 0.0396 - recall: 0.6471 - auc: 0.7576 - val_loss: 0.2107 - val_tp: 54.0000 - val_fp: 592.0000 - val_tn: 10221.0000 - val_fn: 141.0000 - val_accuracy: 0.9334 - val_precision: 0.0836 - val_recall: 0.2769 - val_auc: 0.7778\n",
            "Epoch 25/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5468 - tp: 283.0000 - fp: 6293.0000 - tn: 15332.0000 - fn: 108.0000 - accuracy: 0.7093 - precision: 0.0430 - recall: 0.7238 - auc: 0.7955 - val_loss: 0.3936 - val_tp: 77.0000 - val_fp: 1488.0000 - val_tn: 9325.0000 - val_fn: 118.0000 - val_accuracy: 0.8541 - val_precision: 0.0492 - val_recall: 0.3949 - val_auc: 0.7253\n",
            "Epoch 26/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5633 - tp: 272.0000 - fp: 6710.0000 - tn: 14912.0000 - fn: 122.0000 - accuracy: 0.6897 - precision: 0.0390 - recall: 0.6904 - auc: 0.7811 - val_loss: 0.1924 - val_tp: 34.0000 - val_fp: 331.0000 - val_tn: 10482.0000 - val_fn: 161.0000 - val_accuracy: 0.9553 - val_precision: 0.0932 - val_recall: 0.1744 - val_auc: 0.7859\n",
            "Epoch 27/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5508 - tp: 287.0000 - fp: 6318.0000 - tn: 15305.0000 - fn: 106.0000 - accuracy: 0.7082 - precision: 0.0435 - recall: 0.7303 - auc: 0.7970 - val_loss: 0.2396 - val_tp: 68.0000 - val_fp: 902.0000 - val_tn: 9911.0000 - val_fn: 127.0000 - val_accuracy: 0.9065 - val_precision: 0.0701 - val_recall: 0.3487 - val_auc: 0.7832\n",
            "Epoch 28/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5453 - tp: 278.0000 - fp: 6462.0000 - tn: 15162.0000 - fn: 114.0000 - accuracy: 0.7013 - precision: 0.0412 - recall: 0.7092 - auc: 0.7935 - val_loss: 0.2279 - val_tp: 42.0000 - val_fp: 356.0000 - val_tn: 10457.0000 - val_fn: 153.0000 - val_accuracy: 0.9538 - val_precision: 0.1055 - val_recall: 0.2154 - val_auc: 0.8009\n",
            "Epoch 29/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5335 - tp: 286.0000 - fp: 6178.0000 - tn: 15447.0000 - fn: 105.0000 - accuracy: 0.7146 - precision: 0.0442 - recall: 0.7315 - auc: 0.8107 - val_loss: 0.3234 - val_tp: 79.0000 - val_fp: 880.0000 - val_tn: 9933.0000 - val_fn: 116.0000 - val_accuracy: 0.9095 - val_precision: 0.0824 - val_recall: 0.4051 - val_auc: 0.7956\n",
            "Epoch 30/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5265 - tp: 298.0000 - fp: 6597.0000 - tn: 15027.0000 - fn: 94.0000 - accuracy: 0.6961 - precision: 0.0432 - recall: 0.7602 - auc: 0.8112 - val_loss: 0.3150 - val_tp: 82.0000 - val_fp: 973.0000 - val_tn: 9840.0000 - val_fn: 113.0000 - val_accuracy: 0.9013 - val_precision: 0.0777 - val_recall: 0.4205 - val_auc: 0.8026\n",
            "Epoch 31/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.5079 - tp: 295.0000 - fp: 6296.0000 - tn: 15329.0000 - fn: 96.0000 - accuracy: 0.7097 - precision: 0.0448 - recall: 0.7545 - auc: 0.8211 - val_loss: 0.2579 - val_tp: 58.0000 - val_fp: 576.0000 - val_tn: 10237.0000 - val_fn: 137.0000 - val_accuracy: 0.9352 - val_precision: 0.0915 - val_recall: 0.2974 - val_auc: 0.8013\n",
            "Epoch 32/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5039 - tp: 305.0000 - fp: 5984.0000 - tn: 15640.0000 - fn: 87.0000 - accuracy: 0.7242 - precision: 0.0485 - recall: 0.7781 - auc: 0.8345 - val_loss: 0.2209 - val_tp: 52.0000 - val_fp: 441.0000 - val_tn: 10372.0000 - val_fn: 143.0000 - val_accuracy: 0.9469 - val_precision: 0.1055 - val_recall: 0.2667 - val_auc: 0.7942\n",
            "Epoch 33/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5140 - tp: 291.0000 - fp: 5884.0000 - tn: 15740.0000 - fn: 101.0000 - accuracy: 0.7282 - precision: 0.0471 - recall: 0.7423 - auc: 0.8196 - val_loss: 0.2735 - val_tp: 61.0000 - val_fp: 705.0000 - val_tn: 10108.0000 - val_fn: 134.0000 - val_accuracy: 0.9238 - val_precision: 0.0796 - val_recall: 0.3128 - val_auc: 0.7984\n",
            "Epoch 34/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.4835 - tp: 314.0000 - fp: 5961.0000 - tn: 15662.0000 - fn: 79.0000 - accuracy: 0.7257 - precision: 0.0500 - recall: 0.7990 - auc: 0.8438 - val_loss: 0.3452 - val_tp: 85.0000 - val_fp: 1087.0000 - val_tn: 9726.0000 - val_fn: 110.0000 - val_accuracy: 0.8913 - val_precision: 0.0725 - val_recall: 0.4359 - val_auc: 0.7944\n",
            "Epoch 35/100\n",
            "86/86 [==============================] - 16s 191ms/step - loss: 0.5069 - tp: 298.0000 - fp: 5993.0000 - tn: 15631.0000 - fn: 94.0000 - accuracy: 0.7235 - precision: 0.0474 - recall: 0.7602 - auc: 0.8259 - val_loss: 0.1976 - val_tp: 37.0000 - val_fp: 322.0000 - val_tn: 10491.0000 - val_fn: 158.0000 - val_accuracy: 0.9564 - val_precision: 0.1031 - val_recall: 0.1897 - val_auc: 0.7888\n",
            "Epoch 36/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5120 - tp: 295.0000 - fp: 5860.0000 - tn: 15764.0000 - fn: 97.0000 - accuracy: 0.7294 - precision: 0.0479 - recall: 0.7526 - auc: 0.8244 - val_loss: 0.1985 - val_tp: 44.0000 - val_fp: 548.0000 - val_tn: 10265.0000 - val_fn: 151.0000 - val_accuracy: 0.9365 - val_precision: 0.0743 - val_recall: 0.2256 - val_auc: 0.7740\n",
            "Epoch 37/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.5233 - tp: 291.0000 - fp: 6341.0000 - tn: 15286.0000 - fn: 98.0000 - accuracy: 0.7075 - precision: 0.0439 - recall: 0.7481 - auc: 0.8109 - val_loss: 0.1468 - val_tp: 26.0000 - val_fp: 228.0000 - val_tn: 10585.0000 - val_fn: 169.0000 - val_accuracy: 0.9639 - val_precision: 0.1024 - val_recall: 0.1333 - val_auc: 0.7598\n",
            "Epoch 38/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5174 - tp: 288.0000 - fp: 6145.0000 - tn: 15480.0000 - fn: 103.0000 - accuracy: 0.7162 - precision: 0.0448 - recall: 0.7366 - auc: 0.8153 - val_loss: 0.2991 - val_tp: 73.0000 - val_fp: 954.0000 - val_tn: 9859.0000 - val_fn: 122.0000 - val_accuracy: 0.9023 - val_precision: 0.0711 - val_recall: 0.3744 - val_auc: 0.7893\n",
            "Epoch 39/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.4899 - tp: 303.0000 - fp: 5870.0000 - tn: 15756.0000 - fn: 87.0000 - accuracy: 0.7294 - precision: 0.0491 - recall: 0.7769 - auc: 0.8369 - val_loss: 0.1341 - val_tp: 20.0000 - val_fp: 140.0000 - val_tn: 10673.0000 - val_fn: 175.0000 - val_accuracy: 0.9714 - val_precision: 0.1250 - val_recall: 0.1026 - val_auc: 0.7640\n",
            "Epoch 40/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5219 - tp: 283.0000 - fp: 5849.0000 - tn: 15777.0000 - fn: 107.0000 - accuracy: 0.7295 - precision: 0.0462 - recall: 0.7256 - auc: 0.8163 - val_loss: 0.3280 - val_tp: 55.0000 - val_fp: 685.0000 - val_tn: 10128.0000 - val_fn: 140.0000 - val_accuracy: 0.9251 - val_precision: 0.0743 - val_recall: 0.2821 - val_auc: 0.7407\n",
            "Epoch 41/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5564 - tp: 279.0000 - fp: 6269.0000 - tn: 15352.0000 - fn: 116.0000 - accuracy: 0.7100 - precision: 0.0426 - recall: 0.7063 - auc: 0.7959 - val_loss: 0.3383 - val_tp: 96.0000 - val_fp: 1363.0000 - val_tn: 9450.0000 - val_fn: 99.0000 - val_accuracy: 0.8672 - val_precision: 0.0658 - val_recall: 0.4923 - val_auc: 0.7890\n",
            "Epoch 42/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.5157 - tp: 282.0000 - fp: 5823.0000 - tn: 15802.0000 - fn: 109.0000 - accuracy: 0.7306 - precision: 0.0462 - recall: 0.7212 - auc: 0.8175 - val_loss: 0.1701 - val_tp: 40.0000 - val_fp: 284.0000 - val_tn: 10529.0000 - val_fn: 155.0000 - val_accuracy: 0.9601 - val_precision: 0.1235 - val_recall: 0.2051 - val_auc: 0.8025\n",
            "Epoch 43/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.5021 - tp: 300.0000 - fp: 5909.0000 - tn: 15716.0000 - fn: 91.0000 - accuracy: 0.7275 - precision: 0.0483 - recall: 0.7673 - auc: 0.8287 - val_loss: 0.3096 - val_tp: 83.0000 - val_fp: 998.0000 - val_tn: 9815.0000 - val_fn: 112.0000 - val_accuracy: 0.8992 - val_precision: 0.0768 - val_recall: 0.4256 - val_auc: 0.7955\n",
            "Epoch 44/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.4881 - tp: 306.0000 - fp: 5536.0000 - tn: 16087.0000 - fn: 87.0000 - accuracy: 0.7446 - precision: 0.0524 - recall: 0.7786 - auc: 0.8409 - val_loss: 0.3770 - val_tp: 99.0000 - val_fp: 1561.0000 - val_tn: 9252.0000 - val_fn: 96.0000 - val_accuracy: 0.8495 - val_precision: 0.0596 - val_recall: 0.5077 - val_auc: 0.7875\n",
            "Epoch 45/100\n",
            "86/86 [==============================] - 15s 173ms/step - loss: 0.4518 - tp: 309.0000 - fp: 5350.0000 - tn: 16276.0000 - fn: 81.0000 - accuracy: 0.7533 - precision: 0.0546 - recall: 0.7923 - auc: 0.8644 - val_loss: 0.1545 - val_tp: 27.0000 - val_fp: 183.0000 - val_tn: 10630.0000 - val_fn: 168.0000 - val_accuracy: 0.9681 - val_precision: 0.1286 - val_recall: 0.1385 - val_auc: 0.7887\n",
            "Epoch 46/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4384 - tp: 324.0000 - fp: 5223.0000 - tn: 16402.0000 - fn: 67.0000 - accuracy: 0.7597 - precision: 0.0584 - recall: 0.8286 - auc: 0.8738 - val_loss: 0.2666 - val_tp: 66.0000 - val_fp: 829.0000 - val_tn: 9984.0000 - val_fn: 129.0000 - val_accuracy: 0.9130 - val_precision: 0.0737 - val_recall: 0.3385 - val_auc: 0.7763\n",
            "Epoch 47/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.4401 - tp: 313.0000 - fp: 4999.0000 - tn: 16625.0000 - fn: 79.0000 - accuracy: 0.7693 - precision: 0.0589 - recall: 0.7985 - auc: 0.8739 - val_loss: 0.2706 - val_tp: 71.0000 - val_fp: 861.0000 - val_tn: 9952.0000 - val_fn: 124.0000 - val_accuracy: 0.9105 - val_precision: 0.0762 - val_recall: 0.3641 - val_auc: 0.7820\n",
            "Epoch 48/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4280 - tp: 320.0000 - fp: 4822.0000 - tn: 16803.0000 - fn: 71.0000 - accuracy: 0.7778 - precision: 0.0622 - recall: 0.8184 - auc: 0.8817 - val_loss: 0.1721 - val_tp: 31.0000 - val_fp: 287.0000 - val_tn: 10526.0000 - val_fn: 164.0000 - val_accuracy: 0.9590 - val_precision: 0.0975 - val_recall: 0.1590 - val_auc: 0.7861\n",
            "Epoch 49/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.4215 - tp: 315.0000 - fp: 4819.0000 - tn: 16806.0000 - fn: 76.0000 - accuracy: 0.7777 - precision: 0.0614 - recall: 0.8056 - auc: 0.8852 - val_loss: 0.2571 - val_tp: 60.0000 - val_fp: 746.0000 - val_tn: 10067.0000 - val_fn: 135.0000 - val_accuracy: 0.9200 - val_precision: 0.0744 - val_recall: 0.3077 - val_auc: 0.7739\n",
            "Epoch 50/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4359 - tp: 317.0000 - fp: 4946.0000 - tn: 16679.0000 - fn: 74.0000 - accuracy: 0.7720 - precision: 0.0602 - recall: 0.8107 - auc: 0.8751 - val_loss: 0.2229 - val_tp: 51.0000 - val_fp: 556.0000 - val_tn: 10257.0000 - val_fn: 144.0000 - val_accuracy: 0.9364 - val_precision: 0.0840 - val_recall: 0.2615 - val_auc: 0.7740\n",
            "Epoch 51/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.4146 - tp: 323.0000 - fp: 4488.0000 - tn: 17137.0000 - fn: 68.0000 - accuracy: 0.7931 - precision: 0.0671 - recall: 0.8261 - auc: 0.8900 - val_loss: 0.2123 - val_tp: 43.0000 - val_fp: 418.0000 - val_tn: 10395.0000 - val_fn: 152.0000 - val_accuracy: 0.9482 - val_precision: 0.0933 - val_recall: 0.2205 - val_auc: 0.7717\n",
            "Epoch 52/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.4425 - tp: 317.0000 - fp: 5075.0000 - tn: 16550.0000 - fn: 74.0000 - accuracy: 0.7661 - precision: 0.0588 - recall: 0.8107 - auc: 0.8716 - val_loss: 0.1409 - val_tp: 25.0000 - val_fp: 197.0000 - val_tn: 10616.0000 - val_fn: 170.0000 - val_accuracy: 0.9667 - val_precision: 0.1126 - val_recall: 0.1282 - val_auc: 0.7807\n",
            "Epoch 53/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.4450 - tp: 303.0000 - fp: 4946.0000 - tn: 16676.0000 - fn: 91.0000 - accuracy: 0.7712 - precision: 0.0577 - recall: 0.7690 - auc: 0.8717 - val_loss: 0.7206 - val_tp: 144.0000 - val_fp: 4404.0000 - val_tn: 6409.0000 - val_fn: 51.0000 - val_accuracy: 0.5953 - val_precision: 0.0317 - val_recall: 0.7385 - val_auc: 0.7133\n",
            "Epoch 54/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.4434 - tp: 310.0000 - fp: 4819.0000 - tn: 16805.0000 - fn: 82.0000 - accuracy: 0.7774 - precision: 0.0604 - recall: 0.7908 - auc: 0.8734 - val_loss: 0.5303 - val_tp: 120.0000 - val_fp: 2649.0000 - val_tn: 8164.0000 - val_fn: 75.0000 - val_accuracy: 0.7525 - val_precision: 0.0433 - val_recall: 0.6154 - val_auc: 0.7465\n",
            "Epoch 55/100\n",
            "86/86 [==============================] - 15s 172ms/step - loss: 0.4598 - tp: 309.0000 - fp: 5106.0000 - tn: 16518.0000 - fn: 83.0000 - accuracy: 0.7643 - precision: 0.0571 - recall: 0.7883 - auc: 0.8631 - val_loss: 0.6730 - val_tp: 148.0000 - val_fp: 4152.0000 - val_tn: 6661.0000 - val_fn: 47.0000 - val_accuracy: 0.6186 - val_precision: 0.0344 - val_recall: 0.7590 - val_auc: 0.7618\n",
            "Epoch 56/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.4638 - tp: 304.0000 - fp: 4991.0000 - tn: 16634.0000 - fn: 87.0000 - accuracy: 0.7693 - precision: 0.0574 - recall: 0.7775 - auc: 0.8599 - val_loss: 0.2556 - val_tp: 59.0000 - val_fp: 877.0000 - val_tn: 9936.0000 - val_fn: 136.0000 - val_accuracy: 0.9080 - val_precision: 0.0630 - val_recall: 0.3026 - val_auc: 0.7613\n",
            "Epoch 57/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4392 - tp: 316.0000 - fp: 5096.0000 - tn: 16525.0000 - fn: 79.0000 - accuracy: 0.7649 - precision: 0.0584 - recall: 0.8000 - auc: 0.8733 - val_loss: 0.2129 - val_tp: 39.0000 - val_fp: 485.0000 - val_tn: 10328.0000 - val_fn: 156.0000 - val_accuracy: 0.9418 - val_precision: 0.0744 - val_recall: 0.2000 - val_auc: 0.7456\n",
            "Epoch 58/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.4330 - tp: 315.0000 - fp: 4902.0000 - tn: 16723.0000 - fn: 76.0000 - accuracy: 0.7739 - precision: 0.0604 - recall: 0.8056 - auc: 0.8771 - val_loss: 0.1030 - val_tp: 9.0000 - val_fp: 65.0000 - val_tn: 10748.0000 - val_fn: 186.0000 - val_accuracy: 0.9772 - val_precision: 0.1216 - val_recall: 0.0462 - val_auc: 0.7338\n",
            "Epoch 59/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.4067 - tp: 326.0000 - fp: 4718.0000 - tn: 16908.0000 - fn: 64.0000 - accuracy: 0.7828 - precision: 0.0646 - recall: 0.8359 - auc: 0.8940 - val_loss: 0.3962 - val_tp: 97.0000 - val_fp: 1839.0000 - val_tn: 8974.0000 - val_fn: 98.0000 - val_accuracy: 0.8240 - val_precision: 0.0501 - val_recall: 0.4974 - val_auc: 0.7601\n",
            "Epoch 60/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.3854 - tp: 327.0000 - fp: 4338.0000 - tn: 17288.0000 - fn: 63.0000 - accuracy: 0.8001 - precision: 0.0701 - recall: 0.8385 - auc: 0.9041 - val_loss: 0.1980 - val_tp: 42.0000 - val_fp: 497.0000 - val_tn: 10316.0000 - val_fn: 153.0000 - val_accuracy: 0.9410 - val_precision: 0.0779 - val_recall: 0.2154 - val_auc: 0.7462\n",
            "Epoch 61/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.3873 - tp: 322.0000 - fp: 4335.0000 - tn: 17290.0000 - fn: 69.0000 - accuracy: 0.8000 - precision: 0.0691 - recall: 0.8235 - auc: 0.9040 - val_loss: 0.0904 - val_tp: 3.0000 - val_fp: 16.0000 - val_tn: 10797.0000 - val_fn: 192.0000 - val_accuracy: 0.9811 - val_precision: 0.1579 - val_recall: 0.0154 - val_auc: 0.7440\n",
            "Epoch 62/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.3523 - tp: 334.0000 - fp: 4144.0000 - tn: 17484.0000 - fn: 54.0000 - accuracy: 0.8093 - precision: 0.0746 - recall: 0.8608 - auc: 0.9205 - val_loss: 0.1563 - val_tp: 22.0000 - val_fp: 294.0000 - val_tn: 10519.0000 - val_fn: 173.0000 - val_accuracy: 0.9576 - val_precision: 0.0696 - val_recall: 0.1128 - val_auc: 0.7339\n",
            "Epoch 63/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.3627 - tp: 328.0000 - fp: 4115.0000 - tn: 17509.0000 - fn: 64.0000 - accuracy: 0.8102 - precision: 0.0738 - recall: 0.8367 - auc: 0.9157 - val_loss: 0.1379 - val_tp: 17.0000 - val_fp: 211.0000 - val_tn: 10602.0000 - val_fn: 178.0000 - val_accuracy: 0.9647 - val_precision: 0.0746 - val_recall: 0.0872 - val_auc: 0.7343\n",
            "Epoch 64/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.3268 - tp: 347.0000 - fp: 3817.0000 - tn: 17811.0000 - fn: 41.0000 - accuracy: 0.8248 - precision: 0.0833 - recall: 0.8943 - auc: 0.9334 - val_loss: 0.1316 - val_tp: 20.0000 - val_fp: 207.0000 - val_tn: 10606.0000 - val_fn: 175.0000 - val_accuracy: 0.9653 - val_precision: 0.0881 - val_recall: 0.1026 - val_auc: 0.7328\n",
            "Epoch 65/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.3206 - tp: 351.0000 - fp: 3477.0000 - tn: 18140.0000 - fn: 48.0000 - accuracy: 0.8399 - precision: 0.0917 - recall: 0.8797 - auc: 0.9380 - val_loss: 0.1304 - val_tp: 21.0000 - val_fp: 208.0000 - val_tn: 10605.0000 - val_fn: 174.0000 - val_accuracy: 0.9653 - val_precision: 0.0917 - val_recall: 0.1077 - val_auc: 0.7313\n",
            "Epoch 66/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.3202 - tp: 343.0000 - fp: 3561.0000 - tn: 18064.0000 - fn: 48.0000 - accuracy: 0.8361 - precision: 0.0879 - recall: 0.8772 - auc: 0.9367 - val_loss: 0.0925 - val_tp: 4.0000 - val_fp: 37.0000 - val_tn: 10776.0000 - val_fn: 191.0000 - val_accuracy: 0.9793 - val_precision: 0.0976 - val_recall: 0.0205 - val_auc: 0.7196\n",
            "Epoch 67/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.3615 - tp: 333.0000 - fp: 3855.0000 - tn: 17767.0000 - fn: 61.0000 - accuracy: 0.8221 - precision: 0.0795 - recall: 0.8452 - auc: 0.9177 - val_loss: 0.1863 - val_tp: 33.0000 - val_fp: 478.0000 - val_tn: 10335.0000 - val_fn: 162.0000 - val_accuracy: 0.9419 - val_precision: 0.0646 - val_recall: 0.1692 - val_auc: 0.7099\n",
            "Epoch 68/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.3533 - tp: 333.0000 - fp: 3952.0000 - tn: 17670.0000 - fn: 61.0000 - accuracy: 0.8177 - precision: 0.0777 - recall: 0.8452 - auc: 0.9208 - val_loss: 0.0947 - val_tp: 7.0000 - val_fp: 42.0000 - val_tn: 10771.0000 - val_fn: 188.0000 - val_accuracy: 0.9791 - val_precision: 0.1429 - val_recall: 0.0359 - val_auc: 0.7439\n",
            "Epoch 69/100\n",
            "86/86 [==============================] - 15s 178ms/step - loss: 0.3768 - tp: 327.0000 - fp: 4138.0000 - tn: 17485.0000 - fn: 66.0000 - accuracy: 0.8090 - precision: 0.0732 - recall: 0.8321 - auc: 0.9101 - val_loss: 0.1177 - val_tp: 12.0000 - val_fp: 112.0000 - val_tn: 10701.0000 - val_fn: 183.0000 - val_accuracy: 0.9732 - val_precision: 0.0968 - val_recall: 0.0615 - val_auc: 0.7006\n",
            "Epoch 70/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.3540 - tp: 325.0000 - fp: 3799.0000 - tn: 17821.0000 - fn: 71.0000 - accuracy: 0.8242 - precision: 0.0788 - recall: 0.8207 - auc: 0.9209 - val_loss: 0.2083 - val_tp: 39.0000 - val_fp: 498.0000 - val_tn: 10315.0000 - val_fn: 156.0000 - val_accuracy: 0.9406 - val_precision: 0.0726 - val_recall: 0.2000 - val_auc: 0.7160\n",
            "Epoch 71/100\n",
            "86/86 [==============================] - 15s 173ms/step - loss: 0.3727 - tp: 323.0000 - fp: 3969.0000 - tn: 17657.0000 - fn: 67.0000 - accuracy: 0.8167 - precision: 0.0753 - recall: 0.8282 - auc: 0.9121 - val_loss: 0.1482 - val_tp: 36.0000 - val_fp: 329.0000 - val_tn: 10484.0000 - val_fn: 159.0000 - val_accuracy: 0.9557 - val_precision: 0.0986 - val_recall: 0.1846 - val_auc: 0.7599\n",
            "Epoch 72/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.3837 - tp: 317.0000 - fp: 4288.0000 - tn: 17335.0000 - fn: 76.0000 - accuracy: 0.8018 - precision: 0.0688 - recall: 0.8066 - auc: 0.9053 - val_loss: 0.1252 - val_tp: 19.0000 - val_fp: 170.0000 - val_tn: 10643.0000 - val_fn: 176.0000 - val_accuracy: 0.9686 - val_precision: 0.1005 - val_recall: 0.0974 - val_auc: 0.7531\n",
            "Epoch 73/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.3860 - tp: 326.0000 - fp: 4282.0000 - tn: 17344.0000 - fn: 64.0000 - accuracy: 0.8026 - precision: 0.0707 - recall: 0.8359 - auc: 0.9057 - val_loss: 0.1952 - val_tp: 42.0000 - val_fp: 612.0000 - val_tn: 10201.0000 - val_fn: 153.0000 - val_accuracy: 0.9305 - val_precision: 0.0642 - val_recall: 0.2154 - val_auc: 0.7436\n",
            "Epoch 74/100\n",
            "86/86 [==============================] - 15s 179ms/step - loss: 0.3387 - tp: 337.0000 - fp: 3859.0000 - tn: 17766.0000 - fn: 54.0000 - accuracy: 0.8223 - precision: 0.0803 - recall: 0.8619 - auc: 0.9268 - val_loss: 0.1152 - val_tp: 13.0000 - val_fp: 151.0000 - val_tn: 10662.0000 - val_fn: 182.0000 - val_accuracy: 0.9697 - val_precision: 0.0793 - val_recall: 0.0667 - val_auc: 0.7250\n",
            "Epoch 75/100\n",
            "86/86 [==============================] - 15s 178ms/step - loss: 0.3352 - tp: 344.0000 - fp: 3813.0000 - tn: 17810.0000 - fn: 49.0000 - accuracy: 0.8246 - precision: 0.0828 - recall: 0.8753 - auc: 0.9301 - val_loss: 0.2008 - val_tp: 43.0000 - val_fp: 473.0000 - val_tn: 10340.0000 - val_fn: 152.0000 - val_accuracy: 0.9432 - val_precision: 0.0833 - val_recall: 0.2205 - val_auc: 0.7415\n",
            "Epoch 76/100\n",
            "86/86 [==============================] - 16s 181ms/step - loss: 0.3106 - tp: 342.0000 - fp: 3581.0000 - tn: 18041.0000 - fn: 52.0000 - accuracy: 0.8350 - precision: 0.0872 - recall: 0.8680 - auc: 0.9393 - val_loss: 0.1249 - val_tp: 12.0000 - val_fp: 105.0000 - val_tn: 10708.0000 - val_fn: 183.0000 - val_accuracy: 0.9738 - val_precision: 0.1026 - val_recall: 0.0615 - val_auc: 0.7325\n",
            "Epoch 77/100\n",
            "86/86 [==============================] - 15s 177ms/step - loss: 0.3072 - tp: 342.0000 - fp: 3185.0000 - tn: 18438.0000 - fn: 51.0000 - accuracy: 0.8530 - precision: 0.0970 - recall: 0.8702 - auc: 0.9415 - val_loss: 0.1064 - val_tp: 12.0000 - val_fp: 97.0000 - val_tn: 10716.0000 - val_fn: 183.0000 - val_accuracy: 0.9746 - val_precision: 0.1101 - val_recall: 0.0615 - val_auc: 0.7326\n",
            "Epoch 78/100\n",
            "86/86 [==============================] - 15s 174ms/step - loss: 0.2743 - tp: 342.0000 - fp: 3175.0000 - tn: 18451.0000 - fn: 48.0000 - accuracy: 0.8536 - precision: 0.0972 - recall: 0.8769 - auc: 0.9528 - val_loss: 0.1988 - val_tp: 44.0000 - val_fp: 526.0000 - val_tn: 10287.0000 - val_fn: 151.0000 - val_accuracy: 0.9385 - val_precision: 0.0772 - val_recall: 0.2256 - val_auc: 0.7263\n",
            "Epoch 79/100\n",
            "86/86 [==============================] - 15s 175ms/step - loss: 0.2586 - tp: 361.0000 - fp: 2995.0000 - tn: 18628.0000 - fn: 32.0000 - accuracy: 0.8625 - precision: 0.1076 - recall: 0.9186 - auc: 0.9598 - val_loss: 0.0948 - val_tp: 4.0000 - val_fp: 29.0000 - val_tn: 10784.0000 - val_fn: 191.0000 - val_accuracy: 0.9800 - val_precision: 0.1212 - val_recall: 0.0205 - val_auc: 0.6909\n",
            "Epoch 80/100\n",
            "86/86 [==============================] - 15s 174ms/step - loss: 0.2521 - tp: 359.0000 - fp: 2997.0000 - tn: 18627.0000 - fn: 33.0000 - accuracy: 0.8624 - precision: 0.1070 - recall: 0.9158 - auc: 0.9619 - val_loss: 0.1011 - val_tp: 8.0000 - val_fp: 64.0000 - val_tn: 10749.0000 - val_fn: 187.0000 - val_accuracy: 0.9772 - val_precision: 0.1111 - val_recall: 0.0410 - val_auc: 0.6977\n",
            "Epoch 81/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.2508 - tp: 348.0000 - fp: 2836.0000 - tn: 18791.0000 - fn: 41.0000 - accuracy: 0.8693 - precision: 0.1093 - recall: 0.8946 - auc: 0.9614 - val_loss: 0.1032 - val_tp: 7.0000 - val_fp: 70.0000 - val_tn: 10743.0000 - val_fn: 188.0000 - val_accuracy: 0.9766 - val_precision: 0.0909 - val_recall: 0.0359 - val_auc: 0.6969\n",
            "Epoch 82/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.2491 - tp: 358.0000 - fp: 2911.0000 - tn: 18711.0000 - fn: 36.0000 - accuracy: 0.8661 - precision: 0.1095 - recall: 0.9086 - auc: 0.9627 - val_loss: 0.1250 - val_tp: 17.0000 - val_fp: 157.0000 - val_tn: 10656.0000 - val_fn: 178.0000 - val_accuracy: 0.9696 - val_precision: 0.0977 - val_recall: 0.0872 - val_auc: 0.7080\n",
            "Epoch 83/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.2545 - tp: 357.0000 - fp: 2822.0000 - tn: 18800.0000 - fn: 37.0000 - accuracy: 0.8701 - precision: 0.1123 - recall: 0.9061 - auc: 0.9607 - val_loss: 0.0957 - val_tp: 6.0000 - val_fp: 53.0000 - val_tn: 10760.0000 - val_fn: 189.0000 - val_accuracy: 0.9780 - val_precision: 0.1017 - val_recall: 0.0308 - val_auc: 0.7106\n",
            "Epoch 84/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.2553 - tp: 356.0000 - fp: 2987.0000 - tn: 18638.0000 - fn: 35.0000 - accuracy: 0.8627 - precision: 0.1065 - recall: 0.9105 - auc: 0.9600 - val_loss: 0.1169 - val_tp: 21.0000 - val_fp: 177.0000 - val_tn: 10636.0000 - val_fn: 174.0000 - val_accuracy: 0.9681 - val_precision: 0.1061 - val_recall: 0.1077 - val_auc: 0.7401\n",
            "Epoch 85/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.2661 - tp: 353.0000 - fp: 2887.0000 - tn: 18735.0000 - fn: 41.0000 - accuracy: 0.8670 - precision: 0.1090 - recall: 0.8959 - auc: 0.9560 - val_loss: 0.1015 - val_tp: 7.0000 - val_fp: 57.0000 - val_tn: 10756.0000 - val_fn: 188.0000 - val_accuracy: 0.9777 - val_precision: 0.1094 - val_recall: 0.0359 - val_auc: 0.7046\n",
            "Epoch 86/100\n",
            "86/86 [==============================] - 15s 175ms/step - loss: 0.3038 - tp: 334.0000 - fp: 3500.0000 - tn: 18126.0000 - fn: 56.0000 - accuracy: 0.8385 - precision: 0.0871 - recall: 0.8564 - auc: 0.9415 - val_loss: 0.1388 - val_tp: 33.0000 - val_fp: 311.0000 - val_tn: 10502.0000 - val_fn: 162.0000 - val_accuracy: 0.9570 - val_precision: 0.0959 - val_recall: 0.1692 - val_auc: 0.7340\n",
            "Epoch 87/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.2977 - tp: 338.0000 - fp: 3263.0000 - tn: 18362.0000 - fn: 53.0000 - accuracy: 0.8494 - precision: 0.0939 - recall: 0.8645 - auc: 0.9437 - val_loss: 0.1285 - val_tp: 4.0000 - val_fp: 34.0000 - val_tn: 10779.0000 - val_fn: 191.0000 - val_accuracy: 0.9796 - val_precision: 0.1053 - val_recall: 0.0205 - val_auc: 0.6225\n",
            "Epoch 88/100\n",
            "86/86 [==============================] - 15s 172ms/step - loss: 0.3139 - tp: 334.0000 - fp: 3379.0000 - tn: 18244.0000 - fn: 59.0000 - accuracy: 0.8438 - precision: 0.0900 - recall: 0.8499 - auc: 0.9380 - val_loss: 0.1068 - val_tp: 0.0000e+00 - val_fp: 10.0000 - val_tn: 10803.0000 - val_fn: 195.0000 - val_accuracy: 0.9814 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6410\n",
            "Epoch 89/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.3045 - tp: 339.0000 - fp: 3398.0000 - tn: 18224.0000 - fn: 55.0000 - accuracy: 0.8432 - precision: 0.0907 - recall: 0.8604 - auc: 0.9410 - val_loss: 0.1189 - val_tp: 25.0000 - val_fp: 161.0000 - val_tn: 10652.0000 - val_fn: 170.0000 - val_accuracy: 0.9699 - val_precision: 0.1344 - val_recall: 0.1282 - val_auc: 0.7411\n",
            "Epoch 90/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.3082 - tp: 353.0000 - fp: 3660.0000 - tn: 17963.0000 - fn: 40.0000 - accuracy: 0.8319 - precision: 0.0880 - recall: 0.8982 - auc: 0.9394 - val_loss: 0.1673 - val_tp: 34.0000 - val_fp: 449.0000 - val_tn: 10364.0000 - val_fn: 161.0000 - val_accuracy: 0.9446 - val_precision: 0.0704 - val_recall: 0.1744 - val_auc: 0.7410\n",
            "Epoch 91/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.2645 - tp: 354.0000 - fp: 2989.0000 - tn: 18637.0000 - fn: 36.0000 - accuracy: 0.8626 - precision: 0.1059 - recall: 0.9077 - auc: 0.9559 - val_loss: 0.2446 - val_tp: 52.0000 - val_fp: 813.0000 - val_tn: 10000.0000 - val_fn: 143.0000 - val_accuracy: 0.9132 - val_precision: 0.0601 - val_recall: 0.2667 - val_auc: 0.7189\n",
            "Epoch 92/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.2552 - tp: 354.0000 - fp: 2751.0000 - tn: 18871.0000 - fn: 40.0000 - accuracy: 0.8732 - precision: 0.1140 - recall: 0.8985 - auc: 0.9598 - val_loss: 0.0974 - val_tp: 0.0000e+00 - val_fp: 7.0000 - val_tn: 10806.0000 - val_fn: 195.0000 - val_accuracy: 0.9816 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6699\n",
            "Epoch 93/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.2320 - tp: 358.0000 - fp: 2539.0000 - tn: 19085.0000 - fn: 34.0000 - accuracy: 0.8831 - precision: 0.1236 - recall: 0.9133 - auc: 0.9671 - val_loss: 0.0999 - val_tp: 5.0000 - val_fp: 57.0000 - val_tn: 10756.0000 - val_fn: 190.0000 - val_accuracy: 0.9776 - val_precision: 0.0806 - val_recall: 0.0256 - val_auc: 0.6920\n",
            "Epoch 94/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.2121 - tp: 359.0000 - fp: 2453.0000 - tn: 19172.0000 - fn: 32.0000 - accuracy: 0.8871 - precision: 0.1277 - recall: 0.9182 - auc: 0.9731 - val_loss: 0.1068 - val_tp: 9.0000 - val_fp: 86.0000 - val_tn: 10727.0000 - val_fn: 186.0000 - val_accuracy: 0.9753 - val_precision: 0.0947 - val_recall: 0.0462 - val_auc: 0.6885\n",
            "Epoch 95/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.2056 - tp: 361.0000 - fp: 2208.0000 - tn: 19419.0000 - fn: 28.0000 - accuracy: 0.8984 - precision: 0.1405 - recall: 0.9280 - auc: 0.9749 - val_loss: 0.0991 - val_tp: 4.0000 - val_fp: 31.0000 - val_tn: 10782.0000 - val_fn: 191.0000 - val_accuracy: 0.9798 - val_precision: 0.1143 - val_recall: 0.0205 - val_auc: 0.6663\n",
            "Epoch 96/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.2056 - tp: 359.0000 - fp: 2311.0000 - tn: 19312.0000 - fn: 34.0000 - accuracy: 0.8935 - precision: 0.1345 - recall: 0.9135 - auc: 0.9746 - val_loss: 0.1002 - val_tp: 5.0000 - val_fp: 45.0000 - val_tn: 10768.0000 - val_fn: 190.0000 - val_accuracy: 0.9787 - val_precision: 0.1000 - val_recall: 0.0256 - val_auc: 0.6867\n",
            "Epoch 97/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.1965 - tp: 362.0000 - fp: 2269.0000 - tn: 19354.0000 - fn: 31.0000 - accuracy: 0.8955 - precision: 0.1376 - recall: 0.9211 - auc: 0.9773 - val_loss: 0.0986 - val_tp: 4.0000 - val_fp: 26.0000 - val_tn: 10787.0000 - val_fn: 191.0000 - val_accuracy: 0.9803 - val_precision: 0.1333 - val_recall: 0.0205 - val_auc: 0.6793\n",
            "Epoch 98/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.1964 - tp: 368.0000 - fp: 2345.0000 - tn: 19278.0000 - fn: 25.0000 - accuracy: 0.8924 - precision: 0.1356 - recall: 0.9364 - auc: 0.9773 - val_loss: 0.1013 - val_tp: 8.0000 - val_fp: 65.0000 - val_tn: 10748.0000 - val_fn: 187.0000 - val_accuracy: 0.9771 - val_precision: 0.1096 - val_recall: 0.0410 - val_auc: 0.6945\n",
            "Epoch 99/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.2097 - tp: 349.0000 - fp: 2301.0000 - tn: 19325.0000 - fn: 41.0000 - accuracy: 0.8936 - precision: 0.1317 - recall: 0.8949 - auc: 0.9724 - val_loss: 0.1107 - val_tp: 1.0000 - val_fp: 11.0000 - val_tn: 10802.0000 - val_fn: 194.0000 - val_accuracy: 0.9814 - val_precision: 0.0833 - val_recall: 0.0051 - val_auc: 0.6517\n",
            "Epoch 100/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.2401 - tp: 343.0000 - fp: 2710.0000 - tn: 18913.0000 - fn: 50.0000 - accuracy: 0.8746 - precision: 0.1123 - recall: 0.8728 - auc: 0.9630 - val_loss: 0.1042 - val_tp: 3.0000 - val_fp: 75.0000 - val_tn: 10738.0000 - val_fn: 192.0000 - val_accuracy: 0.9757 - val_precision: 0.0385 - val_recall: 0.0154 - val_auc: 0.7144\n",
            "Epoch 1/100\n",
            " 2/86 [..............................] - ETA: 6s - loss: 2.0731 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 502.0000 - fn: 10.0000 - accuracy: 0.9805 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6911WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0169s vs `on_train_batch_end` time: 0.1146s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0169s vs `on_train_batch_end` time: 0.1146s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "86/86 [==============================] - ETA: 0s - loss: 2.0540 - tp: 1.0000 - fp: 26.0000 - tn: 21600.0000 - fn: 389.0000 - accuracy: 0.9812 - precision: 0.0370 - recall: 0.0026 - auc: 0.5553WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0047s vs `on_test_batch_end` time: 0.0588s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0047s vs `on_test_batch_end` time: 0.0588s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r86/86 [==============================] - 25s 296ms/step - loss: 2.0540 - tp: 1.0000 - fp: 26.0000 - tn: 21600.0000 - fn: 389.0000 - accuracy: 0.9812 - precision: 0.0370 - recall: 0.0026 - auc: 0.5553 - val_loss: 0.0881 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 10815.0000 - val_fn: 193.0000 - val_accuracy: 0.9825 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5843\n",
            "Epoch 2/100\n",
            "86/86 [==============================] - 15s 174ms/step - loss: 1.5814 - tp: 23.0000 - fp: 694.0000 - tn: 20928.0000 - fn: 371.0000 - accuracy: 0.9516 - precision: 0.0321 - recall: 0.0584 - auc: 0.6485 - val_loss: 0.1895 - val_tp: 2.0000 - val_fp: 24.0000 - val_tn: 10791.0000 - val_fn: 191.0000 - val_accuracy: 0.9805 - val_precision: 0.0769 - val_recall: 0.0104 - val_auc: 0.6988\n",
            "Epoch 3/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 1.0296 - tp: 140.0000 - fp: 3886.0000 - tn: 17738.0000 - fn: 252.0000 - accuracy: 0.8120 - precision: 0.0348 - recall: 0.3571 - auc: 0.6863 - val_loss: 0.1360 - val_tp: 15.0000 - val_fp: 94.0000 - val_tn: 10721.0000 - val_fn: 178.0000 - val_accuracy: 0.9753 - val_precision: 0.1376 - val_recall: 0.0777 - val_auc: 0.7271\n",
            "Epoch 4/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.8189 - tp: 196.0000 - fp: 5144.0000 - tn: 16482.0000 - fn: 194.0000 - accuracy: 0.7575 - precision: 0.0367 - recall: 0.5026 - auc: 0.7040 - val_loss: 0.3814 - val_tp: 84.0000 - val_fp: 1343.0000 - val_tn: 9472.0000 - val_fn: 109.0000 - val_accuracy: 0.8681 - val_precision: 0.0589 - val_recall: 0.4352 - val_auc: 0.7416\n",
            "Epoch 5/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.7171 - tp: 225.0000 - fp: 6255.0000 - tn: 15370.0000 - fn: 166.0000 - accuracy: 0.7083 - precision: 0.0347 - recall: 0.5754 - auc: 0.7112 - val_loss: 0.2139 - val_tp: 53.0000 - val_fp: 672.0000 - val_tn: 10143.0000 - val_fn: 140.0000 - val_accuracy: 0.9262 - val_precision: 0.0731 - val_recall: 0.2746 - val_auc: 0.7244\n",
            "Epoch 6/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.7320 - tp: 225.0000 - fp: 5589.0000 - tn: 16034.0000 - fn: 168.0000 - accuracy: 0.7385 - precision: 0.0387 - recall: 0.5725 - auc: 0.7206 - val_loss: 0.3537 - val_tp: 91.0000 - val_fp: 1506.0000 - val_tn: 9309.0000 - val_fn: 102.0000 - val_accuracy: 0.8539 - val_precision: 0.0570 - val_recall: 0.4715 - val_auc: 0.7774\n",
            "Epoch 7/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.7340 - tp: 222.0000 - fp: 5743.0000 - tn: 15884.0000 - fn: 167.0000 - accuracy: 0.7316 - precision: 0.0372 - recall: 0.5707 - auc: 0.7172 - val_loss: 0.1499 - val_tp: 21.0000 - val_fp: 224.0000 - val_tn: 10591.0000 - val_fn: 172.0000 - val_accuracy: 0.9640 - val_precision: 0.0857 - val_recall: 0.1088 - val_auc: 0.6696\n",
            "Epoch 8/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.6078 - tp: 260.0000 - fp: 6943.0000 - tn: 14683.0000 - fn: 130.0000 - accuracy: 0.6787 - precision: 0.0361 - recall: 0.6667 - auc: 0.7426 - val_loss: 0.3569 - val_tp: 84.0000 - val_fp: 2198.0000 - val_tn: 8617.0000 - val_fn: 109.0000 - val_accuracy: 0.7904 - val_precision: 0.0368 - val_recall: 0.4352 - val_auc: 0.7212\n",
            "Epoch 9/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.6371 - tp: 246.0000 - fp: 6748.0000 - tn: 14875.0000 - fn: 147.0000 - accuracy: 0.6868 - precision: 0.0352 - recall: 0.6260 - auc: 0.7287 - val_loss: 0.6246 - val_tp: 146.0000 - val_fp: 4025.0000 - val_tn: 6790.0000 - val_fn: 47.0000 - val_accuracy: 0.6301 - val_precision: 0.0350 - val_recall: 0.7565 - val_auc: 0.7893\n",
            "Epoch 10/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.6039 - tp: 263.0000 - fp: 7059.0000 - tn: 14566.0000 - fn: 128.0000 - accuracy: 0.6736 - precision: 0.0359 - recall: 0.6726 - auc: 0.7420 - val_loss: 0.2106 - val_tp: 42.0000 - val_fp: 596.0000 - val_tn: 10219.0000 - val_fn: 151.0000 - val_accuracy: 0.9321 - val_precision: 0.0658 - val_recall: 0.2176 - val_auc: 0.6706\n",
            "Epoch 11/100\n",
            "86/86 [==============================] - 15s 172ms/step - loss: 0.5895 - tp: 264.0000 - fp: 7053.0000 - tn: 14570.0000 - fn: 129.0000 - accuracy: 0.6738 - precision: 0.0361 - recall: 0.6718 - auc: 0.7569 - val_loss: 0.2828 - val_tp: 55.0000 - val_fp: 1190.0000 - val_tn: 9625.0000 - val_fn: 138.0000 - val_accuracy: 0.8794 - val_precision: 0.0442 - val_recall: 0.2850 - val_auc: 0.6448\n",
            "Epoch 12/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.6096 - tp: 257.0000 - fp: 6105.0000 - tn: 15517.0000 - fn: 137.0000 - accuracy: 0.7165 - precision: 0.0404 - recall: 0.6523 - auc: 0.7595 - val_loss: 0.4932 - val_tp: 111.0000 - val_fp: 3074.0000 - val_tn: 7741.0000 - val_fn: 82.0000 - val_accuracy: 0.7133 - val_precision: 0.0349 - val_recall: 0.5751 - val_auc: 0.7441\n",
            "Epoch 13/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5881 - tp: 259.0000 - fp: 6720.0000 - tn: 14904.0000 - fn: 133.0000 - accuracy: 0.6887 - precision: 0.0371 - recall: 0.6607 - auc: 0.7570 - val_loss: 0.5964 - val_tp: 153.0000 - val_fp: 4238.0000 - val_tn: 6577.0000 - val_fn: 40.0000 - val_accuracy: 0.6114 - val_precision: 0.0348 - val_recall: 0.7927 - val_auc: 0.7895\n",
            "Epoch 14/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.5731 - tp: 283.0000 - fp: 6883.0000 - tn: 14743.0000 - fn: 107.0000 - accuracy: 0.6825 - precision: 0.0395 - recall: 0.7256 - auc: 0.7753 - val_loss: 0.3188 - val_tp: 69.0000 - val_fp: 1577.0000 - val_tn: 9238.0000 - val_fn: 124.0000 - val_accuracy: 0.8455 - val_precision: 0.0419 - val_recall: 0.3575 - val_auc: 0.6784\n",
            "Epoch 15/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.5654 - tp: 281.0000 - fp: 6775.0000 - tn: 14847.0000 - fn: 113.0000 - accuracy: 0.6871 - precision: 0.0398 - recall: 0.7132 - auc: 0.7796 - val_loss: 0.2829 - val_tp: 71.0000 - val_fp: 1427.0000 - val_tn: 9388.0000 - val_fn: 122.0000 - val_accuracy: 0.8593 - val_precision: 0.0474 - val_recall: 0.3679 - val_auc: 0.7239\n",
            "Epoch 16/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5808 - tp: 273.0000 - fp: 6612.0000 - tn: 15013.0000 - fn: 118.0000 - accuracy: 0.6943 - precision: 0.0397 - recall: 0.6982 - auc: 0.7754 - val_loss: 0.3234 - val_tp: 85.0000 - val_fp: 1843.0000 - val_tn: 8972.0000 - val_fn: 108.0000 - val_accuracy: 0.8228 - val_precision: 0.0441 - val_recall: 0.4404 - val_auc: 0.7435\n",
            "Epoch 17/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5800 - tp: 265.0000 - fp: 6213.0000 - tn: 15412.0000 - fn: 126.0000 - accuracy: 0.7121 - precision: 0.0409 - recall: 0.6777 - auc: 0.7786 - val_loss: 0.3829 - val_tp: 96.0000 - val_fp: 2389.0000 - val_tn: 8426.0000 - val_fn: 97.0000 - val_accuracy: 0.7742 - val_precision: 0.0386 - val_recall: 0.4974 - val_auc: 0.7488\n",
            "Epoch 18/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5697 - tp: 269.0000 - fp: 6225.0000 - tn: 15397.0000 - fn: 125.0000 - accuracy: 0.7116 - precision: 0.0414 - recall: 0.6827 - auc: 0.7845 - val_loss: 0.5409 - val_tp: 131.0000 - val_fp: 3620.0000 - val_tn: 7195.0000 - val_fn: 62.0000 - val_accuracy: 0.6655 - val_precision: 0.0349 - val_recall: 0.6788 - val_auc: 0.7702\n",
            "Epoch 19/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5591 - tp: 284.0000 - fp: 6562.0000 - tn: 15061.0000 - fn: 109.0000 - accuracy: 0.6970 - precision: 0.0415 - recall: 0.7226 - auc: 0.7769 - val_loss: 0.2454 - val_tp: 58.0000 - val_fp: 946.0000 - val_tn: 9869.0000 - val_fn: 135.0000 - val_accuracy: 0.9018 - val_precision: 0.0578 - val_recall: 0.3005 - val_auc: 0.6949\n",
            "Epoch 20/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5581 - tp: 285.0000 - fp: 6709.0000 - tn: 14914.0000 - fn: 108.0000 - accuracy: 0.6904 - precision: 0.0407 - recall: 0.7252 - auc: 0.7796 - val_loss: 0.8082 - val_tp: 179.0000 - val_fp: 5824.0000 - val_tn: 4991.0000 - val_fn: 14.0000 - val_accuracy: 0.4697 - val_precision: 0.0298 - val_recall: 0.9275 - val_auc: 0.7913\n",
            "Epoch 21/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5512 - tp: 282.0000 - fp: 6669.0000 - tn: 14956.0000 - fn: 109.0000 - accuracy: 0.6921 - precision: 0.0406 - recall: 0.7212 - auc: 0.7841 - val_loss: 0.2534 - val_tp: 47.0000 - val_fp: 697.0000 - val_tn: 10118.0000 - val_fn: 146.0000 - val_accuracy: 0.9234 - val_precision: 0.0632 - val_recall: 0.2435 - val_auc: 0.6504\n",
            "Epoch 22/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.6267 - tp: 250.0000 - fp: 5932.0000 - tn: 15694.0000 - fn: 140.0000 - accuracy: 0.7242 - precision: 0.0404 - recall: 0.6410 - auc: 0.7618 - val_loss: 0.5595 - val_tp: 125.0000 - val_fp: 2845.0000 - val_tn: 7970.0000 - val_fn: 68.0000 - val_accuracy: 0.7354 - val_precision: 0.0421 - val_recall: 0.6477 - val_auc: 0.7729\n",
            "Epoch 23/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.6876 - tp: 255.0000 - fp: 5745.0000 - tn: 15875.0000 - fn: 141.0000 - accuracy: 0.7326 - precision: 0.0425 - recall: 0.6439 - auc: 0.7541 - val_loss: 0.9432 - val_tp: 144.0000 - val_fp: 4417.0000 - val_tn: 6398.0000 - val_fn: 49.0000 - val_accuracy: 0.5943 - val_precision: 0.0316 - val_recall: 0.7461 - val_auc: 0.7269\n",
            "Epoch 24/100\n",
            "86/86 [==============================] - 15s 172ms/step - loss: 0.5893 - tp: 270.0000 - fp: 6520.0000 - tn: 15102.0000 - fn: 124.0000 - accuracy: 0.6982 - precision: 0.0398 - recall: 0.6853 - auc: 0.7676 - val_loss: 0.4052 - val_tp: 102.0000 - val_fp: 2169.0000 - val_tn: 8646.0000 - val_fn: 91.0000 - val_accuracy: 0.7947 - val_precision: 0.0449 - val_recall: 0.5285 - val_auc: 0.7835\n",
            "Epoch 25/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.6334 - tp: 271.0000 - fp: 6261.0000 - tn: 15365.0000 - fn: 119.0000 - accuracy: 0.7102 - precision: 0.0415 - recall: 0.6949 - auc: 0.7657 - val_loss: 0.6323 - val_tp: 118.0000 - val_fp: 3031.0000 - val_tn: 7784.0000 - val_fn: 75.0000 - val_accuracy: 0.7178 - val_precision: 0.0375 - val_recall: 0.6114 - val_auc: 0.7143\n",
            "Epoch 26/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.6113 - tp: 263.0000 - fp: 6385.0000 - tn: 15238.0000 - fn: 130.0000 - accuracy: 0.7041 - precision: 0.0396 - recall: 0.6692 - auc: 0.7588 - val_loss: 0.2767 - val_tp: 75.0000 - val_fp: 843.0000 - val_tn: 9972.0000 - val_fn: 118.0000 - val_accuracy: 0.9127 - val_precision: 0.0817 - val_recall: 0.3886 - val_auc: 0.8065\n",
            "Epoch 27/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5649 - tp: 279.0000 - fp: 6463.0000 - tn: 15161.0000 - fn: 113.0000 - accuracy: 0.7013 - precision: 0.0414 - recall: 0.7117 - auc: 0.7849 - val_loss: 0.5949 - val_tp: 137.0000 - val_fp: 3353.0000 - val_tn: 7462.0000 - val_fn: 56.0000 - val_accuracy: 0.6903 - val_precision: 0.0393 - val_recall: 0.7098 - val_auc: 0.7942\n",
            "Epoch 28/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5587 - tp: 284.0000 - fp: 6740.0000 - tn: 14885.0000 - fn: 107.0000 - accuracy: 0.6890 - precision: 0.0404 - recall: 0.7263 - auc: 0.7804 - val_loss: 0.3676 - val_tp: 97.0000 - val_fp: 1372.0000 - val_tn: 9443.0000 - val_fn: 96.0000 - val_accuracy: 0.8666 - val_precision: 0.0660 - val_recall: 0.5026 - val_auc: 0.7980\n",
            "Epoch 29/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.5428 - tp: 293.0000 - fp: 6593.0000 - tn: 15031.0000 - fn: 99.0000 - accuracy: 0.6960 - precision: 0.0426 - recall: 0.7474 - auc: 0.7997 - val_loss: 0.3893 - val_tp: 100.0000 - val_fp: 1450.0000 - val_tn: 9365.0000 - val_fn: 93.0000 - val_accuracy: 0.8598 - val_precision: 0.0645 - val_recall: 0.5181 - val_auc: 0.7931\n",
            "Epoch 30/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5364 - tp: 307.0000 - fp: 6218.0000 - tn: 15403.0000 - fn: 88.0000 - accuracy: 0.7136 - precision: 0.0470 - recall: 0.7772 - auc: 0.8072 - val_loss: 0.3263 - val_tp: 90.0000 - val_fp: 1035.0000 - val_tn: 9780.0000 - val_fn: 103.0000 - val_accuracy: 0.8966 - val_precision: 0.0800 - val_recall: 0.4663 - val_auc: 0.8027\n",
            "Epoch 31/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5318 - tp: 296.0000 - fp: 6410.0000 - tn: 15212.0000 - fn: 98.0000 - accuracy: 0.7044 - precision: 0.0441 - recall: 0.7513 - auc: 0.8075 - val_loss: 0.3936 - val_tp: 101.0000 - val_fp: 1402.0000 - val_tn: 9413.0000 - val_fn: 92.0000 - val_accuracy: 0.8643 - val_precision: 0.0672 - val_recall: 0.5233 - val_auc: 0.8039\n",
            "Epoch 32/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5583 - tp: 281.0000 - fp: 5936.0000 - tn: 15688.0000 - fn: 111.0000 - accuracy: 0.7253 - precision: 0.0452 - recall: 0.7168 - auc: 0.7979 - val_loss: 0.4337 - val_tp: 109.0000 - val_fp: 1602.0000 - val_tn: 9213.0000 - val_fn: 84.0000 - val_accuracy: 0.8468 - val_precision: 0.0637 - val_recall: 0.5648 - val_auc: 0.7987\n",
            "Epoch 33/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5366 - tp: 289.0000 - fp: 5916.0000 - tn: 15710.0000 - fn: 101.0000 - accuracy: 0.7267 - precision: 0.0466 - recall: 0.7410 - auc: 0.8086 - val_loss: 0.3475 - val_tp: 97.0000 - val_fp: 1212.0000 - val_tn: 9603.0000 - val_fn: 96.0000 - val_accuracy: 0.8812 - val_precision: 0.0741 - val_recall: 0.5026 - val_auc: 0.8015\n",
            "Epoch 34/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5394 - tp: 294.0000 - fp: 6193.0000 - tn: 15427.0000 - fn: 102.0000 - accuracy: 0.7141 - precision: 0.0453 - recall: 0.7424 - auc: 0.8029 - val_loss: 0.3456 - val_tp: 96.0000 - val_fp: 1299.0000 - val_tn: 9516.0000 - val_fn: 97.0000 - val_accuracy: 0.8732 - val_precision: 0.0688 - val_recall: 0.4974 - val_auc: 0.7971\n",
            "Epoch 35/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5377 - tp: 303.0000 - fp: 5985.0000 - tn: 15638.0000 - fn: 90.0000 - accuracy: 0.7241 - precision: 0.0482 - recall: 0.7710 - auc: 0.8196 - val_loss: 0.2411 - val_tp: 74.0000 - val_fp: 744.0000 - val_tn: 10071.0000 - val_fn: 119.0000 - val_accuracy: 0.9216 - val_precision: 0.0905 - val_recall: 0.3834 - val_auc: 0.7918\n",
            "Epoch 36/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5273 - tp: 286.0000 - fp: 6338.0000 - tn: 15289.0000 - fn: 103.0000 - accuracy: 0.7074 - precision: 0.0432 - recall: 0.7352 - auc: 0.8088 - val_loss: 0.2761 - val_tp: 77.0000 - val_fp: 815.0000 - val_tn: 10000.0000 - val_fn: 116.0000 - val_accuracy: 0.9154 - val_precision: 0.0863 - val_recall: 0.3990 - val_auc: 0.7940\n",
            "Epoch 37/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5233 - tp: 292.0000 - fp: 6175.0000 - tn: 15453.0000 - fn: 96.0000 - accuracy: 0.7152 - precision: 0.0452 - recall: 0.7526 - auc: 0.8124 - val_loss: 0.3435 - val_tp: 92.0000 - val_fp: 1302.0000 - val_tn: 9513.0000 - val_fn: 101.0000 - val_accuracy: 0.8725 - val_precision: 0.0660 - val_recall: 0.4767 - val_auc: 0.7938\n",
            "Epoch 38/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5338 - tp: 290.0000 - fp: 5952.0000 - tn: 15672.0000 - fn: 102.0000 - accuracy: 0.7250 - precision: 0.0465 - recall: 0.7398 - auc: 0.8086 - val_loss: 0.3704 - val_tp: 93.0000 - val_fp: 1252.0000 - val_tn: 9563.0000 - val_fn: 100.0000 - val_accuracy: 0.8772 - val_precision: 0.0691 - val_recall: 0.4819 - val_auc: 0.8053\n",
            "Epoch 39/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5323 - tp: 294.0000 - fp: 6392.0000 - tn: 15229.0000 - fn: 101.0000 - accuracy: 0.7051 - precision: 0.0440 - recall: 0.7443 - auc: 0.8071 - val_loss: 0.3812 - val_tp: 101.0000 - val_fp: 1305.0000 - val_tn: 9510.0000 - val_fn: 92.0000 - val_accuracy: 0.8731 - val_precision: 0.0718 - val_recall: 0.5233 - val_auc: 0.8126\n",
            "Epoch 40/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5451 - tp: 291.0000 - fp: 6469.0000 - tn: 15156.0000 - fn: 100.0000 - accuracy: 0.7016 - precision: 0.0430 - recall: 0.7442 - auc: 0.7970 - val_loss: 0.1404 - val_tp: 31.0000 - val_fp: 118.0000 - val_tn: 10697.0000 - val_fn: 162.0000 - val_accuracy: 0.9746 - val_precision: 0.2081 - val_recall: 0.1606 - val_auc: 0.8111\n",
            "Epoch 41/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5879 - tp: 281.0000 - fp: 5955.0000 - tn: 15669.0000 - fn: 111.0000 - accuracy: 0.7245 - precision: 0.0451 - recall: 0.7168 - auc: 0.7992 - val_loss: 0.3938 - val_tp: 86.0000 - val_fp: 1739.0000 - val_tn: 9076.0000 - val_fn: 107.0000 - val_accuracy: 0.8323 - val_precision: 0.0471 - val_recall: 0.4456 - val_auc: 0.7044\n",
            "Epoch 42/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5653 - tp: 274.0000 - fp: 6033.0000 - tn: 15594.0000 - fn: 115.0000 - accuracy: 0.7207 - precision: 0.0434 - recall: 0.7044 - auc: 0.7906 - val_loss: 0.3425 - val_tp: 86.0000 - val_fp: 1014.0000 - val_tn: 9801.0000 - val_fn: 107.0000 - val_accuracy: 0.8982 - val_precision: 0.0782 - val_recall: 0.4456 - val_auc: 0.7809\n",
            "Epoch 43/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5359 - tp: 294.0000 - fp: 6230.0000 - tn: 15394.0000 - fn: 98.0000 - accuracy: 0.7126 - precision: 0.0451 - recall: 0.7500 - auc: 0.8075 - val_loss: 0.3257 - val_tp: 84.0000 - val_fp: 1051.0000 - val_tn: 9764.0000 - val_fn: 109.0000 - val_accuracy: 0.8946 - val_precision: 0.0740 - val_recall: 0.4352 - val_auc: 0.8011\n",
            "Epoch 44/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5148 - tp: 291.0000 - fp: 5811.0000 - tn: 15815.0000 - fn: 99.0000 - accuracy: 0.7316 - precision: 0.0477 - recall: 0.7462 - auc: 0.8199 - val_loss: 0.2671 - val_tp: 70.0000 - val_fp: 657.0000 - val_tn: 10158.0000 - val_fn: 123.0000 - val_accuracy: 0.9291 - val_precision: 0.0963 - val_recall: 0.3627 - val_auc: 0.7981\n",
            "Epoch 45/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.5045 - tp: 302.0000 - fp: 5927.0000 - tn: 15698.0000 - fn: 89.0000 - accuracy: 0.7267 - precision: 0.0485 - recall: 0.7724 - auc: 0.8294 - val_loss: 0.2320 - val_tp: 64.0000 - val_fp: 545.0000 - val_tn: 10270.0000 - val_fn: 129.0000 - val_accuracy: 0.9388 - val_precision: 0.1051 - val_recall: 0.3316 - val_auc: 0.8056\n",
            "Epoch 46/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5168 - tp: 299.0000 - fp: 5595.0000 - tn: 16028.0000 - fn: 94.0000 - accuracy: 0.7416 - precision: 0.0507 - recall: 0.7608 - auc: 0.8345 - val_loss: 0.3093 - val_tp: 78.0000 - val_fp: 915.0000 - val_tn: 9900.0000 - val_fn: 115.0000 - val_accuracy: 0.9064 - val_precision: 0.0785 - val_recall: 0.4041 - val_auc: 0.7943\n",
            "Epoch 47/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.4800 - tp: 309.0000 - fp: 5444.0000 - tn: 16181.0000 - fn: 82.0000 - accuracy: 0.7490 - precision: 0.0537 - recall: 0.7903 - auc: 0.8495 - val_loss: 0.3034 - val_tp: 78.0000 - val_fp: 800.0000 - val_tn: 10015.0000 - val_fn: 115.0000 - val_accuracy: 0.9169 - val_precision: 0.0888 - val_recall: 0.4041 - val_auc: 0.8040\n",
            "Epoch 48/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4743 - tp: 311.0000 - fp: 5646.0000 - tn: 15977.0000 - fn: 82.0000 - accuracy: 0.7398 - precision: 0.0522 - recall: 0.7913 - auc: 0.8499 - val_loss: 0.3088 - val_tp: 79.0000 - val_fp: 823.0000 - val_tn: 9992.0000 - val_fn: 114.0000 - val_accuracy: 0.9149 - val_precision: 0.0876 - val_recall: 0.4093 - val_auc: 0.7981\n",
            "Epoch 49/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.4652 - tp: 320.0000 - fp: 5534.0000 - tn: 16089.0000 - fn: 73.0000 - accuracy: 0.7453 - precision: 0.0547 - recall: 0.8142 - auc: 0.8602 - val_loss: 0.2667 - val_tp: 67.0000 - val_fp: 595.0000 - val_tn: 10220.0000 - val_fn: 126.0000 - val_accuracy: 0.9345 - val_precision: 0.1012 - val_recall: 0.3472 - val_auc: 0.7946\n",
            "Epoch 50/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.4820 - tp: 303.0000 - fp: 5552.0000 - tn: 16073.0000 - fn: 88.0000 - accuracy: 0.7438 - precision: 0.0518 - recall: 0.7749 - auc: 0.8439 - val_loss: 0.3639 - val_tp: 91.0000 - val_fp: 1137.0000 - val_tn: 9678.0000 - val_fn: 102.0000 - val_accuracy: 0.8874 - val_precision: 0.0741 - val_recall: 0.4715 - val_auc: 0.7868\n",
            "Epoch 51/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4650 - tp: 308.0000 - fp: 5392.0000 - tn: 16231.0000 - fn: 85.0000 - accuracy: 0.7512 - precision: 0.0540 - recall: 0.7837 - auc: 0.8591 - val_loss: 0.3276 - val_tp: 83.0000 - val_fp: 954.0000 - val_tn: 9861.0000 - val_fn: 110.0000 - val_accuracy: 0.9033 - val_precision: 0.0800 - val_recall: 0.4301 - val_auc: 0.7897\n",
            "Epoch 52/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4781 - tp: 298.0000 - fp: 5532.0000 - tn: 16094.0000 - fn: 92.0000 - accuracy: 0.7445 - precision: 0.0511 - recall: 0.7641 - auc: 0.8452 - val_loss: 0.3327 - val_tp: 83.0000 - val_fp: 872.0000 - val_tn: 9943.0000 - val_fn: 110.0000 - val_accuracy: 0.9108 - val_precision: 0.0869 - val_recall: 0.4301 - val_auc: 0.7756\n",
            "Epoch 53/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.4729 - tp: 304.0000 - fp: 5263.0000 - tn: 16361.0000 - fn: 88.0000 - accuracy: 0.7569 - precision: 0.0546 - recall: 0.7755 - auc: 0.8537 - val_loss: 0.5307 - val_tp: 115.0000 - val_fp: 2298.0000 - val_tn: 8517.0000 - val_fn: 78.0000 - val_accuracy: 0.7842 - val_precision: 0.0477 - val_recall: 0.5959 - val_auc: 0.7627\n",
            "Epoch 54/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4818 - tp: 304.0000 - fp: 5522.0000 - tn: 16102.0000 - fn: 88.0000 - accuracy: 0.7452 - precision: 0.0522 - recall: 0.7755 - auc: 0.8460 - val_loss: 0.1411 - val_tp: 28.0000 - val_fp: 204.0000 - val_tn: 10611.0000 - val_fn: 165.0000 - val_accuracy: 0.9665 - val_precision: 0.1207 - val_recall: 0.1451 - val_auc: 0.7896\n",
            "Epoch 55/100\n",
            "86/86 [==============================] - 15s 177ms/step - loss: 0.4858 - tp: 294.0000 - fp: 5559.0000 - tn: 16066.0000 - fn: 97.0000 - accuracy: 0.7431 - precision: 0.0502 - recall: 0.7519 - auc: 0.8438 - val_loss: 0.5577 - val_tp: 111.0000 - val_fp: 2559.0000 - val_tn: 8256.0000 - val_fn: 82.0000 - val_accuracy: 0.7601 - val_precision: 0.0416 - val_recall: 0.5751 - val_auc: 0.7453\n",
            "Epoch 56/100\n",
            "86/86 [==============================] - 15s 178ms/step - loss: 0.4760 - tp: 304.0000 - fp: 5278.0000 - tn: 16345.0000 - fn: 89.0000 - accuracy: 0.7562 - precision: 0.0545 - recall: 0.7735 - auc: 0.8529 - val_loss: 0.5081 - val_tp: 120.0000 - val_fp: 2618.0000 - val_tn: 8197.0000 - val_fn: 73.0000 - val_accuracy: 0.7555 - val_precision: 0.0438 - val_recall: 0.6218 - val_auc: 0.7744\n",
            "Epoch 57/100\n",
            "86/86 [==============================] - 15s 177ms/step - loss: 0.5050 - tp: 299.0000 - fp: 5439.0000 - tn: 16182.0000 - fn: 96.0000 - accuracy: 0.7486 - precision: 0.0521 - recall: 0.7570 - auc: 0.8358 - val_loss: 0.3510 - val_tp: 85.0000 - val_fp: 1014.0000 - val_tn: 9801.0000 - val_fn: 108.0000 - val_accuracy: 0.8981 - val_precision: 0.0773 - val_recall: 0.4404 - val_auc: 0.7533\n",
            "Epoch 1/100\n",
            " 2/86 [..............................] - ETA: 6s - loss: 2.1711 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 503.0000 - fn: 9.0000 - accuracy: 0.9824 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4452WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0110s vs `on_train_batch_end` time: 0.1200s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0110s vs `on_train_batch_end` time: 0.1200s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "86/86 [==============================] - ETA: 0s - loss: 1.9092 - tp: 0.0000e+00 - fp: 49.0000 - tn: 21579.0000 - fn: 388.0000 - accuracy: 0.9802 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5678WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0047s vs `on_test_batch_end` time: 0.0576s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0047s vs `on_test_batch_end` time: 0.0576s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r86/86 [==============================] - 25s 288ms/step - loss: 1.9092 - tp: 0.0000e+00 - fp: 49.0000 - tn: 21579.0000 - fn: 388.0000 - accuracy: 0.9802 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5678 - val_loss: 0.0883 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 10813.0000 - val_fn: 195.0000 - val_accuracy: 0.9823 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6448\n",
            "Epoch 2/100\n",
            "86/86 [==============================] - 15s 172ms/step - loss: 1.4046 - tp: 43.0000 - fp: 902.0000 - tn: 20723.0000 - fn: 348.0000 - accuracy: 0.9432 - precision: 0.0455 - recall: 0.1100 - auc: 0.6556 - val_loss: 0.0934 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 10813.0000 - val_fn: 195.0000 - val_accuracy: 0.9823 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6764\n",
            "Epoch 3/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.9478 - tp: 157.0000 - fp: 3763.0000 - tn: 17862.0000 - fn: 234.0000 - accuracy: 0.8185 - precision: 0.0401 - recall: 0.4015 - auc: 0.7003 - val_loss: 0.0903 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 10812.0000 - val_fn: 195.0000 - val_accuracy: 0.9822 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7179\n",
            "Epoch 4/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.8092 - tp: 204.0000 - fp: 5794.0000 - tn: 15836.0000 - fn: 182.0000 - accuracy: 0.7286 - precision: 0.0340 - recall: 0.5285 - auc: 0.6928 - val_loss: 0.1502 - val_tp: 23.0000 - val_fp: 304.0000 - val_tn: 10509.0000 - val_fn: 172.0000 - val_accuracy: 0.9568 - val_precision: 0.0703 - val_recall: 0.1179 - val_auc: 0.7646\n",
            "Epoch 5/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.7856 - tp: 205.0000 - fp: 5544.0000 - tn: 16079.0000 - fn: 188.0000 - accuracy: 0.7396 - precision: 0.0357 - recall: 0.5216 - auc: 0.7117 - val_loss: 0.4371 - val_tp: 102.0000 - val_fp: 2624.0000 - val_tn: 8189.0000 - val_fn: 93.0000 - val_accuracy: 0.7532 - val_precision: 0.0374 - val_recall: 0.5231 - val_auc: 0.7446\n",
            "Epoch 6/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.6847 - tp: 234.0000 - fp: 5663.0000 - tn: 15964.0000 - fn: 155.0000 - accuracy: 0.7357 - precision: 0.0397 - recall: 0.6015 - auc: 0.7381 - val_loss: 0.3501 - val_tp: 82.0000 - val_fp: 1209.0000 - val_tn: 9604.0000 - val_fn: 113.0000 - val_accuracy: 0.8799 - val_precision: 0.0635 - val_recall: 0.4205 - val_auc: 0.7646\n",
            "Epoch 7/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.6108 - tp: 266.0000 - fp: 6568.0000 - tn: 15059.0000 - fn: 123.0000 - accuracy: 0.6961 - precision: 0.0389 - recall: 0.6838 - auc: 0.7596 - val_loss: 0.2882 - val_tp: 38.0000 - val_fp: 559.0000 - val_tn: 10254.0000 - val_fn: 157.0000 - val_accuracy: 0.9350 - val_precision: 0.0637 - val_recall: 0.1949 - val_auc: 0.7078\n",
            "Epoch 8/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.6680 - tp: 226.0000 - fp: 5826.0000 - tn: 15802.0000 - fn: 162.0000 - accuracy: 0.7280 - precision: 0.0373 - recall: 0.5825 - auc: 0.7272 - val_loss: 0.2217 - val_tp: 32.0000 - val_fp: 458.0000 - val_tn: 10355.0000 - val_fn: 163.0000 - val_accuracy: 0.9436 - val_precision: 0.0653 - val_recall: 0.1641 - val_auc: 0.7148\n",
            "Epoch 9/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.6471 - tp: 239.0000 - fp: 6298.0000 - tn: 15327.0000 - fn: 152.0000 - accuracy: 0.7070 - precision: 0.0366 - recall: 0.6113 - auc: 0.7501 - val_loss: 0.3312 - val_tp: 76.0000 - val_fp: 1808.0000 - val_tn: 9005.0000 - val_fn: 119.0000 - val_accuracy: 0.8249 - val_precision: 0.0403 - val_recall: 0.3897 - val_auc: 0.7346\n",
            "Epoch 10/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5759 - tp: 267.0000 - fp: 6868.0000 - tn: 14759.0000 - fn: 122.0000 - accuracy: 0.6825 - precision: 0.0374 - recall: 0.6864 - auc: 0.7650 - val_loss: 0.4771 - val_tp: 101.0000 - val_fp: 2042.0000 - val_tn: 8771.0000 - val_fn: 94.0000 - val_accuracy: 0.8060 - val_precision: 0.0471 - val_recall: 0.5179 - val_auc: 0.7400\n",
            "Epoch 11/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5908 - tp: 262.0000 - fp: 6423.0000 - tn: 15202.0000 - fn: 129.0000 - accuracy: 0.7024 - precision: 0.0392 - recall: 0.6701 - auc: 0.7588 - val_loss: 0.3778 - val_tp: 90.0000 - val_fp: 1499.0000 - val_tn: 9314.0000 - val_fn: 105.0000 - val_accuracy: 0.8543 - val_precision: 0.0566 - val_recall: 0.4615 - val_auc: 0.7717\n",
            "Epoch 12/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5803 - tp: 278.0000 - fp: 6597.0000 - tn: 15030.0000 - fn: 111.0000 - accuracy: 0.6953 - precision: 0.0404 - recall: 0.7147 - auc: 0.7716 - val_loss: 0.2654 - val_tp: 64.0000 - val_fp: 1145.0000 - val_tn: 9668.0000 - val_fn: 131.0000 - val_accuracy: 0.8841 - val_precision: 0.0529 - val_recall: 0.3282 - val_auc: 0.7631\n",
            "Epoch 13/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5515 - tp: 280.0000 - fp: 6553.0000 - tn: 15070.0000 - fn: 113.0000 - accuracy: 0.6972 - precision: 0.0410 - recall: 0.7125 - auc: 0.7873 - val_loss: 0.3341 - val_tp: 77.0000 - val_fp: 1591.0000 - val_tn: 9222.0000 - val_fn: 118.0000 - val_accuracy: 0.8447 - val_precision: 0.0462 - val_recall: 0.3949 - val_auc: 0.7662\n",
            "Epoch 14/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5462 - tp: 279.0000 - fp: 6567.0000 - tn: 15061.0000 - fn: 109.0000 - accuracy: 0.6968 - precision: 0.0408 - recall: 0.7191 - auc: 0.7886 - val_loss: 0.2214 - val_tp: 46.0000 - val_fp: 815.0000 - val_tn: 9998.0000 - val_fn: 149.0000 - val_accuracy: 0.9124 - val_precision: 0.0534 - val_recall: 0.2359 - val_auc: 0.7557\n",
            "Epoch 15/100\n",
            "86/86 [==============================] - 15s 175ms/step - loss: 0.5316 - tp: 288.0000 - fp: 6784.0000 - tn: 14843.0000 - fn: 101.0000 - accuracy: 0.6873 - precision: 0.0407 - recall: 0.7404 - auc: 0.7975 - val_loss: 0.1982 - val_tp: 37.0000 - val_fp: 597.0000 - val_tn: 10216.0000 - val_fn: 158.0000 - val_accuracy: 0.9314 - val_precision: 0.0584 - val_recall: 0.1897 - val_auc: 0.7486\n",
            "Epoch 16/100\n",
            "86/86 [==============================] - 15s 175ms/step - loss: 0.5326 - tp: 300.0000 - fp: 6654.0000 - tn: 14970.0000 - fn: 92.0000 - accuracy: 0.6936 - precision: 0.0431 - recall: 0.7653 - auc: 0.8007 - val_loss: 0.2085 - val_tp: 40.0000 - val_fp: 686.0000 - val_tn: 10127.0000 - val_fn: 155.0000 - val_accuracy: 0.9236 - val_precision: 0.0551 - val_recall: 0.2051 - val_auc: 0.7391\n",
            "Epoch 17/100\n",
            "86/86 [==============================] - 15s 174ms/step - loss: 0.5348 - tp: 281.0000 - fp: 6654.0000 - tn: 14975.0000 - fn: 106.0000 - accuracy: 0.6930 - precision: 0.0405 - recall: 0.7261 - auc: 0.7949 - val_loss: 0.2013 - val_tp: 38.0000 - val_fp: 630.0000 - val_tn: 10183.0000 - val_fn: 157.0000 - val_accuracy: 0.9285 - val_precision: 0.0569 - val_recall: 0.1949 - val_auc: 0.7566\n",
            "Epoch 18/100\n",
            "86/86 [==============================] - 15s 172ms/step - loss: 0.5334 - tp: 292.0000 - fp: 6357.0000 - tn: 15270.0000 - fn: 97.0000 - accuracy: 0.7068 - precision: 0.0439 - recall: 0.7506 - auc: 0.8105 - val_loss: 0.2282 - val_tp: 43.0000 - val_fp: 760.0000 - val_tn: 10053.0000 - val_fn: 152.0000 - val_accuracy: 0.9172 - val_precision: 0.0535 - val_recall: 0.2205 - val_auc: 0.7724\n",
            "Epoch 19/100\n",
            "86/86 [==============================] - 15s 172ms/step - loss: 0.5340 - tp: 278.0000 - fp: 6275.0000 - tn: 15353.0000 - fn: 110.0000 - accuracy: 0.7100 - precision: 0.0424 - recall: 0.7165 - auc: 0.8035 - val_loss: 0.2303 - val_tp: 45.0000 - val_fp: 634.0000 - val_tn: 10179.0000 - val_fn: 150.0000 - val_accuracy: 0.9288 - val_precision: 0.0663 - val_recall: 0.2308 - val_auc: 0.7751\n",
            "Epoch 20/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5274 - tp: 285.0000 - fp: 6400.0000 - tn: 15228.0000 - fn: 103.0000 - accuracy: 0.7046 - precision: 0.0426 - recall: 0.7345 - auc: 0.8034 - val_loss: 0.1568 - val_tp: 23.0000 - val_fp: 264.0000 - val_tn: 10549.0000 - val_fn: 172.0000 - val_accuracy: 0.9604 - val_precision: 0.0801 - val_recall: 0.1179 - val_auc: 0.7593\n",
            "Epoch 21/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5515 - tp: 279.0000 - fp: 6658.0000 - tn: 14970.0000 - fn: 109.0000 - accuracy: 0.6926 - precision: 0.0402 - recall: 0.7191 - auc: 0.7832 - val_loss: 0.2372 - val_tp: 49.0000 - val_fp: 868.0000 - val_tn: 9945.0000 - val_fn: 146.0000 - val_accuracy: 0.9079 - val_precision: 0.0534 - val_recall: 0.2513 - val_auc: 0.7350\n",
            "Epoch 22/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5637 - tp: 276.0000 - fp: 6691.0000 - tn: 14931.0000 - fn: 118.0000 - accuracy: 0.6907 - precision: 0.0396 - recall: 0.7005 - auc: 0.7771 - val_loss: 0.2714 - val_tp: 61.0000 - val_fp: 1177.0000 - val_tn: 9636.0000 - val_fn: 134.0000 - val_accuracy: 0.8809 - val_precision: 0.0493 - val_recall: 0.3128 - val_auc: 0.6929\n",
            "Epoch 23/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5635 - tp: 292.0000 - fp: 6544.0000 - tn: 15080.0000 - fn: 100.0000 - accuracy: 0.6982 - precision: 0.0427 - recall: 0.7449 - auc: 0.7857 - val_loss: 0.2639 - val_tp: 62.0000 - val_fp: 1214.0000 - val_tn: 9599.0000 - val_fn: 133.0000 - val_accuracy: 0.8776 - val_precision: 0.0486 - val_recall: 0.3179 - val_auc: 0.7132\n",
            "Epoch 24/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.6037 - tp: 267.0000 - fp: 6092.0000 - tn: 15534.0000 - fn: 123.0000 - accuracy: 0.7177 - precision: 0.0420 - recall: 0.6846 - auc: 0.7846 - val_loss: 0.3654 - val_tp: 79.0000 - val_fp: 1332.0000 - val_tn: 9481.0000 - val_fn: 116.0000 - val_accuracy: 0.8685 - val_precision: 0.0560 - val_recall: 0.4051 - val_auc: 0.7777\n",
            "Epoch 25/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.6020 - tp: 272.0000 - fp: 6018.0000 - tn: 15607.0000 - fn: 119.0000 - accuracy: 0.7212 - precision: 0.0432 - recall: 0.6957 - auc: 0.7734 - val_loss: 0.5505 - val_tp: 94.0000 - val_fp: 2288.0000 - val_tn: 8525.0000 - val_fn: 101.0000 - val_accuracy: 0.7830 - val_precision: 0.0395 - val_recall: 0.4821 - val_auc: 0.6756\n",
            "Epoch 26/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5589 - tp: 277.0000 - fp: 6098.0000 - tn: 15527.0000 - fn: 114.0000 - accuracy: 0.7178 - precision: 0.0435 - recall: 0.7084 - auc: 0.7888 - val_loss: 0.2956 - val_tp: 58.0000 - val_fp: 824.0000 - val_tn: 9989.0000 - val_fn: 137.0000 - val_accuracy: 0.9127 - val_precision: 0.0658 - val_recall: 0.2974 - val_auc: 0.7878\n",
            "Epoch 27/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5642 - tp: 268.0000 - fp: 6058.0000 - tn: 15569.0000 - fn: 121.0000 - accuracy: 0.7193 - precision: 0.0424 - recall: 0.6889 - auc: 0.7868 - val_loss: 0.3198 - val_tp: 54.0000 - val_fp: 717.0000 - val_tn: 10096.0000 - val_fn: 141.0000 - val_accuracy: 0.9221 - val_precision: 0.0700 - val_recall: 0.2769 - val_auc: 0.7790\n",
            "Epoch 28/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5398 - tp: 285.0000 - fp: 6361.0000 - tn: 15263.0000 - fn: 107.0000 - accuracy: 0.7062 - precision: 0.0429 - recall: 0.7270 - auc: 0.7988 - val_loss: 0.3262 - val_tp: 54.0000 - val_fp: 704.0000 - val_tn: 10109.0000 - val_fn: 141.0000 - val_accuracy: 0.9232 - val_precision: 0.0712 - val_recall: 0.2769 - val_auc: 0.7699\n",
            "Epoch 29/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5310 - tp: 297.0000 - fp: 6202.0000 - tn: 15421.0000 - fn: 96.0000 - accuracy: 0.7139 - precision: 0.0457 - recall: 0.7557 - auc: 0.8097 - val_loss: 0.2716 - val_tp: 48.0000 - val_fp: 647.0000 - val_tn: 10166.0000 - val_fn: 147.0000 - val_accuracy: 0.9279 - val_precision: 0.0691 - val_recall: 0.2462 - val_auc: 0.7774\n",
            "Epoch 30/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5193 - tp: 303.0000 - fp: 6705.0000 - tn: 14922.0000 - fn: 86.0000 - accuracy: 0.6915 - precision: 0.0432 - recall: 0.7789 - auc: 0.8098 - val_loss: 0.2627 - val_tp: 47.0000 - val_fp: 574.0000 - val_tn: 10239.0000 - val_fn: 148.0000 - val_accuracy: 0.9344 - val_precision: 0.0757 - val_recall: 0.2410 - val_auc: 0.7803\n",
            "Epoch 31/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.5204 - tp: 292.0000 - fp: 6228.0000 - tn: 15398.0000 - fn: 98.0000 - accuracy: 0.7127 - precision: 0.0448 - recall: 0.7487 - auc: 0.8117 - val_loss: 0.2636 - val_tp: 38.0000 - val_fp: 527.0000 - val_tn: 10286.0000 - val_fn: 157.0000 - val_accuracy: 0.9379 - val_precision: 0.0673 - val_recall: 0.1949 - val_auc: 0.7730\n",
            "Epoch 32/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5067 - tp: 296.0000 - fp: 6070.0000 - tn: 15556.0000 - fn: 94.0000 - accuracy: 0.7200 - precision: 0.0465 - recall: 0.7590 - auc: 0.8240 - val_loss: 0.3400 - val_tp: 78.0000 - val_fp: 1083.0000 - val_tn: 9730.0000 - val_fn: 117.0000 - val_accuracy: 0.8910 - val_precision: 0.0672 - val_recall: 0.4000 - val_auc: 0.7797\n",
            "Epoch 33/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4986 - tp: 305.0000 - fp: 6189.0000 - tn: 15435.0000 - fn: 87.0000 - accuracy: 0.7149 - precision: 0.0470 - recall: 0.7781 - auc: 0.8310 - val_loss: 0.2800 - val_tp: 53.0000 - val_fp: 706.0000 - val_tn: 10107.0000 - val_fn: 142.0000 - val_accuracy: 0.9230 - val_precision: 0.0698 - val_recall: 0.2718 - val_auc: 0.7812\n",
            "Epoch 34/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5144 - tp: 292.0000 - fp: 6002.0000 - tn: 15623.0000 - fn: 99.0000 - accuracy: 0.7229 - precision: 0.0464 - recall: 0.7468 - auc: 0.8193 - val_loss: 0.1703 - val_tp: 15.0000 - val_fp: 170.0000 - val_tn: 10643.0000 - val_fn: 180.0000 - val_accuracy: 0.9682 - val_precision: 0.0811 - val_recall: 0.0769 - val_auc: 0.7756\n",
            "Epoch 35/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5020 - tp: 303.0000 - fp: 6102.0000 - tn: 15525.0000 - fn: 86.0000 - accuracy: 0.7189 - precision: 0.0473 - recall: 0.7789 - auc: 0.8265 - val_loss: 0.3118 - val_tp: 71.0000 - val_fp: 991.0000 - val_tn: 9822.0000 - val_fn: 124.0000 - val_accuracy: 0.8987 - val_precision: 0.0669 - val_recall: 0.3641 - val_auc: 0.7757\n",
            "Epoch 36/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5108 - tp: 298.0000 - fp: 6131.0000 - tn: 15497.0000 - fn: 90.0000 - accuracy: 0.7174 - precision: 0.0464 - recall: 0.7680 - auc: 0.8191 - val_loss: 0.2765 - val_tp: 60.0000 - val_fp: 765.0000 - val_tn: 10048.0000 - val_fn: 135.0000 - val_accuracy: 0.9182 - val_precision: 0.0727 - val_recall: 0.3077 - val_auc: 0.7854\n",
            "Epoch 37/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5122 - tp: 295.0000 - fp: 6311.0000 - tn: 15316.0000 - fn: 94.0000 - accuracy: 0.7091 - precision: 0.0447 - recall: 0.7584 - auc: 0.8166 - val_loss: 0.2011 - val_tp: 33.0000 - val_fp: 407.0000 - val_tn: 10406.0000 - val_fn: 162.0000 - val_accuracy: 0.9483 - val_precision: 0.0750 - val_recall: 0.1692 - val_auc: 0.7819\n",
            "Epoch 38/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5111 - tp: 294.0000 - fp: 5961.0000 - tn: 15664.0000 - fn: 97.0000 - accuracy: 0.7248 - precision: 0.0470 - recall: 0.7519 - auc: 0.8243 - val_loss: 0.2362 - val_tp: 53.0000 - val_fp: 682.0000 - val_tn: 10131.0000 - val_fn: 142.0000 - val_accuracy: 0.9251 - val_precision: 0.0721 - val_recall: 0.2718 - val_auc: 0.7747\n",
            "Epoch 39/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5259 - tp: 289.0000 - fp: 5996.0000 - tn: 15627.0000 - fn: 104.0000 - accuracy: 0.7229 - precision: 0.0460 - recall: 0.7354 - auc: 0.8137 - val_loss: 0.1523 - val_tp: 22.0000 - val_fp: 219.0000 - val_tn: 10594.0000 - val_fn: 173.0000 - val_accuracy: 0.9644 - val_precision: 0.0913 - val_recall: 0.1128 - val_auc: 0.7751\n",
            "Epoch 40/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5115 - tp: 297.0000 - fp: 6128.0000 - tn: 15499.0000 - fn: 92.0000 - accuracy: 0.7175 - precision: 0.0462 - recall: 0.7635 - auc: 0.8182 - val_loss: 0.2208 - val_tp: 42.0000 - val_fp: 539.0000 - val_tn: 10274.0000 - val_fn: 153.0000 - val_accuracy: 0.9371 - val_precision: 0.0723 - val_recall: 0.2154 - val_auc: 0.7805\n",
            "Epoch 41/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5080 - tp: 286.0000 - fp: 5942.0000 - tn: 15687.0000 - fn: 101.0000 - accuracy: 0.7255 - precision: 0.0459 - recall: 0.7390 - auc: 0.8219 - val_loss: 0.2673 - val_tp: 49.0000 - val_fp: 592.0000 - val_tn: 10221.0000 - val_fn: 146.0000 - val_accuracy: 0.9330 - val_precision: 0.0764 - val_recall: 0.2513 - val_auc: 0.7621\n",
            "Epoch 42/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.4909 - tp: 303.0000 - fp: 5930.0000 - tn: 15696.0000 - fn: 87.0000 - accuracy: 0.7267 - precision: 0.0486 - recall: 0.7769 - auc: 0.8340 - val_loss: 0.3905 - val_tp: 81.0000 - val_fp: 1485.0000 - val_tn: 9328.0000 - val_fn: 114.0000 - val_accuracy: 0.8547 - val_precision: 0.0517 - val_recall: 0.4154 - val_auc: 0.7486\n",
            "Epoch 43/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5047 - tp: 291.0000 - fp: 5825.0000 - tn: 15803.0000 - fn: 97.0000 - accuracy: 0.7310 - precision: 0.0476 - recall: 0.7500 - auc: 0.8244 - val_loss: 0.2980 - val_tp: 77.0000 - val_fp: 1083.0000 - val_tn: 9730.0000 - val_fn: 118.0000 - val_accuracy: 0.8909 - val_precision: 0.0664 - val_recall: 0.3949 - val_auc: 0.7747\n",
            "Epoch 44/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.4807 - tp: 309.0000 - fp: 5957.0000 - tn: 15669.0000 - fn: 81.0000 - accuracy: 0.7257 - precision: 0.0493 - recall: 0.7923 - auc: 0.8415 - val_loss: 0.2237 - val_tp: 51.0000 - val_fp: 662.0000 - val_tn: 10151.0000 - val_fn: 144.0000 - val_accuracy: 0.9268 - val_precision: 0.0715 - val_recall: 0.2615 - val_auc: 0.7774\n",
            "Epoch 45/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.4725 - tp: 303.0000 - fp: 5496.0000 - tn: 16130.0000 - fn: 87.0000 - accuracy: 0.7464 - precision: 0.0523 - recall: 0.7769 - auc: 0.8497 - val_loss: 0.2290 - val_tp: 52.0000 - val_fp: 633.0000 - val_tn: 10180.0000 - val_fn: 143.0000 - val_accuracy: 0.9295 - val_precision: 0.0759 - val_recall: 0.2667 - val_auc: 0.7740\n",
            "Epoch 46/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.4525 - tp: 306.0000 - fp: 5564.0000 - tn: 16063.0000 - fn: 83.0000 - accuracy: 0.7435 - precision: 0.0521 - recall: 0.7866 - auc: 0.8623 - val_loss: 0.3851 - val_tp: 86.0000 - val_fp: 1519.0000 - val_tn: 9294.0000 - val_fn: 109.0000 - val_accuracy: 0.8521 - val_precision: 0.0536 - val_recall: 0.4410 - val_auc: 0.7541\n",
            "Epoch 47/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4447 - tp: 319.0000 - fp: 5319.0000 - tn: 16307.0000 - fn: 71.0000 - accuracy: 0.7552 - precision: 0.0566 - recall: 0.8179 - auc: 0.8700 - val_loss: 0.2921 - val_tp: 64.0000 - val_fp: 956.0000 - val_tn: 9857.0000 - val_fn: 131.0000 - val_accuracy: 0.9013 - val_precision: 0.0627 - val_recall: 0.3282 - val_auc: 0.7650\n",
            "Epoch 48/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.4483 - tp: 316.0000 - fp: 5373.0000 - tn: 16254.0000 - fn: 73.0000 - accuracy: 0.7526 - precision: 0.0555 - recall: 0.8123 - auc: 0.8672 - val_loss: 0.2184 - val_tp: 42.0000 - val_fp: 538.0000 - val_tn: 10275.0000 - val_fn: 153.0000 - val_accuracy: 0.9372 - val_precision: 0.0724 - val_recall: 0.2154 - val_auc: 0.7707\n",
            "Epoch 49/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.4369 - tp: 332.0000 - fp: 5300.0000 - tn: 16323.0000 - fn: 61.0000 - accuracy: 0.7565 - precision: 0.0589 - recall: 0.8448 - auc: 0.8777 - val_loss: 0.2359 - val_tp: 47.0000 - val_fp: 634.0000 - val_tn: 10179.0000 - val_fn: 148.0000 - val_accuracy: 0.9290 - val_precision: 0.0690 - val_recall: 0.2410 - val_auc: 0.7664\n",
            "Epoch 50/100\n",
            "86/86 [==============================] - 15s 179ms/step - loss: 0.4306 - tp: 323.0000 - fp: 4993.0000 - tn: 16635.0000 - fn: 65.0000 - accuracy: 0.7703 - precision: 0.0608 - recall: 0.8325 - auc: 0.8802 - val_loss: 0.2212 - val_tp: 41.0000 - val_fp: 541.0000 - val_tn: 10272.0000 - val_fn: 154.0000 - val_accuracy: 0.9369 - val_precision: 0.0704 - val_recall: 0.2103 - val_auc: 0.7634\n",
            "Epoch 51/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.4507 - tp: 316.0000 - fp: 5114.0000 - tn: 16509.0000 - fn: 77.0000 - accuracy: 0.7642 - precision: 0.0582 - recall: 0.8041 - auc: 0.8675 - val_loss: 0.2012 - val_tp: 35.0000 - val_fp: 521.0000 - val_tn: 10292.0000 - val_fn: 160.0000 - val_accuracy: 0.9381 - val_precision: 0.0629 - val_recall: 0.1795 - val_auc: 0.7598\n",
            "Epoch 52/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.4230 - tp: 320.0000 - fp: 4785.0000 - tn: 16842.0000 - fn: 69.0000 - accuracy: 0.7795 - precision: 0.0627 - recall: 0.8226 - auc: 0.8838 - val_loss: 0.1731 - val_tp: 27.0000 - val_fp: 356.0000 - val_tn: 10457.0000 - val_fn: 168.0000 - val_accuracy: 0.9524 - val_precision: 0.0705 - val_recall: 0.1385 - val_auc: 0.7523\n",
            "Epoch 53/100\n",
            "86/86 [==============================] - 16s 184ms/step - loss: 0.4486 - tp: 319.0000 - fp: 5251.0000 - tn: 16375.0000 - fn: 71.0000 - accuracy: 0.7583 - precision: 0.0573 - recall: 0.8179 - auc: 0.8663 - val_loss: 0.4151 - val_tp: 98.0000 - val_fp: 1883.0000 - val_tn: 8930.0000 - val_fn: 97.0000 - val_accuracy: 0.8201 - val_precision: 0.0495 - val_recall: 0.5026 - val_auc: 0.7418\n",
            "Epoch 54/100\n",
            "86/86 [==============================] - 16s 189ms/step - loss: 0.4518 - tp: 308.0000 - fp: 5322.0000 - tn: 16307.0000 - fn: 79.0000 - accuracy: 0.7547 - precision: 0.0547 - recall: 0.7959 - auc: 0.8626 - val_loss: 0.3143 - val_tp: 66.0000 - val_fp: 1315.0000 - val_tn: 9498.0000 - val_fn: 129.0000 - val_accuracy: 0.8688 - val_precision: 0.0478 - val_recall: 0.3385 - val_auc: 0.7333\n",
            "Epoch 55/100\n",
            "86/86 [==============================] - 16s 181ms/step - loss: 0.5112 - tp: 297.0000 - fp: 5298.0000 - tn: 16326.0000 - fn: 95.0000 - accuracy: 0.7550 - precision: 0.0531 - recall: 0.7577 - auc: 0.8366 - val_loss: 0.4065 - val_tp: 96.0000 - val_fp: 1612.0000 - val_tn: 9201.0000 - val_fn: 99.0000 - val_accuracy: 0.8446 - val_precision: 0.0562 - val_recall: 0.4923 - val_auc: 0.7578\n",
            "Epoch 56/100\n",
            "86/86 [==============================] - 15s 178ms/step - loss: 0.4638 - tp: 310.0000 - fp: 5280.0000 - tn: 16349.0000 - fn: 77.0000 - accuracy: 0.7567 - precision: 0.0555 - recall: 0.8010 - auc: 0.8574 - val_loss: 0.3694 - val_tp: 80.0000 - val_fp: 1571.0000 - val_tn: 9242.0000 - val_fn: 115.0000 - val_accuracy: 0.8468 - val_precision: 0.0485 - val_recall: 0.4103 - val_auc: 0.7476\n",
            "Epoch 57/100\n",
            "86/86 [==============================] - 15s 177ms/step - loss: 0.4504 - tp: 309.0000 - fp: 5313.0000 - tn: 16314.0000 - fn: 80.0000 - accuracy: 0.7550 - precision: 0.0550 - recall: 0.7943 - auc: 0.8651 - val_loss: 0.2838 - val_tp: 71.0000 - val_fp: 1194.0000 - val_tn: 9619.0000 - val_fn: 124.0000 - val_accuracy: 0.8803 - val_precision: 0.0561 - val_recall: 0.3641 - val_auc: 0.7635\n",
            "Epoch 58/100\n",
            "86/86 [==============================] - 15s 172ms/step - loss: 0.4276 - tp: 320.0000 - fp: 4949.0000 - tn: 16678.0000 - fn: 69.0000 - accuracy: 0.7721 - precision: 0.0607 - recall: 0.8226 - auc: 0.8832 - val_loss: 0.4268 - val_tp: 107.0000 - val_fp: 2256.0000 - val_tn: 8557.0000 - val_fn: 88.0000 - val_accuracy: 0.7871 - val_precision: 0.0453 - val_recall: 0.5487 - val_auc: 0.7395\n",
            "Epoch 59/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.4192 - tp: 325.0000 - fp: 4727.0000 - tn: 16901.0000 - fn: 63.0000 - accuracy: 0.7824 - precision: 0.0643 - recall: 0.8376 - auc: 0.8869 - val_loss: 0.1873 - val_tp: 26.0000 - val_fp: 327.0000 - val_tn: 10486.0000 - val_fn: 169.0000 - val_accuracy: 0.9549 - val_precision: 0.0737 - val_recall: 0.1333 - val_auc: 0.7024\n",
            "Epoch 60/100\n",
            "86/86 [==============================] - 15s 172ms/step - loss: 0.4029 - tp: 325.0000 - fp: 4718.0000 - tn: 16908.0000 - fn: 65.0000 - accuracy: 0.7827 - precision: 0.0644 - recall: 0.8333 - auc: 0.8940 - val_loss: 0.2855 - val_tp: 55.0000 - val_fp: 1039.0000 - val_tn: 9774.0000 - val_fn: 140.0000 - val_accuracy: 0.8929 - val_precision: 0.0503 - val_recall: 0.2821 - val_auc: 0.7148\n",
            "Epoch 61/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4066 - tp: 320.0000 - fp: 4757.0000 - tn: 16870.0000 - fn: 69.0000 - accuracy: 0.7808 - precision: 0.0630 - recall: 0.8226 - auc: 0.8915 - val_loss: 0.1602 - val_tp: 17.0000 - val_fp: 273.0000 - val_tn: 10540.0000 - val_fn: 178.0000 - val_accuracy: 0.9590 - val_precision: 0.0586 - val_recall: 0.0872 - val_auc: 0.6940\n",
            "Epoch 62/100\n",
            "86/86 [==============================] - 15s 176ms/step - loss: 0.3712 - tp: 331.0000 - fp: 4477.0000 - tn: 17150.0000 - fn: 58.0000 - accuracy: 0.7940 - precision: 0.0688 - recall: 0.8509 - auc: 0.9100 - val_loss: 0.2664 - val_tp: 52.0000 - val_fp: 1065.0000 - val_tn: 9748.0000 - val_fn: 143.0000 - val_accuracy: 0.8903 - val_precision: 0.0466 - val_recall: 0.2667 - val_auc: 0.7101\n",
            "Epoch 63/100\n",
            "86/86 [==============================] - 15s 173ms/step - loss: 0.3499 - tp: 341.0000 - fp: 4045.0000 - tn: 17580.0000 - fn: 50.0000 - accuracy: 0.8140 - precision: 0.0777 - recall: 0.8721 - auc: 0.9225 - val_loss: 0.3321 - val_tp: 63.0000 - val_fp: 1532.0000 - val_tn: 9281.0000 - val_fn: 132.0000 - val_accuracy: 0.8488 - val_precision: 0.0395 - val_recall: 0.3231 - val_auc: 0.6672\n",
            "Epoch 64/100\n",
            "86/86 [==============================] - 15s 176ms/step - loss: 0.3561 - tp: 339.0000 - fp: 4049.0000 - tn: 17576.0000 - fn: 52.0000 - accuracy: 0.8137 - precision: 0.0773 - recall: 0.8670 - auc: 0.9189 - val_loss: 0.2075 - val_tp: 32.0000 - val_fp: 602.0000 - val_tn: 10211.0000 - val_fn: 163.0000 - val_accuracy: 0.9305 - val_precision: 0.0505 - val_recall: 0.1641 - val_auc: 0.6610\n",
            "Epoch 65/100\n",
            "86/86 [==============================] - 15s 173ms/step - loss: 0.3302 - tp: 340.0000 - fp: 3892.0000 - tn: 17737.0000 - fn: 47.0000 - accuracy: 0.8211 - precision: 0.0803 - recall: 0.8786 - auc: 0.9315 - val_loss: 0.2318 - val_tp: 40.0000 - val_fp: 785.0000 - val_tn: 10028.0000 - val_fn: 155.0000 - val_accuracy: 0.9146 - val_precision: 0.0485 - val_recall: 0.2051 - val_auc: 0.6539\n",
            "Epoch 66/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.3265 - tp: 350.0000 - fp: 3822.0000 - tn: 17802.0000 - fn: 42.0000 - accuracy: 0.8245 - precision: 0.0839 - recall: 0.8929 - auc: 0.9342 - val_loss: 0.2696 - val_tp: 47.0000 - val_fp: 1045.0000 - val_tn: 9768.0000 - val_fn: 148.0000 - val_accuracy: 0.8916 - val_precision: 0.0430 - val_recall: 0.2410 - val_auc: 0.6498\n",
            "Epoch 67/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.3477 - tp: 337.0000 - fp: 4175.0000 - tn: 17449.0000 - fn: 55.0000 - accuracy: 0.8079 - precision: 0.0747 - recall: 0.8597 - auc: 0.9220 - val_loss: 0.2642 - val_tp: 51.0000 - val_fp: 1076.0000 - val_tn: 9737.0000 - val_fn: 144.0000 - val_accuracy: 0.8892 - val_precision: 0.0453 - val_recall: 0.2615 - val_auc: 0.6875\n",
            "Epoch 68/100\n",
            "86/86 [==============================] - 15s 179ms/step - loss: 0.3370 - tp: 333.0000 - fp: 3807.0000 - tn: 17821.0000 - fn: 55.0000 - accuracy: 0.8246 - precision: 0.0804 - recall: 0.8582 - auc: 0.9277 - val_loss: 0.4093 - val_tp: 72.0000 - val_fp: 2036.0000 - val_tn: 8777.0000 - val_fn: 123.0000 - val_accuracy: 0.8039 - val_precision: 0.0342 - val_recall: 0.3692 - val_auc: 0.6305\n",
            "Epoch 69/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.3578 - tp: 337.0000 - fp: 4109.0000 - tn: 17514.0000 - fn: 56.0000 - accuracy: 0.8108 - precision: 0.0758 - recall: 0.8575 - auc: 0.9173 - val_loss: 0.2494 - val_tp: 46.0000 - val_fp: 939.0000 - val_tn: 9874.0000 - val_fn: 149.0000 - val_accuracy: 0.9012 - val_precision: 0.0467 - val_recall: 0.2359 - val_auc: 0.6692\n",
            "Epoch 70/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.3458 - tp: 338.0000 - fp: 3838.0000 - tn: 17790.0000 - fn: 50.0000 - accuracy: 0.8234 - precision: 0.0809 - recall: 0.8711 - auc: 0.9249 - val_loss: 0.6346 - val_tp: 116.0000 - val_fp: 3600.0000 - val_tn: 7213.0000 - val_fn: 79.0000 - val_accuracy: 0.6658 - val_precision: 0.0312 - val_recall: 0.5949 - val_auc: 0.6782\n",
            "Epoch 71/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.3652 - tp: 325.0000 - fp: 3748.0000 - tn: 17877.0000 - fn: 66.0000 - accuracy: 0.8268 - precision: 0.0798 - recall: 0.8312 - auc: 0.9163 - val_loss: 0.1099 - val_tp: 10.0000 - val_fp: 81.0000 - val_tn: 10732.0000 - val_fn: 185.0000 - val_accuracy: 0.9758 - val_precision: 0.1099 - val_recall: 0.0513 - val_auc: 0.7372\n",
            "Epoch 72/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.3910 - tp: 332.0000 - fp: 4451.0000 - tn: 17171.0000 - fn: 62.0000 - accuracy: 0.7950 - precision: 0.0694 - recall: 0.8426 - auc: 0.9025 - val_loss: 0.2436 - val_tp: 54.0000 - val_fp: 984.0000 - val_tn: 9829.0000 - val_fn: 141.0000 - val_accuracy: 0.8978 - val_precision: 0.0520 - val_recall: 0.2769 - val_auc: 0.7335\n",
            "Epoch 73/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.3597 - tp: 336.0000 - fp: 4268.0000 - tn: 17357.0000 - fn: 55.0000 - accuracy: 0.8036 - precision: 0.0730 - recall: 0.8593 - auc: 0.9155 - val_loss: 0.4715 - val_tp: 110.0000 - val_fp: 2787.0000 - val_tn: 8026.0000 - val_fn: 85.0000 - val_accuracy: 0.7391 - val_precision: 0.0380 - val_recall: 0.5641 - val_auc: 0.7209\n",
            "Epoch 74/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.3283 - tp: 342.0000 - fp: 3798.0000 - tn: 17827.0000 - fn: 49.0000 - accuracy: 0.8253 - precision: 0.0826 - recall: 0.8747 - auc: 0.9317 - val_loss: 0.2787 - val_tp: 68.0000 - val_fp: 1336.0000 - val_tn: 9477.0000 - val_fn: 127.0000 - val_accuracy: 0.8671 - val_precision: 0.0484 - val_recall: 0.3487 - val_auc: 0.7371\n",
            "Epoch 75/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.3283 - tp: 341.0000 - fp: 3676.0000 - tn: 17947.0000 - fn: 52.0000 - accuracy: 0.8307 - precision: 0.0849 - recall: 0.8677 - auc: 0.9315 - val_loss: 0.1722 - val_tp: 30.0000 - val_fp: 329.0000 - val_tn: 10484.0000 - val_fn: 165.0000 - val_accuracy: 0.9551 - val_precision: 0.0836 - val_recall: 0.1538 - val_auc: 0.7053\n",
            "Epoch 76/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.3195 - tp: 334.0000 - fp: 3482.0000 - tn: 18145.0000 - fn: 55.0000 - accuracy: 0.8393 - precision: 0.0875 - recall: 0.8586 - auc: 0.9352 - val_loss: 0.1481 - val_tp: 18.0000 - val_fp: 272.0000 - val_tn: 10541.0000 - val_fn: 177.0000 - val_accuracy: 0.9592 - val_precision: 0.0621 - val_recall: 0.0923 - val_auc: 0.6766\n",
            "Epoch 77/100\n",
            "86/86 [==============================] - 15s 173ms/step - loss: 0.2859 - tp: 346.0000 - fp: 3310.0000 - tn: 18319.0000 - fn: 41.0000 - accuracy: 0.8478 - precision: 0.0946 - recall: 0.8941 - auc: 0.9488 - val_loss: 0.2511 - val_tp: 41.0000 - val_fp: 955.0000 - val_tn: 9858.0000 - val_fn: 154.0000 - val_accuracy: 0.8993 - val_precision: 0.0412 - val_recall: 0.2103 - val_auc: 0.6316\n",
            "Epoch 78/100\n",
            "86/86 [==============================] - 15s 174ms/step - loss: 0.2770 - tp: 356.0000 - fp: 3201.0000 - tn: 18421.0000 - fn: 38.0000 - accuracy: 0.8529 - precision: 0.1001 - recall: 0.9036 - auc: 0.9528 - val_loss: 0.2440 - val_tp: 47.0000 - val_fp: 935.0000 - val_tn: 9878.0000 - val_fn: 148.0000 - val_accuracy: 0.9016 - val_precision: 0.0479 - val_recall: 0.2410 - val_auc: 0.6586\n",
            "Epoch 79/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.2723 - tp: 343.0000 - fp: 3164.0000 - tn: 18460.0000 - fn: 49.0000 - accuracy: 0.8541 - precision: 0.0978 - recall: 0.8750 - auc: 0.9537 - val_loss: 0.3110 - val_tp: 56.0000 - val_fp: 1414.0000 - val_tn: 9399.0000 - val_fn: 139.0000 - val_accuracy: 0.8589 - val_precision: 0.0381 - val_recall: 0.2872 - val_auc: 0.6506\n",
            "Epoch 80/100\n",
            "86/86 [==============================] - 15s 172ms/step - loss: 0.2506 - tp: 357.0000 - fp: 2957.0000 - tn: 18669.0000 - fn: 33.0000 - accuracy: 0.8642 - precision: 0.1077 - recall: 0.9154 - auc: 0.9625 - val_loss: 0.3088 - val_tp: 58.0000 - val_fp: 1380.0000 - val_tn: 9433.0000 - val_fn: 137.0000 - val_accuracy: 0.8622 - val_precision: 0.0403 - val_recall: 0.2974 - val_auc: 0.6457\n",
            "Epoch 81/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.2481 - tp: 357.0000 - fp: 2810.0000 - tn: 18814.0000 - fn: 35.0000 - accuracy: 0.8708 - precision: 0.1127 - recall: 0.9107 - auc: 0.9635 - val_loss: 0.2719 - val_tp: 51.0000 - val_fp: 1124.0000 - val_tn: 9689.0000 - val_fn: 144.0000 - val_accuracy: 0.8848 - val_precision: 0.0434 - val_recall: 0.2615 - val_auc: 0.6255\n",
            "Epoch 82/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.2445 - tp: 360.0000 - fp: 2749.0000 - tn: 18876.0000 - fn: 31.0000 - accuracy: 0.8737 - precision: 0.1158 - recall: 0.9207 - auc: 0.9642 - val_loss: 0.2603 - val_tp: 54.0000 - val_fp: 1056.0000 - val_tn: 9757.0000 - val_fn: 141.0000 - val_accuracy: 0.8913 - val_precision: 0.0486 - val_recall: 0.2769 - val_auc: 0.6553\n",
            "Epoch 83/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.2480 - tp: 349.0000 - fp: 2777.0000 - tn: 18848.0000 - fn: 42.0000 - accuracy: 0.8720 - precision: 0.1116 - recall: 0.8926 - auc: 0.9623 - val_loss: 0.1623 - val_tp: 22.0000 - val_fp: 357.0000 - val_tn: 10456.0000 - val_fn: 173.0000 - val_accuracy: 0.9519 - val_precision: 0.0580 - val_recall: 0.1128 - val_auc: 0.6570\n",
            "Epoch 84/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.2554 - tp: 354.0000 - fp: 2941.0000 - tn: 18683.0000 - fn: 38.0000 - accuracy: 0.8647 - precision: 0.1074 - recall: 0.9031 - auc: 0.9596 - val_loss: 0.3060 - val_tp: 59.0000 - val_fp: 1423.0000 - val_tn: 9390.0000 - val_fn: 136.0000 - val_accuracy: 0.8584 - val_precision: 0.0398 - val_recall: 0.3026 - val_auc: 0.6690\n",
            "Epoch 85/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.2624 - tp: 354.0000 - fp: 2990.0000 - tn: 18635.0000 - fn: 37.0000 - accuracy: 0.8625 - precision: 0.1059 - recall: 0.9054 - auc: 0.9577 - val_loss: 0.1281 - val_tp: 11.0000 - val_fp: 176.0000 - val_tn: 10637.0000 - val_fn: 184.0000 - val_accuracy: 0.9673 - val_precision: 0.0588 - val_recall: 0.0564 - val_auc: 0.6939\n",
            "Epoch 86/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.2952 - tp: 339.0000 - fp: 3283.0000 - tn: 18342.0000 - fn: 52.0000 - accuracy: 0.8485 - precision: 0.0936 - recall: 0.8670 - auc: 0.9443 - val_loss: 0.1629 - val_tp: 34.0000 - val_fp: 455.0000 - val_tn: 10358.0000 - val_fn: 161.0000 - val_accuracy: 0.9440 - val_precision: 0.0695 - val_recall: 0.1744 - val_auc: 0.7251\n",
            "Epoch 87/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.2845 - tp: 343.0000 - fp: 3185.0000 - tn: 18441.0000 - fn: 47.0000 - accuracy: 0.8532 - precision: 0.0972 - recall: 0.8795 - auc: 0.9488 - val_loss: 0.2118 - val_tp: 43.0000 - val_fp: 771.0000 - val_tn: 10042.0000 - val_fn: 152.0000 - val_accuracy: 0.9162 - val_precision: 0.0528 - val_recall: 0.2205 - val_auc: 0.7225\n",
            "Epoch 88/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.3208 - tp: 337.0000 - fp: 3489.0000 - tn: 18137.0000 - fn: 53.0000 - accuracy: 0.8391 - precision: 0.0881 - recall: 0.8641 - auc: 0.9359 - val_loss: 0.1117 - val_tp: 15.0000 - val_fp: 84.0000 - val_tn: 10729.0000 - val_fn: 180.0000 - val_accuracy: 0.9760 - val_precision: 0.1515 - val_recall: 0.0769 - val_auc: 0.7209\n",
            "Epoch 89/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.3087 - tp: 341.0000 - fp: 3359.0000 - tn: 18267.0000 - fn: 49.0000 - accuracy: 0.8452 - precision: 0.0922 - recall: 0.8744 - auc: 0.9399 - val_loss: 0.1769 - val_tp: 26.0000 - val_fp: 507.0000 - val_tn: 10306.0000 - val_fn: 169.0000 - val_accuracy: 0.9386 - val_precision: 0.0488 - val_recall: 0.1333 - val_auc: 0.7026\n",
            "Epoch 90/100\n",
            "86/86 [==============================] - 14s 169ms/step - loss: 0.2586 - tp: 348.0000 - fp: 2949.0000 - tn: 18679.0000 - fn: 40.0000 - accuracy: 0.8642 - precision: 0.1056 - recall: 0.8969 - auc: 0.9582 - val_loss: 0.2259 - val_tp: 51.0000 - val_fp: 825.0000 - val_tn: 9988.0000 - val_fn: 144.0000 - val_accuracy: 0.9120 - val_precision: 0.0582 - val_recall: 0.2615 - val_auc: 0.6947\n",
            "Epoch 91/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.2554 - tp: 345.0000 - fp: 2692.0000 - tn: 18937.0000 - fn: 42.0000 - accuracy: 0.8758 - precision: 0.1136 - recall: 0.8915 - auc: 0.9591 - val_loss: 0.1638 - val_tp: 26.0000 - val_fp: 426.0000 - val_tn: 10387.0000 - val_fn: 169.0000 - val_accuracy: 0.9459 - val_precision: 0.0575 - val_recall: 0.1333 - val_auc: 0.6869\n",
            "Epoch 92/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.2245 - tp: 355.0000 - fp: 2524.0000 - tn: 19100.0000 - fn: 37.0000 - accuracy: 0.8837 - precision: 0.1233 - recall: 0.9056 - auc: 0.9695 - val_loss: 0.2912 - val_tp: 51.0000 - val_fp: 1293.0000 - val_tn: 9520.0000 - val_fn: 144.0000 - val_accuracy: 0.8695 - val_precision: 0.0379 - val_recall: 0.2615 - val_auc: 0.6559\n",
            "Epoch 93/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.2136 - tp: 357.0000 - fp: 2369.0000 - tn: 19256.0000 - fn: 34.0000 - accuracy: 0.8909 - precision: 0.1310 - recall: 0.9130 - auc: 0.9726 - val_loss: 0.2714 - val_tp: 47.0000 - val_fp: 1082.0000 - val_tn: 9731.0000 - val_fn: 148.0000 - val_accuracy: 0.8883 - val_precision: 0.0416 - val_recall: 0.2410 - val_auc: 0.6293\n",
            "Epoch 94/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.1916 - tp: 364.0000 - fp: 2211.0000 - tn: 19417.0000 - fn: 24.0000 - accuracy: 0.8985 - precision: 0.1414 - recall: 0.9381 - auc: 0.9784 - val_loss: 0.1858 - val_tp: 25.0000 - val_fp: 506.0000 - val_tn: 10307.0000 - val_fn: 170.0000 - val_accuracy: 0.9386 - val_precision: 0.0471 - val_recall: 0.1282 - val_auc: 0.6430\n",
            "Epoch 95/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.2157 - tp: 352.0000 - fp: 2401.0000 - tn: 19226.0000 - fn: 37.0000 - accuracy: 0.8893 - precision: 0.1279 - recall: 0.9049 - auc: 0.9712 - val_loss: 0.1873 - val_tp: 32.0000 - val_fp: 558.0000 - val_tn: 10255.0000 - val_fn: 163.0000 - val_accuracy: 0.9345 - val_precision: 0.0542 - val_recall: 0.1641 - val_auc: 0.6556\n",
            "Epoch 96/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.2114 - tp: 354.0000 - fp: 2392.0000 - tn: 19235.0000 - fn: 35.0000 - accuracy: 0.8898 - precision: 0.1289 - recall: 0.9100 - auc: 0.9725 - val_loss: 0.1692 - val_tp: 21.0000 - val_fp: 421.0000 - val_tn: 10392.0000 - val_fn: 174.0000 - val_accuracy: 0.9459 - val_precision: 0.0475 - val_recall: 0.1077 - val_auc: 0.6387\n",
            "Epoch 97/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.1904 - tp: 364.0000 - fp: 2281.0000 - tn: 19347.0000 - fn: 24.0000 - accuracy: 0.8953 - precision: 0.1376 - recall: 0.9381 - auc: 0.9789 - val_loss: 0.1955 - val_tp: 29.0000 - val_fp: 597.0000 - val_tn: 10216.0000 - val_fn: 166.0000 - val_accuracy: 0.9307 - val_precision: 0.0463 - val_recall: 0.1487 - val_auc: 0.6377\n",
            "Epoch 1/100\n",
            " 2/86 [..............................] - ETA: 5s - loss: 2.2201 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 503.0000 - fn: 9.0000 - accuracy: 0.9824 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4010WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0112s vs `on_train_batch_end` time: 0.1102s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0112s vs `on_train_batch_end` time: 0.1102s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "86/86 [==============================] - ETA: 0s - loss: 1.9908 - tp: 1.0000 - fp: 20.0000 - tn: 21607.0000 - fn: 388.0000 - accuracy: 0.9815 - precision: 0.0476 - recall: 0.0026 - auc: 0.5592WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0049s vs `on_test_batch_end` time: 0.0619s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0049s vs `on_test_batch_end` time: 0.0619s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r86/86 [==============================] - 25s 292ms/step - loss: 1.9908 - tp: 1.0000 - fp: 20.0000 - tn: 21607.0000 - fn: 388.0000 - accuracy: 0.9815 - precision: 0.0476 - recall: 0.0026 - auc: 0.5592 - val_loss: 0.1085 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 10813.0000 - val_fn: 195.0000 - val_accuracy: 0.9823 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5098\n",
            "Epoch 2/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 1.5284 - tp: 32.0000 - fp: 874.0000 - tn: 20751.0000 - fn: 359.0000 - accuracy: 0.9440 - precision: 0.0353 - recall: 0.0818 - auc: 0.6454 - val_loss: 0.2140 - val_tp: 3.0000 - val_fp: 6.0000 - val_tn: 10807.0000 - val_fn: 192.0000 - val_accuracy: 0.9820 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.6732\n",
            "Epoch 3/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 1.0435 - tp: 135.0000 - fp: 2865.0000 - tn: 18759.0000 - fn: 257.0000 - accuracy: 0.8582 - precision: 0.0450 - recall: 0.3444 - auc: 0.7048 - val_loss: 0.0838 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 10813.0000 - val_fn: 195.0000 - val_accuracy: 0.9823 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7047\n",
            "Epoch 4/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.7809 - tp: 209.0000 - fp: 5490.0000 - tn: 16137.0000 - fn: 180.0000 - accuracy: 0.7425 - precision: 0.0367 - recall: 0.5373 - auc: 0.7142 - val_loss: 0.0910 - val_tp: 3.0000 - val_fp: 6.0000 - val_tn: 10807.0000 - val_fn: 192.0000 - val_accuracy: 0.9820 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.7651\n",
            "Epoch 5/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.7142 - tp: 223.0000 - fp: 5670.0000 - tn: 15952.0000 - fn: 171.0000 - accuracy: 0.7347 - precision: 0.0378 - recall: 0.5660 - auc: 0.7265 - val_loss: 0.7201 - val_tp: 133.0000 - val_fp: 4206.0000 - val_tn: 6607.0000 - val_fn: 62.0000 - val_accuracy: 0.6123 - val_precision: 0.0307 - val_recall: 0.6821 - val_auc: 0.7243\n",
            "Epoch 6/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.7395 - tp: 214.0000 - fp: 5528.0000 - tn: 16099.0000 - fn: 175.0000 - accuracy: 0.7410 - precision: 0.0373 - recall: 0.5501 - auc: 0.7230 - val_loss: 0.4768 - val_tp: 106.0000 - val_fp: 2139.0000 - val_tn: 8674.0000 - val_fn: 89.0000 - val_accuracy: 0.7976 - val_precision: 0.0472 - val_recall: 0.5436 - val_auc: 0.7482\n",
            "Epoch 7/100\n",
            "86/86 [==============================] - 15s 174ms/step - loss: 0.7303 - tp: 223.0000 - fp: 5843.0000 - tn: 15784.0000 - fn: 166.0000 - accuracy: 0.7271 - precision: 0.0368 - recall: 0.5733 - auc: 0.7218 - val_loss: 0.2392 - val_tp: 56.0000 - val_fp: 1011.0000 - val_tn: 9802.0000 - val_fn: 139.0000 - val_accuracy: 0.8955 - val_precision: 0.0525 - val_recall: 0.2872 - val_auc: 0.7111\n",
            "Epoch 8/100\n",
            "86/86 [==============================] - 14s 164ms/step - loss: 0.6393 - tp: 249.0000 - fp: 6202.0000 - tn: 15425.0000 - fn: 140.0000 - accuracy: 0.7119 - precision: 0.0386 - recall: 0.6401 - auc: 0.7427 - val_loss: 0.5739 - val_tp: 139.0000 - val_fp: 3248.0000 - val_tn: 7565.0000 - val_fn: 56.0000 - val_accuracy: 0.6999 - val_precision: 0.0410 - val_recall: 0.7128 - val_auc: 0.7779\n",
            "Epoch 9/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.6116 - tp: 271.0000 - fp: 6593.0000 - tn: 15028.0000 - fn: 124.0000 - accuracy: 0.6949 - precision: 0.0395 - recall: 0.6861 - auc: 0.7599 - val_loss: 0.4829 - val_tp: 128.0000 - val_fp: 2440.0000 - val_tn: 8373.0000 - val_fn: 67.0000 - val_accuracy: 0.7723 - val_precision: 0.0498 - val_recall: 0.6564 - val_auc: 0.7896\n",
            "Epoch 10/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5736 - tp: 269.0000 - fp: 6541.0000 - tn: 15083.0000 - fn: 123.0000 - accuracy: 0.6973 - precision: 0.0395 - recall: 0.6862 - auc: 0.7698 - val_loss: 0.3171 - val_tp: 89.0000 - val_fp: 1253.0000 - val_tn: 9560.0000 - val_fn: 106.0000 - val_accuracy: 0.8765 - val_precision: 0.0663 - val_recall: 0.4564 - val_auc: 0.7980\n",
            "Epoch 11/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5861 - tp: 261.0000 - fp: 6552.0000 - tn: 15073.0000 - fn: 130.0000 - accuracy: 0.6965 - precision: 0.0383 - recall: 0.6675 - auc: 0.7607 - val_loss: 0.3397 - val_tp: 85.0000 - val_fp: 1169.0000 - val_tn: 9644.0000 - val_fn: 110.0000 - val_accuracy: 0.8838 - val_precision: 0.0678 - val_recall: 0.4359 - val_auc: 0.7948\n",
            "Epoch 12/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.5619 - tp: 279.0000 - fp: 6737.0000 - tn: 14887.0000 - fn: 113.0000 - accuracy: 0.6889 - precision: 0.0398 - recall: 0.7117 - auc: 0.7799 - val_loss: 0.4171 - val_tp: 124.0000 - val_fp: 2064.0000 - val_tn: 8749.0000 - val_fn: 71.0000 - val_accuracy: 0.8061 - val_precision: 0.0567 - val_recall: 0.6359 - val_auc: 0.8031\n",
            "Epoch 13/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5509 - tp: 279.0000 - fp: 6651.0000 - tn: 14974.0000 - fn: 112.0000 - accuracy: 0.6928 - precision: 0.0403 - recall: 0.7136 - auc: 0.7892 - val_loss: 0.2505 - val_tp: 66.0000 - val_fp: 766.0000 - val_tn: 10047.0000 - val_fn: 129.0000 - val_accuracy: 0.9187 - val_precision: 0.0793 - val_recall: 0.3385 - val_auc: 0.8015\n",
            "Epoch 14/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.5591 - tp: 281.0000 - fp: 6723.0000 - tn: 14902.0000 - fn: 110.0000 - accuracy: 0.6896 - precision: 0.0401 - recall: 0.7187 - auc: 0.7822 - val_loss: 0.2258 - val_tp: 58.0000 - val_fp: 630.0000 - val_tn: 10183.0000 - val_fn: 137.0000 - val_accuracy: 0.9303 - val_precision: 0.0843 - val_recall: 0.2974 - val_auc: 0.8002\n",
            "Epoch 15/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.5456 - tp: 291.0000 - fp: 6655.0000 - tn: 14970.0000 - fn: 100.0000 - accuracy: 0.6932 - precision: 0.0419 - recall: 0.7442 - auc: 0.7930 - val_loss: 0.2382 - val_tp: 61.0000 - val_fp: 719.0000 - val_tn: 10094.0000 - val_fn: 134.0000 - val_accuracy: 0.9225 - val_precision: 0.0782 - val_recall: 0.3128 - val_auc: 0.7995\n",
            "Epoch 16/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5281 - tp: 293.0000 - fp: 6576.0000 - tn: 15050.0000 - fn: 97.0000 - accuracy: 0.6969 - precision: 0.0427 - recall: 0.7513 - auc: 0.8045 - val_loss: 0.2230 - val_tp: 52.0000 - val_fp: 576.0000 - val_tn: 10237.0000 - val_fn: 143.0000 - val_accuracy: 0.9347 - val_precision: 0.0828 - val_recall: 0.2667 - val_auc: 0.8005\n",
            "Epoch 17/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5234 - tp: 301.0000 - fp: 6489.0000 - tn: 15135.0000 - fn: 91.0000 - accuracy: 0.7011 - precision: 0.0443 - recall: 0.7679 - auc: 0.8089 - val_loss: 0.2492 - val_tp: 66.0000 - val_fp: 827.0000 - val_tn: 9986.0000 - val_fn: 129.0000 - val_accuracy: 0.9132 - val_precision: 0.0739 - val_recall: 0.3385 - val_auc: 0.7973\n",
            "Epoch 18/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5357 - tp: 297.0000 - fp: 6573.0000 - tn: 15052.0000 - fn: 94.0000 - accuracy: 0.6972 - precision: 0.0432 - recall: 0.7596 - auc: 0.8017 - val_loss: 0.1967 - val_tp: 42.0000 - val_fp: 424.0000 - val_tn: 10389.0000 - val_fn: 153.0000 - val_accuracy: 0.9476 - val_precision: 0.0901 - val_recall: 0.2154 - val_auc: 0.7986\n",
            "Epoch 19/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5420 - tp: 277.0000 - fp: 6252.0000 - tn: 15372.0000 - fn: 115.0000 - accuracy: 0.7108 - precision: 0.0424 - recall: 0.7066 - auc: 0.7956 - val_loss: 0.2447 - val_tp: 51.0000 - val_fp: 516.0000 - val_tn: 10297.0000 - val_fn: 144.0000 - val_accuracy: 0.9400 - val_precision: 0.0899 - val_recall: 0.2615 - val_auc: 0.8059\n",
            "Epoch 20/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5378 - tp: 284.0000 - fp: 6374.0000 - tn: 15250.0000 - fn: 108.0000 - accuracy: 0.7056 - precision: 0.0427 - recall: 0.7245 - auc: 0.8054 - val_loss: 0.2003 - val_tp: 45.0000 - val_fp: 445.0000 - val_tn: 10368.0000 - val_fn: 150.0000 - val_accuracy: 0.9459 - val_precision: 0.0918 - val_recall: 0.2308 - val_auc: 0.8078\n",
            "Epoch 21/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5436 - tp: 282.0000 - fp: 6535.0000 - tn: 15092.0000 - fn: 107.0000 - accuracy: 0.6983 - precision: 0.0414 - recall: 0.7249 - auc: 0.7948 - val_loss: 0.1131 - val_tp: 11.0000 - val_fp: 70.0000 - val_tn: 10743.0000 - val_fn: 184.0000 - val_accuracy: 0.9769 - val_precision: 0.1358 - val_recall: 0.0564 - val_auc: 0.7879\n",
            "Epoch 22/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5669 - tp: 279.0000 - fp: 6357.0000 - tn: 15266.0000 - fn: 114.0000 - accuracy: 0.7061 - precision: 0.0420 - recall: 0.7099 - auc: 0.7824 - val_loss: 0.2970 - val_tp: 70.0000 - val_fp: 1027.0000 - val_tn: 9786.0000 - val_fn: 125.0000 - val_accuracy: 0.8953 - val_precision: 0.0638 - val_recall: 0.3590 - val_auc: 0.7961\n",
            "Epoch 23/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.6158 - tp: 263.0000 - fp: 5993.0000 - tn: 15631.0000 - fn: 129.0000 - accuracy: 0.7219 - precision: 0.0420 - recall: 0.6709 - auc: 0.7720 - val_loss: 0.4670 - val_tp: 125.0000 - val_fp: 2363.0000 - val_tn: 8450.0000 - val_fn: 70.0000 - val_accuracy: 0.7790 - val_precision: 0.0502 - val_recall: 0.6410 - val_auc: 0.7904\n",
            "Epoch 24/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.5571 - tp: 274.0000 - fp: 6263.0000 - tn: 15363.0000 - fn: 116.0000 - accuracy: 0.7103 - precision: 0.0419 - recall: 0.7026 - auc: 0.7803 - val_loss: 0.5351 - val_tp: 141.0000 - val_fp: 3272.0000 - val_tn: 7541.0000 - val_fn: 54.0000 - val_accuracy: 0.6979 - val_precision: 0.0413 - val_recall: 0.7231 - val_auc: 0.7987\n",
            "Epoch 25/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5625 - tp: 282.0000 - fp: 7057.0000 - tn: 14568.0000 - fn: 109.0000 - accuracy: 0.6745 - precision: 0.0384 - recall: 0.7212 - auc: 0.7730 - val_loss: 0.3515 - val_tp: 93.0000 - val_fp: 1393.0000 - val_tn: 9420.0000 - val_fn: 102.0000 - val_accuracy: 0.8642 - val_precision: 0.0626 - val_recall: 0.4769 - val_auc: 0.8017\n",
            "Epoch 26/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5611 - tp: 289.0000 - fp: 6234.0000 - tn: 15389.0000 - fn: 104.0000 - accuracy: 0.7121 - precision: 0.0443 - recall: 0.7354 - auc: 0.7972 - val_loss: 0.3861 - val_tp: 88.0000 - val_fp: 1374.0000 - val_tn: 9439.0000 - val_fn: 107.0000 - val_accuracy: 0.8655 - val_precision: 0.0602 - val_recall: 0.4513 - val_auc: 0.7843\n",
            "Epoch 27/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5325 - tp: 293.0000 - fp: 6344.0000 - tn: 15283.0000 - fn: 96.0000 - accuracy: 0.7075 - precision: 0.0441 - recall: 0.7532 - auc: 0.8018 - val_loss: 0.1659 - val_tp: 20.0000 - val_fp: 132.0000 - val_tn: 10681.0000 - val_fn: 175.0000 - val_accuracy: 0.9721 - val_precision: 0.1316 - val_recall: 0.1026 - val_auc: 0.7939\n",
            "Epoch 28/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.5355 - tp: 299.0000 - fp: 6653.0000 - tn: 14967.0000 - fn: 97.0000 - accuracy: 0.6934 - precision: 0.0430 - recall: 0.7551 - auc: 0.8017 - val_loss: 0.1570 - val_tp: 23.0000 - val_fp: 133.0000 - val_tn: 10680.0000 - val_fn: 172.0000 - val_accuracy: 0.9723 - val_precision: 0.1474 - val_recall: 0.1179 - val_auc: 0.7987\n",
            "Epoch 29/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5025 - tp: 300.0000 - fp: 6282.0000 - tn: 15345.0000 - fn: 89.0000 - accuracy: 0.7106 - precision: 0.0456 - recall: 0.7712 - auc: 0.8258 - val_loss: 0.1696 - val_tp: 31.0000 - val_fp: 247.0000 - val_tn: 10566.0000 - val_fn: 164.0000 - val_accuracy: 0.9627 - val_precision: 0.1115 - val_recall: 0.1590 - val_auc: 0.7957\n",
            "Epoch 30/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5319 - tp: 295.0000 - fp: 6097.0000 - tn: 15529.0000 - fn: 95.0000 - accuracy: 0.7188 - precision: 0.0462 - recall: 0.7564 - auc: 0.8171 - val_loss: 0.2149 - val_tp: 47.0000 - val_fp: 469.0000 - val_tn: 10344.0000 - val_fn: 148.0000 - val_accuracy: 0.9439 - val_precision: 0.0911 - val_recall: 0.2410 - val_auc: 0.8029\n",
            "Epoch 31/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5069 - tp: 291.0000 - fp: 6016.0000 - tn: 15610.0000 - fn: 99.0000 - accuracy: 0.7222 - precision: 0.0461 - recall: 0.7462 - auc: 0.8251 - val_loss: 0.2369 - val_tp: 54.0000 - val_fp: 628.0000 - val_tn: 10185.0000 - val_fn: 141.0000 - val_accuracy: 0.9301 - val_precision: 0.0792 - val_recall: 0.2769 - val_auc: 0.8039\n",
            "Epoch 32/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.4885 - tp: 315.0000 - fp: 6195.0000 - tn: 15428.0000 - fn: 78.0000 - accuracy: 0.7151 - precision: 0.0484 - recall: 0.8015 - auc: 0.8367 - val_loss: 0.2279 - val_tp: 51.0000 - val_fp: 580.0000 - val_tn: 10233.0000 - val_fn: 144.0000 - val_accuracy: 0.9342 - val_precision: 0.0808 - val_recall: 0.2615 - val_auc: 0.8021\n",
            "Epoch 33/100\n",
            "86/86 [==============================] - 14s 169ms/step - loss: 0.4963 - tp: 317.0000 - fp: 6255.0000 - tn: 15368.0000 - fn: 76.0000 - accuracy: 0.7124 - precision: 0.0482 - recall: 0.8066 - auc: 0.8337 - val_loss: 0.2250 - val_tp: 52.0000 - val_fp: 579.0000 - val_tn: 10234.0000 - val_fn: 143.0000 - val_accuracy: 0.9344 - val_precision: 0.0824 - val_recall: 0.2667 - val_auc: 0.8011\n",
            "Epoch 34/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.4895 - tp: 305.0000 - fp: 6088.0000 - tn: 15540.0000 - fn: 83.0000 - accuracy: 0.7197 - precision: 0.0477 - recall: 0.7861 - auc: 0.8333 - val_loss: 0.2151 - val_tp: 53.0000 - val_fp: 572.0000 - val_tn: 10241.0000 - val_fn: 142.0000 - val_accuracy: 0.9351 - val_precision: 0.0848 - val_recall: 0.2718 - val_auc: 0.8023\n",
            "Epoch 35/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.5017 - tp: 301.0000 - fp: 6238.0000 - tn: 15390.0000 - fn: 87.0000 - accuracy: 0.7127 - precision: 0.0460 - recall: 0.7758 - auc: 0.8252 - val_loss: 0.1671 - val_tp: 33.0000 - val_fp: 283.0000 - val_tn: 10530.0000 - val_fn: 162.0000 - val_accuracy: 0.9596 - val_precision: 0.1044 - val_recall: 0.1692 - val_auc: 0.8025\n",
            "Epoch 36/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4842 - tp: 305.0000 - fp: 5962.0000 - tn: 15665.0000 - fn: 84.0000 - accuracy: 0.7254 - precision: 0.0487 - recall: 0.7841 - auc: 0.8400 - val_loss: 0.1580 - val_tp: 26.0000 - val_fp: 205.0000 - val_tn: 10608.0000 - val_fn: 169.0000 - val_accuracy: 0.9660 - val_precision: 0.1126 - val_recall: 0.1333 - val_auc: 0.8032\n",
            "Epoch 37/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5059 - tp: 292.0000 - fp: 6355.0000 - tn: 15270.0000 - fn: 99.0000 - accuracy: 0.7068 - precision: 0.0439 - recall: 0.7468 - auc: 0.8192 - val_loss: 0.3051 - val_tp: 83.0000 - val_fp: 1165.0000 - val_tn: 9648.0000 - val_fn: 112.0000 - val_accuracy: 0.8840 - val_precision: 0.0665 - val_recall: 0.4256 - val_auc: 0.8010\n",
            "Epoch 38/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5070 - tp: 301.0000 - fp: 6416.0000 - tn: 15205.0000 - fn: 94.0000 - accuracy: 0.7043 - precision: 0.0448 - recall: 0.7620 - auc: 0.8217 - val_loss: 0.3052 - val_tp: 77.0000 - val_fp: 1040.0000 - val_tn: 9773.0000 - val_fn: 118.0000 - val_accuracy: 0.8948 - val_precision: 0.0689 - val_recall: 0.3949 - val_auc: 0.8021\n",
            "Epoch 39/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.5018 - tp: 305.0000 - fp: 6339.0000 - tn: 15286.0000 - fn: 86.0000 - accuracy: 0.7082 - precision: 0.0459 - recall: 0.7801 - auc: 0.8265 - val_loss: 0.3755 - val_tp: 87.0000 - val_fp: 1375.0000 - val_tn: 9438.0000 - val_fn: 108.0000 - val_accuracy: 0.8653 - val_precision: 0.0595 - val_recall: 0.4462 - val_auc: 0.7923\n",
            "Epoch 40/100\n",
            "86/86 [==============================] - 14s 164ms/step - loss: 0.4993 - tp: 289.0000 - fp: 5840.0000 - tn: 15789.0000 - fn: 98.0000 - accuracy: 0.7303 - precision: 0.0472 - recall: 0.7468 - auc: 0.8275 - val_loss: 0.5310 - val_tp: 132.0000 - val_fp: 2708.0000 - val_tn: 8105.0000 - val_fn: 63.0000 - val_accuracy: 0.7483 - val_precision: 0.0465 - val_recall: 0.6769 - val_auc: 0.7713\n",
            "Epoch 41/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.4960 - tp: 303.0000 - fp: 6179.0000 - tn: 15446.0000 - fn: 88.0000 - accuracy: 0.7153 - precision: 0.0467 - recall: 0.7749 - auc: 0.8295 - val_loss: 0.4874 - val_tp: 103.0000 - val_fp: 2080.0000 - val_tn: 8733.0000 - val_fn: 92.0000 - val_accuracy: 0.8027 - val_precision: 0.0472 - val_recall: 0.5282 - val_auc: 0.7505\n",
            "Epoch 42/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.4942 - tp: 300.0000 - fp: 6117.0000 - tn: 15509.0000 - fn: 90.0000 - accuracy: 0.7181 - precision: 0.0468 - recall: 0.7692 - auc: 0.8305 - val_loss: 0.3261 - val_tp: 75.0000 - val_fp: 1201.0000 - val_tn: 9612.0000 - val_fn: 120.0000 - val_accuracy: 0.8800 - val_precision: 0.0588 - val_recall: 0.3846 - val_auc: 0.7677\n",
            "Epoch 43/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.4788 - tp: 309.0000 - fp: 5949.0000 - tn: 15676.0000 - fn: 82.0000 - accuracy: 0.7261 - precision: 0.0494 - recall: 0.7903 - auc: 0.8422 - val_loss: 0.3477 - val_tp: 84.0000 - val_fp: 1295.0000 - val_tn: 9518.0000 - val_fn: 111.0000 - val_accuracy: 0.8723 - val_precision: 0.0609 - val_recall: 0.4308 - val_auc: 0.7904\n",
            "Epoch 44/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.4705 - tp: 315.0000 - fp: 5549.0000 - tn: 16074.0000 - fn: 78.0000 - accuracy: 0.7444 - precision: 0.0537 - recall: 0.8015 - auc: 0.8551 - val_loss: 0.2706 - val_tp: 62.0000 - val_fp: 610.0000 - val_tn: 10203.0000 - val_fn: 133.0000 - val_accuracy: 0.9325 - val_precision: 0.0923 - val_recall: 0.3179 - val_auc: 0.7758\n",
            "Epoch 45/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.4565 - tp: 313.0000 - fp: 5468.0000 - tn: 16158.0000 - fn: 77.0000 - accuracy: 0.7481 - precision: 0.0541 - recall: 0.8026 - auc: 0.8594 - val_loss: 0.2413 - val_tp: 54.0000 - val_fp: 569.0000 - val_tn: 10244.0000 - val_fn: 141.0000 - val_accuracy: 0.9355 - val_precision: 0.0867 - val_recall: 0.2769 - val_auc: 0.7846\n",
            "Epoch 46/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.4384 - tp: 319.0000 - fp: 5164.0000 - tn: 16460.0000 - fn: 73.0000 - accuracy: 0.7621 - precision: 0.0582 - recall: 0.8138 - auc: 0.8731 - val_loss: 0.3245 - val_tp: 72.0000 - val_fp: 1093.0000 - val_tn: 9720.0000 - val_fn: 123.0000 - val_accuracy: 0.8895 - val_precision: 0.0618 - val_recall: 0.3692 - val_auc: 0.7661\n",
            "Epoch 47/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.4384 - tp: 318.0000 - fp: 5490.0000 - tn: 16135.0000 - fn: 73.0000 - accuracy: 0.7473 - precision: 0.0548 - recall: 0.8133 - auc: 0.8700 - val_loss: 0.2332 - val_tp: 44.0000 - val_fp: 529.0000 - val_tn: 10284.0000 - val_fn: 151.0000 - val_accuracy: 0.9382 - val_precision: 0.0768 - val_recall: 0.2256 - val_auc: 0.7695\n",
            "Epoch 48/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.4142 - tp: 324.0000 - fp: 4897.0000 - tn: 16729.0000 - fn: 66.0000 - accuracy: 0.7746 - precision: 0.0621 - recall: 0.8308 - auc: 0.8895 - val_loss: 0.2427 - val_tp: 51.0000 - val_fp: 624.0000 - val_tn: 10189.0000 - val_fn: 144.0000 - val_accuracy: 0.9302 - val_precision: 0.0756 - val_recall: 0.2615 - val_auc: 0.7695\n",
            "Epoch 49/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4102 - tp: 315.0000 - fp: 4790.0000 - tn: 16835.0000 - fn: 76.0000 - accuracy: 0.7790 - precision: 0.0617 - recall: 0.8056 - auc: 0.8888 - val_loss: 0.2096 - val_tp: 43.0000 - val_fp: 476.0000 - val_tn: 10337.0000 - val_fn: 152.0000 - val_accuracy: 0.9430 - val_precision: 0.0829 - val_recall: 0.2205 - val_auc: 0.7668\n",
            "Epoch 50/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.4292 - tp: 320.0000 - fp: 5036.0000 - tn: 16586.0000 - fn: 74.0000 - accuracy: 0.7679 - precision: 0.0597 - recall: 0.8122 - auc: 0.8782 - val_loss: 0.2276 - val_tp: 53.0000 - val_fp: 564.0000 - val_tn: 10249.0000 - val_fn: 142.0000 - val_accuracy: 0.9359 - val_precision: 0.0859 - val_recall: 0.2718 - val_auc: 0.7744\n",
            "Epoch 51/100\n",
            "86/86 [==============================] - 14s 164ms/step - loss: 0.4263 - tp: 313.0000 - fp: 5129.0000 - tn: 16499.0000 - fn: 75.0000 - accuracy: 0.7636 - precision: 0.0575 - recall: 0.8067 - auc: 0.8782 - val_loss: 0.2861 - val_tp: 68.0000 - val_fp: 881.0000 - val_tn: 9932.0000 - val_fn: 127.0000 - val_accuracy: 0.9084 - val_precision: 0.0717 - val_recall: 0.3487 - val_auc: 0.7651\n",
            "Epoch 52/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.4217 - tp: 318.0000 - fp: 4934.0000 - tn: 16692.0000 - fn: 72.0000 - accuracy: 0.7726 - precision: 0.0605 - recall: 0.8154 - auc: 0.8824 - val_loss: 0.1889 - val_tp: 36.0000 - val_fp: 385.0000 - val_tn: 10428.0000 - val_fn: 159.0000 - val_accuracy: 0.9506 - val_precision: 0.0855 - val_recall: 0.1846 - val_auc: 0.7730\n",
            "Epoch 53/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.4220 - tp: 318.0000 - fp: 5077.0000 - tn: 16546.0000 - fn: 75.0000 - accuracy: 0.7660 - precision: 0.0589 - recall: 0.8092 - auc: 0.8822 - val_loss: 0.2713 - val_tp: 66.0000 - val_fp: 985.0000 - val_tn: 9828.0000 - val_fn: 129.0000 - val_accuracy: 0.8988 - val_precision: 0.0628 - val_recall: 0.3385 - val_auc: 0.7809\n",
            "Epoch 54/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.4374 - tp: 312.0000 - fp: 5093.0000 - tn: 16530.0000 - fn: 81.0000 - accuracy: 0.7650 - precision: 0.0577 - recall: 0.7939 - auc: 0.8736 - val_loss: 0.2155 - val_tp: 36.0000 - val_fp: 530.0000 - val_tn: 10283.0000 - val_fn: 159.0000 - val_accuracy: 0.9374 - val_precision: 0.0636 - val_recall: 0.1846 - val_auc: 0.7535\n",
            "Epoch 55/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.4382 - tp: 311.0000 - fp: 4990.0000 - tn: 16637.0000 - fn: 78.0000 - accuracy: 0.7698 - precision: 0.0587 - recall: 0.7995 - auc: 0.8719 - val_loss: 0.4597 - val_tp: 115.0000 - val_fp: 2503.0000 - val_tn: 8310.0000 - val_fn: 80.0000 - val_accuracy: 0.7654 - val_precision: 0.0439 - val_recall: 0.5897 - val_auc: 0.7582\n",
            "Epoch 56/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.4907 - tp: 298.0000 - fp: 5172.0000 - tn: 16453.0000 - fn: 93.0000 - accuracy: 0.7609 - precision: 0.0545 - recall: 0.7621 - auc: 0.8510 - val_loss: 0.2007 - val_tp: 27.0000 - val_fp: 516.0000 - val_tn: 10297.0000 - val_fn: 168.0000 - val_accuracy: 0.9379 - val_precision: 0.0497 - val_recall: 0.1385 - val_auc: 0.7326\n",
            "Epoch 57/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.4471 - tp: 308.0000 - fp: 5100.0000 - tn: 16527.0000 - fn: 81.0000 - accuracy: 0.7647 - precision: 0.0570 - recall: 0.7918 - auc: 0.8668 - val_loss: 0.3387 - val_tp: 54.0000 - val_fp: 1061.0000 - val_tn: 9752.0000 - val_fn: 141.0000 - val_accuracy: 0.8908 - val_precision: 0.0484 - val_recall: 0.2769 - val_auc: 0.7420\n",
            "Epoch 58/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.4280 - tp: 313.0000 - fp: 5059.0000 - tn: 16568.0000 - fn: 76.0000 - accuracy: 0.7668 - precision: 0.0583 - recall: 0.8046 - auc: 0.8791 - val_loss: 0.5088 - val_tp: 114.0000 - val_fp: 2805.0000 - val_tn: 8008.0000 - val_fn: 81.0000 - val_accuracy: 0.7378 - val_precision: 0.0391 - val_recall: 0.5846 - val_auc: 0.7306\n",
            "Epoch 59/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.4039 - tp: 323.0000 - fp: 4703.0000 - tn: 16924.0000 - fn: 66.0000 - accuracy: 0.7834 - precision: 0.0643 - recall: 0.8303 - auc: 0.8935 - val_loss: 0.4515 - val_tp: 104.0000 - val_fp: 2276.0000 - val_tn: 8537.0000 - val_fn: 91.0000 - val_accuracy: 0.7850 - val_precision: 0.0437 - val_recall: 0.5333 - val_auc: 0.7477\n",
            "Epoch 60/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.3877 - tp: 324.0000 - fp: 4404.0000 - tn: 17224.0000 - fn: 64.0000 - accuracy: 0.7971 - precision: 0.0685 - recall: 0.8351 - auc: 0.9020 - val_loss: 0.1745 - val_tp: 32.0000 - val_fp: 432.0000 - val_tn: 10381.0000 - val_fn: 163.0000 - val_accuracy: 0.9459 - val_precision: 0.0690 - val_recall: 0.1641 - val_auc: 0.7573\n",
            "Epoch 61/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.3774 - tp: 334.0000 - fp: 4354.0000 - tn: 17269.0000 - fn: 59.0000 - accuracy: 0.7996 - precision: 0.0712 - recall: 0.8499 - auc: 0.9088 - val_loss: 0.3234 - val_tp: 62.0000 - val_fp: 1334.0000 - val_tn: 9479.0000 - val_fn: 133.0000 - val_accuracy: 0.8667 - val_precision: 0.0444 - val_recall: 0.3179 - val_auc: 0.7174\n",
            "Epoch 62/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.3501 - tp: 337.0000 - fp: 3917.0000 - tn: 17705.0000 - fn: 57.0000 - accuracy: 0.8195 - precision: 0.0792 - recall: 0.8553 - auc: 0.9224 - val_loss: 0.2499 - val_tp: 40.0000 - val_fp: 767.0000 - val_tn: 10046.0000 - val_fn: 155.0000 - val_accuracy: 0.9162 - val_precision: 0.0496 - val_recall: 0.2051 - val_auc: 0.6885\n",
            "Epoch 63/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.3255 - tp: 349.0000 - fp: 3945.0000 - tn: 17681.0000 - fn: 41.0000 - accuracy: 0.8189 - precision: 0.0813 - recall: 0.8949 - auc: 0.9329 - val_loss: 0.2421 - val_tp: 43.0000 - val_fp: 744.0000 - val_tn: 10069.0000 - val_fn: 152.0000 - val_accuracy: 0.9186 - val_precision: 0.0546 - val_recall: 0.2205 - val_auc: 0.6861\n",
            "Epoch 64/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.3273 - tp: 342.0000 - fp: 4063.0000 - tn: 17561.0000 - fn: 50.0000 - accuracy: 0.8132 - precision: 0.0776 - recall: 0.8724 - auc: 0.9320 - val_loss: 0.2570 - val_tp: 49.0000 - val_fp: 853.0000 - val_tn: 9960.0000 - val_fn: 146.0000 - val_accuracy: 0.9092 - val_precision: 0.0543 - val_recall: 0.2513 - val_auc: 0.6974\n",
            "Epoch 65/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.3137 - tp: 354.0000 - fp: 3685.0000 - tn: 17933.0000 - fn: 44.0000 - accuracy: 0.8306 - precision: 0.0876 - recall: 0.8894 - auc: 0.9398 - val_loss: 0.2658 - val_tp: 58.0000 - val_fp: 932.0000 - val_tn: 9881.0000 - val_fn: 137.0000 - val_accuracy: 0.9029 - val_precision: 0.0586 - val_recall: 0.2974 - val_auc: 0.7066\n",
            "Epoch 66/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.3083 - tp: 343.0000 - fp: 3448.0000 - tn: 18178.0000 - fn: 47.0000 - accuracy: 0.8413 - precision: 0.0905 - recall: 0.8795 - auc: 0.9414 - val_loss: 0.1822 - val_tp: 33.0000 - val_fp: 415.0000 - val_tn: 10398.0000 - val_fn: 162.0000 - val_accuracy: 0.9476 - val_precision: 0.0737 - val_recall: 0.1692 - val_auc: 0.7083\n",
            "Epoch 67/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.3382 - tp: 332.0000 - fp: 3704.0000 - tn: 17921.0000 - fn: 59.0000 - accuracy: 0.8291 - precision: 0.0823 - recall: 0.8491 - auc: 0.9272 - val_loss: 0.2308 - val_tp: 49.0000 - val_fp: 756.0000 - val_tn: 10057.0000 - val_fn: 146.0000 - val_accuracy: 0.9181 - val_precision: 0.0609 - val_recall: 0.2513 - val_auc: 0.7289\n",
            "Epoch 68/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.2975 - tp: 354.0000 - fp: 3458.0000 - tn: 18167.0000 - fn: 37.0000 - accuracy: 0.8413 - precision: 0.0929 - recall: 0.9054 - auc: 0.9461 - val_loss: 0.3142 - val_tp: 75.0000 - val_fp: 1333.0000 - val_tn: 9480.0000 - val_fn: 120.0000 - val_accuracy: 0.8680 - val_precision: 0.0533 - val_recall: 0.3846 - val_auc: 0.7339\n",
            "Epoch 69/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.3404 - tp: 332.0000 - fp: 3805.0000 - tn: 17820.0000 - fn: 59.0000 - accuracy: 0.8245 - precision: 0.0803 - recall: 0.8491 - auc: 0.9250 - val_loss: 0.1023 - val_tp: 8.0000 - val_fp: 106.0000 - val_tn: 10707.0000 - val_fn: 187.0000 - val_accuracy: 0.9734 - val_precision: 0.0702 - val_recall: 0.0410 - val_auc: 0.7486\n",
            "Epoch 70/100\n",
            "86/86 [==============================] - 15s 176ms/step - loss: 0.3417 - tp: 334.0000 - fp: 3795.0000 - tn: 17828.0000 - fn: 59.0000 - accuracy: 0.8249 - precision: 0.0809 - recall: 0.8499 - auc: 0.9260 - val_loss: 0.3552 - val_tp: 75.0000 - val_fp: 1543.0000 - val_tn: 9270.0000 - val_fn: 120.0000 - val_accuracy: 0.8489 - val_precision: 0.0464 - val_recall: 0.3846 - val_auc: 0.7039\n",
            "Epoch 71/100\n",
            "86/86 [==============================] - 15s 178ms/step - loss: 0.3535 - tp: 328.0000 - fp: 4072.0000 - tn: 17554.0000 - fn: 62.0000 - accuracy: 0.8122 - precision: 0.0745 - recall: 0.8410 - auc: 0.9190 - val_loss: 0.1207 - val_tp: 13.0000 - val_fp: 153.0000 - val_tn: 10660.0000 - val_fn: 182.0000 - val_accuracy: 0.9696 - val_precision: 0.0783 - val_recall: 0.0667 - val_auc: 0.7415\n",
            "Epoch 72/100\n",
            "86/86 [==============================] - 15s 177ms/step - loss: 0.3532 - tp: 333.0000 - fp: 3912.0000 - tn: 17713.0000 - fn: 58.0000 - accuracy: 0.8197 - precision: 0.0784 - recall: 0.8517 - auc: 0.9200 - val_loss: 0.1819 - val_tp: 48.0000 - val_fp: 540.0000 - val_tn: 10273.0000 - val_fn: 147.0000 - val_accuracy: 0.9376 - val_precision: 0.0816 - val_recall: 0.2462 - val_auc: 0.7530\n",
            "Epoch 73/100\n",
            "86/86 [==============================] - 15s 174ms/step - loss: 0.3433 - tp: 337.0000 - fp: 3947.0000 - tn: 17678.0000 - fn: 54.0000 - accuracy: 0.8183 - precision: 0.0787 - recall: 0.8619 - auc: 0.9252 - val_loss: 0.3193 - val_tp: 62.0000 - val_fp: 1373.0000 - val_tn: 9440.0000 - val_fn: 133.0000 - val_accuracy: 0.8632 - val_precision: 0.0432 - val_recall: 0.3179 - val_auc: 0.7291\n",
            "Epoch 74/100\n",
            "86/86 [==============================] - 15s 172ms/step - loss: 0.3023 - tp: 347.0000 - fp: 3335.0000 - tn: 18288.0000 - fn: 46.0000 - accuracy: 0.8464 - precision: 0.0942 - recall: 0.8830 - auc: 0.9427 - val_loss: 0.4933 - val_tp: 79.0000 - val_fp: 2213.0000 - val_tn: 8600.0000 - val_fn: 116.0000 - val_accuracy: 0.7884 - val_precision: 0.0345 - val_recall: 0.4051 - val_auc: 0.6715\n",
            "Epoch 75/100\n",
            "86/86 [==============================] - 15s 172ms/step - loss: 0.3185 - tp: 332.0000 - fp: 3514.0000 - tn: 18113.0000 - fn: 57.0000 - accuracy: 0.8378 - precision: 0.0863 - recall: 0.8535 - auc: 0.9355 - val_loss: 0.3026 - val_tp: 68.0000 - val_fp: 1221.0000 - val_tn: 9592.0000 - val_fn: 127.0000 - val_accuracy: 0.8775 - val_precision: 0.0528 - val_recall: 0.3487 - val_auc: 0.7288\n",
            "Epoch 76/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.3054 - tp: 338.0000 - fp: 3318.0000 - tn: 18305.0000 - fn: 55.0000 - accuracy: 0.8468 - precision: 0.0925 - recall: 0.8601 - auc: 0.9417 - val_loss: 0.1681 - val_tp: 28.0000 - val_fp: 330.0000 - val_tn: 10483.0000 - val_fn: 167.0000 - val_accuracy: 0.9549 - val_precision: 0.0782 - val_recall: 0.1436 - val_auc: 0.7029\n",
            "Epoch 77/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.2760 - tp: 350.0000 - fp: 3208.0000 - tn: 18414.0000 - fn: 44.0000 - accuracy: 0.8523 - precision: 0.0984 - recall: 0.8883 - auc: 0.9526 - val_loss: 0.1880 - val_tp: 37.0000 - val_fp: 419.0000 - val_tn: 10394.0000 - val_fn: 158.0000 - val_accuracy: 0.9476 - val_precision: 0.0811 - val_recall: 0.1897 - val_auc: 0.7056\n",
            "Epoch 78/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.2691 - tp: 352.0000 - fp: 3218.0000 - tn: 18404.0000 - fn: 42.0000 - accuracy: 0.8519 - precision: 0.0986 - recall: 0.8934 - auc: 0.9548 - val_loss: 0.2683 - val_tp: 61.0000 - val_fp: 922.0000 - val_tn: 9891.0000 - val_fn: 134.0000 - val_accuracy: 0.9041 - val_precision: 0.0621 - val_recall: 0.3128 - val_auc: 0.6952\n",
            "Epoch 79/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.2677 - tp: 350.0000 - fp: 3145.0000 - tn: 18479.0000 - fn: 42.0000 - accuracy: 0.8552 - precision: 0.1001 - recall: 0.8929 - auc: 0.9552 - val_loss: 0.2256 - val_tp: 45.0000 - val_fp: 654.0000 - val_tn: 10159.0000 - val_fn: 150.0000 - val_accuracy: 0.9270 - val_precision: 0.0644 - val_recall: 0.2308 - val_auc: 0.6940\n",
            "Epoch 80/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.2330 - tp: 361.0000 - fp: 2748.0000 - tn: 18878.0000 - fn: 29.0000 - accuracy: 0.8739 - precision: 0.1161 - recall: 0.9256 - auc: 0.9680 - val_loss: 0.2516 - val_tp: 53.0000 - val_fp: 805.0000 - val_tn: 10008.0000 - val_fn: 142.0000 - val_accuracy: 0.9140 - val_precision: 0.0618 - val_recall: 0.2718 - val_auc: 0.6757\n",
            "Epoch 81/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.2341 - tp: 354.0000 - fp: 2703.0000 - tn: 18923.0000 - fn: 36.0000 - accuracy: 0.8756 - precision: 0.1158 - recall: 0.9077 - auc: 0.9670 - val_loss: 0.2280 - val_tp: 43.0000 - val_fp: 665.0000 - val_tn: 10148.0000 - val_fn: 152.0000 - val_accuracy: 0.9258 - val_precision: 0.0607 - val_recall: 0.2205 - val_auc: 0.6759\n",
            "Epoch 82/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.2398 - tp: 359.0000 - fp: 2740.0000 - tn: 18883.0000 - fn: 34.0000 - accuracy: 0.8740 - precision: 0.1158 - recall: 0.9135 - auc: 0.9651 - val_loss: 0.2395 - val_tp: 53.0000 - val_fp: 743.0000 - val_tn: 10070.0000 - val_fn: 142.0000 - val_accuracy: 0.9196 - val_precision: 0.0666 - val_recall: 0.2718 - val_auc: 0.6927\n",
            "Epoch 83/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.2326 - tp: 364.0000 - fp: 2788.0000 - tn: 18835.0000 - fn: 29.0000 - accuracy: 0.8720 - precision: 0.1155 - recall: 0.9262 - auc: 0.9671 - val_loss: 0.2701 - val_tp: 64.0000 - val_fp: 993.0000 - val_tn: 9820.0000 - val_fn: 131.0000 - val_accuracy: 0.8979 - val_precision: 0.0605 - val_recall: 0.3282 - val_auc: 0.7033\n",
            "Epoch 84/100\n",
            "86/86 [==============================] - 14s 169ms/step - loss: 0.2441 - tp: 353.0000 - fp: 2691.0000 - tn: 18935.0000 - fn: 37.0000 - accuracy: 0.8761 - precision: 0.1160 - recall: 0.9051 - auc: 0.9637 - val_loss: 0.1393 - val_tp: 26.0000 - val_fp: 285.0000 - val_tn: 10528.0000 - val_fn: 169.0000 - val_accuracy: 0.9588 - val_precision: 0.0836 - val_recall: 0.1333 - val_auc: 0.7076\n",
            "Epoch 85/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.2713 - tp: 344.0000 - fp: 3065.0000 - tn: 18558.0000 - fn: 49.0000 - accuracy: 0.8586 - precision: 0.1009 - recall: 0.8753 - auc: 0.9539 - val_loss: 0.2861 - val_tp: 55.0000 - val_fp: 1065.0000 - val_tn: 9748.0000 - val_fn: 140.0000 - val_accuracy: 0.8905 - val_precision: 0.0491 - val_recall: 0.2821 - val_auc: 0.6846\n",
            "Epoch 86/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.2552 - tp: 352.0000 - fp: 2779.0000 - tn: 18845.0000 - fn: 40.0000 - accuracy: 0.8720 - precision: 0.1124 - recall: 0.8980 - auc: 0.9596 - val_loss: 0.1144 - val_tp: 14.0000 - val_fp: 120.0000 - val_tn: 10693.0000 - val_fn: 181.0000 - val_accuracy: 0.9727 - val_precision: 0.1045 - val_recall: 0.0718 - val_auc: 0.6803\n",
            "Epoch 87/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.2751 - tp: 347.0000 - fp: 3032.0000 - tn: 18594.0000 - fn: 43.0000 - accuracy: 0.8603 - precision: 0.1027 - recall: 0.8897 - auc: 0.9522 - val_loss: 0.1034 - val_tp: 14.0000 - val_fp: 88.0000 - val_tn: 10725.0000 - val_fn: 181.0000 - val_accuracy: 0.9756 - val_precision: 0.1373 - val_recall: 0.0718 - val_auc: 0.6931\n",
            "Epoch 88/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.2849 - tp: 347.0000 - fp: 3124.0000 - tn: 18501.0000 - fn: 44.0000 - accuracy: 0.8561 - precision: 0.1000 - recall: 0.8875 - auc: 0.9488 - val_loss: 0.1595 - val_tp: 38.0000 - val_fp: 415.0000 - val_tn: 10398.0000 - val_fn: 157.0000 - val_accuracy: 0.9480 - val_precision: 0.0839 - val_recall: 0.1949 - val_auc: 0.7241\n",
            "Epoch 89/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.2750 - tp: 341.0000 - fp: 3082.0000 - tn: 18545.0000 - fn: 48.0000 - accuracy: 0.8578 - precision: 0.0996 - recall: 0.8766 - auc: 0.9524 - val_loss: 0.5304 - val_tp: 92.0000 - val_fp: 2633.0000 - val_tn: 8180.0000 - val_fn: 103.0000 - val_accuracy: 0.7515 - val_precision: 0.0338 - val_recall: 0.4718 - val_auc: 0.6665\n",
            "Epoch 90/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.2614 - tp: 345.0000 - fp: 2946.0000 - tn: 18677.0000 - fn: 48.0000 - accuracy: 0.8640 - precision: 0.1048 - recall: 0.8779 - auc: 0.9568 - val_loss: 0.1512 - val_tp: 38.0000 - val_fp: 357.0000 - val_tn: 10456.0000 - val_fn: 157.0000 - val_accuracy: 0.9533 - val_precision: 0.0962 - val_recall: 0.1949 - val_auc: 0.7409\n",
            "Epoch 91/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.2631 - tp: 344.0000 - fp: 3013.0000 - tn: 18614.0000 - fn: 45.0000 - accuracy: 0.8611 - precision: 0.1025 - recall: 0.8843 - auc: 0.9558 - val_loss: 0.1112 - val_tp: 11.0000 - val_fp: 117.0000 - val_tn: 10696.0000 - val_fn: 184.0000 - val_accuracy: 0.9727 - val_precision: 0.0859 - val_recall: 0.0564 - val_auc: 0.7026\n",
            "Epoch 92/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.2413 - tp: 352.0000 - fp: 2756.0000 - tn: 18871.0000 - fn: 37.0000 - accuracy: 0.8731 - precision: 0.1133 - recall: 0.9049 - auc: 0.9636 - val_loss: 0.1141 - val_tp: 18.0000 - val_fp: 154.0000 - val_tn: 10659.0000 - val_fn: 177.0000 - val_accuracy: 0.9699 - val_precision: 0.1047 - val_recall: 0.0923 - val_auc: 0.7370\n",
            "Epoch 93/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.2172 - tp: 352.0000 - fp: 2429.0000 - tn: 19195.0000 - fn: 40.0000 - accuracy: 0.8879 - precision: 0.1266 - recall: 0.8980 - auc: 0.9708 - val_loss: 0.1666 - val_tp: 37.0000 - val_fp: 381.0000 - val_tn: 10432.0000 - val_fn: 158.0000 - val_accuracy: 0.9510 - val_precision: 0.0885 - val_recall: 0.1897 - val_auc: 0.6625\n",
            "Epoch 94/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.2109 - tp: 358.0000 - fp: 2491.0000 - tn: 19135.0000 - fn: 32.0000 - accuracy: 0.8854 - precision: 0.1257 - recall: 0.9179 - auc: 0.9729 - val_loss: 0.1820 - val_tp: 30.0000 - val_fp: 488.0000 - val_tn: 10325.0000 - val_fn: 165.0000 - val_accuracy: 0.9407 - val_precision: 0.0579 - val_recall: 0.1538 - val_auc: 0.6466\n",
            "Epoch 95/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.1993 - tp: 362.0000 - fp: 2308.0000 - tn: 19318.0000 - fn: 28.0000 - accuracy: 0.8939 - precision: 0.1356 - recall: 0.9282 - auc: 0.9761 - val_loss: 0.1409 - val_tp: 20.0000 - val_fp: 246.0000 - val_tn: 10567.0000 - val_fn: 175.0000 - val_accuracy: 0.9618 - val_precision: 0.0752 - val_recall: 0.1026 - val_auc: 0.6537\n",
            "Epoch 96/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.1863 - tp: 370.0000 - fp: 2334.0000 - tn: 19288.0000 - fn: 24.0000 - accuracy: 0.8929 - precision: 0.1368 - recall: 0.9391 - auc: 0.9797 - val_loss: 0.1478 - val_tp: 23.0000 - val_fp: 283.0000 - val_tn: 10530.0000 - val_fn: 172.0000 - val_accuracy: 0.9587 - val_precision: 0.0752 - val_recall: 0.1179 - val_auc: 0.6495\n",
            "Epoch 97/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.1750 - tp: 369.0000 - fp: 2109.0000 - tn: 19519.0000 - fn: 19.0000 - accuracy: 0.9033 - precision: 0.1489 - recall: 0.9510 - auc: 0.9827 - val_loss: 0.1351 - val_tp: 21.0000 - val_fp: 205.0000 - val_tn: 10608.0000 - val_fn: 174.0000 - val_accuracy: 0.9656 - val_precision: 0.0929 - val_recall: 0.1077 - val_auc: 0.6458\n",
            "Epoch 98/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.1826 - tp: 368.0000 - fp: 2019.0000 - tn: 19606.0000 - fn: 23.0000 - accuracy: 0.9072 - precision: 0.1542 - recall: 0.9412 - auc: 0.9806 - val_loss: 0.1165 - val_tp: 12.0000 - val_fp: 133.0000 - val_tn: 10680.0000 - val_fn: 183.0000 - val_accuracy: 0.9713 - val_precision: 0.0828 - val_recall: 0.0615 - val_auc: 0.6646\n",
            "Epoch 99/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.1942 - tp: 369.0000 - fp: 2271.0000 - tn: 19351.0000 - fn: 25.0000 - accuracy: 0.8957 - precision: 0.1398 - recall: 0.9365 - auc: 0.9775 - val_loss: 0.1480 - val_tp: 17.0000 - val_fp: 274.0000 - val_tn: 10539.0000 - val_fn: 178.0000 - val_accuracy: 0.9589 - val_precision: 0.0584 - val_recall: 0.0872 - val_auc: 0.6277\n",
            "Epoch 100/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.1969 - tp: 361.0000 - fp: 2185.0000 - tn: 19442.0000 - fn: 28.0000 - accuracy: 0.8995 - precision: 0.1418 - recall: 0.9280 - auc: 0.9763 - val_loss: 0.1402 - val_tp: 20.0000 - val_fp: 220.0000 - val_tn: 10593.0000 - val_fn: 175.0000 - val_accuracy: 0.9641 - val_precision: 0.0833 - val_recall: 0.1026 - val_auc: 0.6436\n",
            "Epoch 1/100\n",
            " 2/86 [..............................] - ETA: 5s - loss: 1.7958 - tp: 0.0000e+00 - fp: 1.0000 - tn: 502.0000 - fn: 9.0000 - accuracy: 0.9805 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5465    WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0108s vs `on_train_batch_end` time: 0.1072s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0108s vs `on_train_batch_end` time: 0.1072s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "86/86 [==============================] - ETA: 0s - loss: 1.7959 - tp: 1.0000 - fp: 48.0000 - tn: 21579.0000 - fn: 388.0000 - accuracy: 0.9802 - precision: 0.0204 - recall: 0.0026 - auc: 0.5481WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0048s vs `on_test_batch_end` time: 0.0570s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0048s vs `on_test_batch_end` time: 0.0570s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r86/86 [==============================] - 25s 289ms/step - loss: 1.7959 - tp: 1.0000 - fp: 48.0000 - tn: 21579.0000 - fn: 388.0000 - accuracy: 0.9802 - precision: 0.0204 - recall: 0.0026 - auc: 0.5481 - val_loss: 0.1017 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 10814.0000 - val_fn: 194.0000 - val_accuracy: 0.9824 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5726\n",
            "Epoch 2/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 1.3169 - tp: 57.0000 - fp: 1524.0000 - tn: 20099.0000 - fn: 336.0000 - accuracy: 0.9155 - precision: 0.0361 - recall: 0.1450 - auc: 0.6598 - val_loss: 0.0882 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 10814.0000 - val_fn: 194.0000 - val_accuracy: 0.9824 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6992\n",
            "Epoch 3/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.9950 - tp: 143.0000 - fp: 3728.0000 - tn: 17898.0000 - fn: 247.0000 - accuracy: 0.8194 - precision: 0.0369 - recall: 0.3667 - auc: 0.6786 - val_loss: 0.0812 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 10814.0000 - val_fn: 194.0000 - val_accuracy: 0.9824 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7502\n",
            "Epoch 4/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.7328 - tp: 211.0000 - fp: 6190.0000 - tn: 15438.0000 - fn: 177.0000 - accuracy: 0.7108 - precision: 0.0330 - recall: 0.5438 - auc: 0.7081 - val_loss: 0.0934 - val_tp: 1.0000 - val_fp: 5.0000 - val_tn: 10809.0000 - val_fn: 193.0000 - val_accuracy: 0.9820 - val_precision: 0.1667 - val_recall: 0.0052 - val_auc: 0.6893\n",
            "Epoch 5/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.6853 - tp: 224.0000 - fp: 5944.0000 - tn: 15682.0000 - fn: 166.0000 - accuracy: 0.7225 - precision: 0.0363 - recall: 0.5744 - auc: 0.7252 - val_loss: 0.0854 - val_tp: 2.0000 - val_fp: 4.0000 - val_tn: 10810.0000 - val_fn: 192.0000 - val_accuracy: 0.9822 - val_precision: 0.3333 - val_recall: 0.0103 - val_auc: 0.7447\n",
            "Epoch 6/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.6665 - tp: 244.0000 - fp: 6723.0000 - tn: 14904.0000 - fn: 145.0000 - accuracy: 0.6880 - precision: 0.0350 - recall: 0.6272 - auc: 0.7299 - val_loss: 0.1594 - val_tp: 31.0000 - val_fp: 379.0000 - val_tn: 10435.0000 - val_fn: 163.0000 - val_accuracy: 0.9508 - val_precision: 0.0756 - val_recall: 0.1598 - val_auc: 0.7509\n",
            "Epoch 7/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.6309 - tp: 236.0000 - fp: 6648.0000 - tn: 14978.0000 - fn: 154.0000 - accuracy: 0.6910 - precision: 0.0343 - recall: 0.6051 - auc: 0.7299 - val_loss: 0.7169 - val_tp: 146.0000 - val_fp: 4900.0000 - val_tn: 5914.0000 - val_fn: 48.0000 - val_accuracy: 0.5505 - val_precision: 0.0289 - val_recall: 0.7526 - val_auc: 0.7442\n",
            "Epoch 8/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.6279 - tp: 232.0000 - fp: 6613.0000 - tn: 15014.0000 - fn: 157.0000 - accuracy: 0.6925 - precision: 0.0339 - recall: 0.5964 - auc: 0.7342 - val_loss: 0.5853 - val_tp: 146.0000 - val_fp: 4154.0000 - val_tn: 6660.0000 - val_fn: 48.0000 - val_accuracy: 0.6183 - val_precision: 0.0340 - val_recall: 0.7526 - val_auc: 0.7619\n",
            "Epoch 9/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.6171 - tp: 251.0000 - fp: 6485.0000 - tn: 15141.0000 - fn: 139.0000 - accuracy: 0.6991 - precision: 0.0373 - recall: 0.6436 - auc: 0.7467 - val_loss: 0.5729 - val_tp: 133.0000 - val_fp: 3390.0000 - val_tn: 7424.0000 - val_fn: 61.0000 - val_accuracy: 0.6865 - val_precision: 0.0378 - val_recall: 0.6856 - val_auc: 0.7630\n",
            "Epoch 10/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.6341 - tp: 246.0000 - fp: 6855.0000 - tn: 14772.0000 - fn: 143.0000 - accuracy: 0.6821 - precision: 0.0346 - recall: 0.6324 - auc: 0.7440 - val_loss: 0.9891 - val_tp: 167.0000 - val_fp: 7487.0000 - val_tn: 3327.0000 - val_fn: 27.0000 - val_accuracy: 0.3174 - val_precision: 0.0218 - val_recall: 0.8608 - val_auc: 0.6732\n",
            "Epoch 11/100\n",
            "86/86 [==============================] - 14s 169ms/step - loss: 0.6056 - tp: 264.0000 - fp: 6457.0000 - tn: 15167.0000 - fn: 128.0000 - accuracy: 0.7009 - precision: 0.0393 - recall: 0.6735 - auc: 0.7657 - val_loss: 0.3964 - val_tp: 94.0000 - val_fp: 2680.0000 - val_tn: 8134.0000 - val_fn: 100.0000 - val_accuracy: 0.7475 - val_precision: 0.0339 - val_recall: 0.4845 - val_auc: 0.7299\n",
            "Epoch 12/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5957 - tp: 264.0000 - fp: 6721.0000 - tn: 14902.0000 - fn: 129.0000 - accuracy: 0.6889 - precision: 0.0378 - recall: 0.6718 - auc: 0.7580 - val_loss: 0.3654 - val_tp: 89.0000 - val_fp: 1869.0000 - val_tn: 8945.0000 - val_fn: 105.0000 - val_accuracy: 0.8207 - val_precision: 0.0455 - val_recall: 0.4588 - val_auc: 0.7737\n",
            "Epoch 13/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5800 - tp: 267.0000 - fp: 6539.0000 - tn: 15086.0000 - fn: 124.0000 - accuracy: 0.6974 - precision: 0.0392 - recall: 0.6829 - auc: 0.7646 - val_loss: 0.3717 - val_tp: 99.0000 - val_fp: 2172.0000 - val_tn: 8642.0000 - val_fn: 95.0000 - val_accuracy: 0.7941 - val_precision: 0.0436 - val_recall: 0.5103 - val_auc: 0.7767\n",
            "Epoch 14/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5688 - tp: 284.0000 - fp: 6982.0000 - tn: 14641.0000 - fn: 109.0000 - accuracy: 0.6779 - precision: 0.0391 - recall: 0.7226 - auc: 0.7754 - val_loss: 0.2738 - val_tp: 59.0000 - val_fp: 774.0000 - val_tn: 10040.0000 - val_fn: 135.0000 - val_accuracy: 0.9174 - val_precision: 0.0708 - val_recall: 0.3041 - val_auc: 0.7853\n",
            "Epoch 15/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5630 - tp: 281.0000 - fp: 7103.0000 - tn: 14525.0000 - fn: 107.0000 - accuracy: 0.6725 - precision: 0.0381 - recall: 0.7242 - auc: 0.7703 - val_loss: 0.3621 - val_tp: 91.0000 - val_fp: 1770.0000 - val_tn: 9044.0000 - val_fn: 103.0000 - val_accuracy: 0.8299 - val_precision: 0.0489 - val_recall: 0.4691 - val_auc: 0.7822\n",
            "Epoch 16/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5605 - tp: 270.0000 - fp: 6982.0000 - tn: 14641.0000 - fn: 123.0000 - accuracy: 0.6773 - precision: 0.0372 - recall: 0.6870 - auc: 0.7752 - val_loss: 0.2979 - val_tp: 71.0000 - val_fp: 1417.0000 - val_tn: 9397.0000 - val_fn: 123.0000 - val_accuracy: 0.8601 - val_precision: 0.0477 - val_recall: 0.3660 - val_auc: 0.7729\n",
            "Epoch 17/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5510 - tp: 288.0000 - fp: 6805.0000 - tn: 14821.0000 - fn: 102.0000 - accuracy: 0.6863 - precision: 0.0406 - recall: 0.7385 - auc: 0.7874 - val_loss: 0.3201 - val_tp: 82.0000 - val_fp: 1706.0000 - val_tn: 9108.0000 - val_fn: 112.0000 - val_accuracy: 0.8348 - val_precision: 0.0459 - val_recall: 0.4227 - val_auc: 0.7681\n",
            "Epoch 18/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5448 - tp: 287.0000 - fp: 6756.0000 - tn: 14872.0000 - fn: 101.0000 - accuracy: 0.6885 - precision: 0.0407 - recall: 0.7397 - auc: 0.7899 - val_loss: 0.4000 - val_tp: 107.0000 - val_fp: 2854.0000 - val_tn: 7960.0000 - val_fn: 87.0000 - val_accuracy: 0.7328 - val_precision: 0.0361 - val_recall: 0.5515 - val_auc: 0.7570\n",
            "Epoch 19/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5635 - tp: 269.0000 - fp: 6583.0000 - tn: 15041.0000 - fn: 123.0000 - accuracy: 0.6954 - precision: 0.0393 - recall: 0.6862 - auc: 0.7781 - val_loss: 0.3167 - val_tp: 78.0000 - val_fp: 1140.0000 - val_tn: 9674.0000 - val_fn: 116.0000 - val_accuracy: 0.8859 - val_precision: 0.0640 - val_recall: 0.4021 - val_auc: 0.7844\n",
            "Epoch 20/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5359 - tp: 281.0000 - fp: 6738.0000 - tn: 14889.0000 - fn: 108.0000 - accuracy: 0.6890 - precision: 0.0400 - recall: 0.7224 - auc: 0.7942 - val_loss: 0.3176 - val_tp: 79.0000 - val_fp: 1692.0000 - val_tn: 9122.0000 - val_fn: 115.0000 - val_accuracy: 0.8358 - val_precision: 0.0446 - val_recall: 0.4072 - val_auc: 0.7634\n",
            "Epoch 21/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5634 - tp: 280.0000 - fp: 6926.0000 - tn: 14701.0000 - fn: 109.0000 - accuracy: 0.6805 - precision: 0.0389 - recall: 0.7198 - auc: 0.7764 - val_loss: 0.4031 - val_tp: 101.0000 - val_fp: 1825.0000 - val_tn: 8989.0000 - val_fn: 93.0000 - val_accuracy: 0.8258 - val_precision: 0.0524 - val_recall: 0.5206 - val_auc: 0.7819\n",
            "Epoch 22/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5653 - tp: 276.0000 - fp: 6246.0000 - tn: 15374.0000 - fn: 120.0000 - accuracy: 0.7108 - precision: 0.0423 - recall: 0.6970 - auc: 0.7869 - val_loss: 0.3925 - val_tp: 90.0000 - val_fp: 1526.0000 - val_tn: 9288.0000 - val_fn: 104.0000 - val_accuracy: 0.8519 - val_precision: 0.0557 - val_recall: 0.4639 - val_auc: 0.7796\n",
            "Epoch 23/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.5573 - tp: 280.0000 - fp: 6561.0000 - tn: 15062.0000 - fn: 113.0000 - accuracy: 0.6969 - precision: 0.0409 - recall: 0.7125 - auc: 0.7835 - val_loss: 0.2714 - val_tp: 60.0000 - val_fp: 926.0000 - val_tn: 9888.0000 - val_fn: 134.0000 - val_accuracy: 0.9037 - val_precision: 0.0609 - val_recall: 0.3093 - val_auc: 0.7696\n",
            "Epoch 24/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5524 - tp: 283.0000 - fp: 6386.0000 - tn: 15239.0000 - fn: 108.0000 - accuracy: 0.7050 - precision: 0.0424 - recall: 0.7238 - auc: 0.7881 - val_loss: 0.3038 - val_tp: 52.0000 - val_fp: 439.0000 - val_tn: 10375.0000 - val_fn: 142.0000 - val_accuracy: 0.9472 - val_precision: 0.1059 - val_recall: 0.2680 - val_auc: 0.7978\n",
            "Epoch 25/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5484 - tp: 285.0000 - fp: 6248.0000 - tn: 15375.0000 - fn: 108.0000 - accuracy: 0.7113 - precision: 0.0436 - recall: 0.7252 - auc: 0.8009 - val_loss: 0.2911 - val_tp: 82.0000 - val_fp: 1325.0000 - val_tn: 9489.0000 - val_fn: 112.0000 - val_accuracy: 0.8695 - val_precision: 0.0583 - val_recall: 0.4227 - val_auc: 0.7821\n",
            "Epoch 26/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5701 - tp: 278.0000 - fp: 6524.0000 - tn: 15101.0000 - fn: 113.0000 - accuracy: 0.6985 - precision: 0.0409 - recall: 0.7110 - auc: 0.7796 - val_loss: 0.1648 - val_tp: 9.0000 - val_fp: 179.0000 - val_tn: 10635.0000 - val_fn: 185.0000 - val_accuracy: 0.9669 - val_precision: 0.0479 - val_recall: 0.0464 - val_auc: 0.6507\n",
            "Epoch 27/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5487 - tp: 290.0000 - fp: 6859.0000 - tn: 14766.0000 - fn: 101.0000 - accuracy: 0.6839 - precision: 0.0406 - recall: 0.7417 - auc: 0.7884 - val_loss: 0.1388 - val_tp: 12.0000 - val_fp: 91.0000 - val_tn: 10723.0000 - val_fn: 182.0000 - val_accuracy: 0.9752 - val_precision: 0.1165 - val_recall: 0.0619 - val_auc: 0.7639\n",
            "Epoch 28/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5291 - tp: 289.0000 - fp: 6680.0000 - tn: 14945.0000 - fn: 102.0000 - accuracy: 0.6920 - precision: 0.0415 - recall: 0.7391 - auc: 0.8006 - val_loss: 0.3347 - val_tp: 76.0000 - val_fp: 1000.0000 - val_tn: 9814.0000 - val_fn: 118.0000 - val_accuracy: 0.8984 - val_precision: 0.0706 - val_recall: 0.3918 - val_auc: 0.8004\n",
            "Epoch 29/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.5649 - tp: 280.0000 - fp: 6084.0000 - tn: 15540.0000 - fn: 112.0000 - accuracy: 0.7186 - precision: 0.0440 - recall: 0.7143 - auc: 0.7964 - val_loss: 0.3319 - val_tp: 63.0000 - val_fp: 682.0000 - val_tn: 10132.0000 - val_fn: 131.0000 - val_accuracy: 0.9261 - val_precision: 0.0846 - val_recall: 0.3247 - val_auc: 0.7942\n",
            "Epoch 30/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.5135 - tp: 296.0000 - fp: 6088.0000 - tn: 15538.0000 - fn: 94.0000 - accuracy: 0.7192 - precision: 0.0464 - recall: 0.7590 - auc: 0.8171 - val_loss: 0.3370 - val_tp: 72.0000 - val_fp: 950.0000 - val_tn: 9864.0000 - val_fn: 122.0000 - val_accuracy: 0.9026 - val_precision: 0.0705 - val_recall: 0.3711 - val_auc: 0.8002\n",
            "Epoch 31/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5129 - tp: 301.0000 - fp: 6362.0000 - tn: 15262.0000 - fn: 91.0000 - accuracy: 0.7069 - precision: 0.0452 - recall: 0.7679 - auc: 0.8179 - val_loss: 0.2710 - val_tp: 65.0000 - val_fp: 819.0000 - val_tn: 9995.0000 - val_fn: 129.0000 - val_accuracy: 0.9139 - val_precision: 0.0735 - val_recall: 0.3351 - val_auc: 0.7974\n",
            "Epoch 32/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.4991 - tp: 310.0000 - fp: 6252.0000 - tn: 15373.0000 - fn: 81.0000 - accuracy: 0.7123 - precision: 0.0472 - recall: 0.7928 - auc: 0.8305 - val_loss: 0.2756 - val_tp: 68.0000 - val_fp: 945.0000 - val_tn: 9869.0000 - val_fn: 126.0000 - val_accuracy: 0.9027 - val_precision: 0.0671 - val_recall: 0.3505 - val_auc: 0.7962\n",
            "Epoch 33/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5235 - tp: 288.0000 - fp: 5958.0000 - tn: 15666.0000 - fn: 104.0000 - accuracy: 0.7247 - precision: 0.0461 - recall: 0.7347 - auc: 0.8205 - val_loss: 0.2718 - val_tp: 73.0000 - val_fp: 969.0000 - val_tn: 9845.0000 - val_fn: 121.0000 - val_accuracy: 0.9010 - val_precision: 0.0701 - val_recall: 0.3763 - val_auc: 0.7932\n",
            "Epoch 34/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5025 - tp: 301.0000 - fp: 6146.0000 - tn: 15478.0000 - fn: 91.0000 - accuracy: 0.7167 - precision: 0.0467 - recall: 0.7679 - auc: 0.8261 - val_loss: 0.3057 - val_tp: 72.0000 - val_fp: 958.0000 - val_tn: 9856.0000 - val_fn: 122.0000 - val_accuracy: 0.9019 - val_precision: 0.0699 - val_recall: 0.3711 - val_auc: 0.7997\n",
            "Epoch 35/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4992 - tp: 300.0000 - fp: 5997.0000 - tn: 15629.0000 - fn: 90.0000 - accuracy: 0.7235 - precision: 0.0476 - recall: 0.7692 - auc: 0.8307 - val_loss: 0.2552 - val_tp: 61.0000 - val_fp: 868.0000 - val_tn: 9946.0000 - val_fn: 133.0000 - val_accuracy: 0.9091 - val_precision: 0.0657 - val_recall: 0.3144 - val_auc: 0.7846\n",
            "Epoch 36/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.4970 - tp: 300.0000 - fp: 5802.0000 - tn: 15826.0000 - fn: 88.0000 - accuracy: 0.7325 - precision: 0.0492 - recall: 0.7732 - auc: 0.8326 - val_loss: 0.3698 - val_tp: 89.0000 - val_fp: 1588.0000 - val_tn: 9226.0000 - val_fn: 105.0000 - val_accuracy: 0.8462 - val_precision: 0.0531 - val_recall: 0.4588 - val_auc: 0.7927\n",
            "Epoch 37/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5314 - tp: 289.0000 - fp: 6106.0000 - tn: 15519.0000 - fn: 102.0000 - accuracy: 0.7180 - precision: 0.0452 - recall: 0.7391 - auc: 0.8104 - val_loss: 0.0977 - val_tp: 1.0000 - val_fp: 16.0000 - val_tn: 10798.0000 - val_fn: 193.0000 - val_accuracy: 0.9810 - val_precision: 0.0588 - val_recall: 0.0052 - val_auc: 0.7504\n",
            "Epoch 38/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5217 - tp: 289.0000 - fp: 6073.0000 - tn: 15552.0000 - fn: 102.0000 - accuracy: 0.7195 - precision: 0.0454 - recall: 0.7391 - auc: 0.8177 - val_loss: 0.1704 - val_tp: 31.0000 - val_fp: 336.0000 - val_tn: 10478.0000 - val_fn: 163.0000 - val_accuracy: 0.9547 - val_precision: 0.0845 - val_recall: 0.1598 - val_auc: 0.7367\n",
            "Epoch 39/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.5117 - tp: 299.0000 - fp: 5809.0000 - tn: 15812.0000 - fn: 96.0000 - accuracy: 0.7318 - precision: 0.0490 - recall: 0.7570 - auc: 0.8282 - val_loss: 0.2720 - val_tp: 70.0000 - val_fp: 1089.0000 - val_tn: 9725.0000 - val_fn: 124.0000 - val_accuracy: 0.8898 - val_precision: 0.0604 - val_recall: 0.3608 - val_auc: 0.7835\n",
            "Epoch 40/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.5015 - tp: 295.0000 - fp: 5765.0000 - tn: 15861.0000 - fn: 95.0000 - accuracy: 0.7338 - precision: 0.0487 - recall: 0.7564 - auc: 0.8331 - val_loss: 0.1508 - val_tp: 16.0000 - val_fp: 244.0000 - val_tn: 10570.0000 - val_fn: 178.0000 - val_accuracy: 0.9617 - val_precision: 0.0615 - val_recall: 0.0825 - val_auc: 0.7583\n",
            "Epoch 41/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5276 - tp: 279.0000 - fp: 5335.0000 - tn: 16291.0000 - fn: 111.0000 - accuracy: 0.7526 - precision: 0.0497 - recall: 0.7154 - auc: 0.8245 - val_loss: 0.1971 - val_tp: 34.0000 - val_fp: 413.0000 - val_tn: 10401.0000 - val_fn: 160.0000 - val_accuracy: 0.9479 - val_precision: 0.0761 - val_recall: 0.1753 - val_auc: 0.7728\n",
            "Epoch 42/100\n",
            "86/86 [==============================] - 14s 169ms/step - loss: 0.5177 - tp: 289.0000 - fp: 6090.0000 - tn: 15535.0000 - fn: 102.0000 - accuracy: 0.7188 - precision: 0.0453 - recall: 0.7391 - auc: 0.8187 - val_loss: 0.2507 - val_tp: 44.0000 - val_fp: 570.0000 - val_tn: 10244.0000 - val_fn: 150.0000 - val_accuracy: 0.9346 - val_precision: 0.0717 - val_recall: 0.2268 - val_auc: 0.7890\n",
            "Epoch 43/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4995 - tp: 290.0000 - fp: 5835.0000 - tn: 15792.0000 - fn: 99.0000 - accuracy: 0.7305 - precision: 0.0473 - recall: 0.7455 - auc: 0.8289 - val_loss: 0.3433 - val_tp: 70.0000 - val_fp: 1041.0000 - val_tn: 9773.0000 - val_fn: 124.0000 - val_accuracy: 0.8942 - val_precision: 0.0630 - val_recall: 0.3608 - val_auc: 0.7761\n",
            "Epoch 44/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.4781 - tp: 303.0000 - fp: 5332.0000 - tn: 16291.0000 - fn: 90.0000 - accuracy: 0.7537 - precision: 0.0538 - recall: 0.7710 - auc: 0.8507 - val_loss: 0.2115 - val_tp: 37.0000 - val_fp: 511.0000 - val_tn: 10303.0000 - val_fn: 157.0000 - val_accuracy: 0.9393 - val_precision: 0.0675 - val_recall: 0.1907 - val_auc: 0.7779\n",
            "Epoch 45/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4664 - tp: 313.0000 - fp: 5356.0000 - tn: 16268.0000 - fn: 79.0000 - accuracy: 0.7531 - precision: 0.0552 - recall: 0.7985 - auc: 0.8566 - val_loss: 0.2805 - val_tp: 67.0000 - val_fp: 988.0000 - val_tn: 9826.0000 - val_fn: 127.0000 - val_accuracy: 0.8987 - val_precision: 0.0635 - val_recall: 0.3454 - val_auc: 0.7808\n",
            "Epoch 46/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.4525 - tp: 315.0000 - fp: 5236.0000 - tn: 16389.0000 - fn: 76.0000 - accuracy: 0.7587 - precision: 0.0567 - recall: 0.8056 - auc: 0.8645 - val_loss: 0.2591 - val_tp: 49.0000 - val_fp: 641.0000 - val_tn: 10173.0000 - val_fn: 145.0000 - val_accuracy: 0.9286 - val_precision: 0.0710 - val_recall: 0.2526 - val_auc: 0.7759\n",
            "Epoch 47/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.4422 - tp: 317.0000 - fp: 5173.0000 - tn: 16451.0000 - fn: 75.0000 - accuracy: 0.7616 - precision: 0.0577 - recall: 0.8087 - auc: 0.8715 - val_loss: 0.3209 - val_tp: 73.0000 - val_fp: 1186.0000 - val_tn: 9628.0000 - val_fn: 121.0000 - val_accuracy: 0.8813 - val_precision: 0.0580 - val_recall: 0.3763 - val_auc: 0.7740\n",
            "Epoch 48/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4241 - tp: 318.0000 - fp: 4847.0000 - tn: 16781.0000 - fn: 70.0000 - accuracy: 0.7767 - precision: 0.0616 - recall: 0.8196 - auc: 0.8830 - val_loss: 0.2508 - val_tp: 55.0000 - val_fp: 840.0000 - val_tn: 9974.0000 - val_fn: 139.0000 - val_accuracy: 0.9111 - val_precision: 0.0615 - val_recall: 0.2835 - val_auc: 0.7664\n",
            "Epoch 49/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4405 - tp: 317.0000 - fp: 4950.0000 - tn: 16673.0000 - fn: 76.0000 - accuracy: 0.7717 - precision: 0.0602 - recall: 0.8066 - auc: 0.8737 - val_loss: 0.3162 - val_tp: 76.0000 - val_fp: 1300.0000 - val_tn: 9514.0000 - val_fn: 118.0000 - val_accuracy: 0.8712 - val_precision: 0.0552 - val_recall: 0.3918 - val_auc: 0.7767\n",
            "Epoch 50/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4125 - tp: 323.0000 - fp: 4826.0000 - tn: 16800.0000 - fn: 67.0000 - accuracy: 0.7778 - precision: 0.0627 - recall: 0.8282 - auc: 0.8932 - val_loss: 0.3517 - val_tp: 81.0000 - val_fp: 1540.0000 - val_tn: 9274.0000 - val_fn: 113.0000 - val_accuracy: 0.8498 - val_precision: 0.0500 - val_recall: 0.4175 - val_auc: 0.7699\n",
            "Epoch 51/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.4293 - tp: 319.0000 - fp: 4713.0000 - tn: 16909.0000 - fn: 75.0000 - accuracy: 0.7825 - precision: 0.0634 - recall: 0.8096 - auc: 0.8824 - val_loss: 0.2366 - val_tp: 53.0000 - val_fp: 767.0000 - val_tn: 10047.0000 - val_fn: 141.0000 - val_accuracy: 0.9175 - val_precision: 0.0646 - val_recall: 0.2732 - val_auc: 0.7675\n",
            "Epoch 52/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.4269 - tp: 312.0000 - fp: 4793.0000 - tn: 16832.0000 - fn: 79.0000 - accuracy: 0.7787 - precision: 0.0611 - recall: 0.7980 - auc: 0.8820 - val_loss: 0.3522 - val_tp: 93.0000 - val_fp: 1885.0000 - val_tn: 8929.0000 - val_fn: 101.0000 - val_accuracy: 0.8196 - val_precision: 0.0470 - val_recall: 0.4794 - val_auc: 0.7744\n",
            "Epoch 53/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.4325 - tp: 314.0000 - fp: 4760.0000 - tn: 16865.0000 - fn: 77.0000 - accuracy: 0.7803 - precision: 0.0619 - recall: 0.8031 - auc: 0.8779 - val_loss: 0.2468 - val_tp: 54.0000 - val_fp: 820.0000 - val_tn: 9994.0000 - val_fn: 140.0000 - val_accuracy: 0.9128 - val_precision: 0.0618 - val_recall: 0.2784 - val_auc: 0.7562\n",
            "Epoch 54/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.4549 - tp: 313.0000 - fp: 5113.0000 - tn: 16513.0000 - fn: 77.0000 - accuracy: 0.7643 - precision: 0.0577 - recall: 0.8026 - auc: 0.8644 - val_loss: 0.2260 - val_tp: 53.0000 - val_fp: 730.0000 - val_tn: 10084.0000 - val_fn: 141.0000 - val_accuracy: 0.9209 - val_precision: 0.0677 - val_recall: 0.2732 - val_auc: 0.7716\n",
            "Epoch 1/100\n",
            " 2/86 [..............................] - ETA: 6s - loss: 2.1568 - tp: 0.0000e+00 - fp: 3.0000 - tn: 499.0000 - fn: 10.0000 - accuracy: 0.9746 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5098WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0107s vs `on_train_batch_end` time: 0.1210s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0107s vs `on_train_batch_end` time: 0.1210s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "86/86 [==============================] - ETA: 0s - loss: 1.8018 - tp: 4.0000 - fp: 62.0000 - tn: 21565.0000 - fn: 385.0000 - accuracy: 0.9797 - precision: 0.0606 - recall: 0.0103 - auc: 0.5618WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0052s vs `on_test_batch_end` time: 0.0572s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0052s vs `on_test_batch_end` time: 0.0572s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r86/86 [==============================] - 25s 287ms/step - loss: 1.8018 - tp: 4.0000 - fp: 62.0000 - tn: 21565.0000 - fn: 385.0000 - accuracy: 0.9797 - precision: 0.0606 - recall: 0.0103 - auc: 0.5618 - val_loss: 0.1439 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 10814.0000 - val_fn: 194.0000 - val_accuracy: 0.9824 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6495\n",
            "Epoch 2/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 1.3156 - tp: 57.0000 - fp: 1205.0000 - tn: 20418.0000 - fn: 336.0000 - accuracy: 0.9300 - precision: 0.0452 - recall: 0.1450 - auc: 0.6697 - val_loss: 0.4037 - val_tp: 71.0000 - val_fp: 1271.0000 - val_tn: 9543.0000 - val_fn: 123.0000 - val_accuracy: 0.8734 - val_precision: 0.0529 - val_recall: 0.3660 - val_auc: 0.6561\n",
            "Epoch 3/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.9210 - tp: 172.0000 - fp: 3744.0000 - tn: 17878.0000 - fn: 222.0000 - accuracy: 0.8199 - precision: 0.0439 - recall: 0.4365 - auc: 0.7112 - val_loss: 0.2237 - val_tp: 48.0000 - val_fp: 505.0000 - val_tn: 10309.0000 - val_fn: 146.0000 - val_accuracy: 0.9409 - val_precision: 0.0868 - val_recall: 0.2474 - val_auc: 0.6849\n",
            "Epoch 4/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.7706 - tp: 211.0000 - fp: 4679.0000 - tn: 16948.0000 - fn: 178.0000 - accuracy: 0.7794 - precision: 0.0431 - recall: 0.5424 - auc: 0.7230 - val_loss: 0.1767 - val_tp: 41.0000 - val_fp: 343.0000 - val_tn: 10471.0000 - val_fn: 153.0000 - val_accuracy: 0.9549 - val_precision: 0.1068 - val_recall: 0.2113 - val_auc: 0.7282\n",
            "Epoch 5/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.6981 - tp: 240.0000 - fp: 6176.0000 - tn: 15450.0000 - fn: 150.0000 - accuracy: 0.7127 - precision: 0.0374 - recall: 0.6154 - auc: 0.7275 - val_loss: 0.2380 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 10814.0000 - val_fn: 194.0000 - val_accuracy: 0.9824 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5136\n",
            "Epoch 6/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.6715 - tp: 245.0000 - fp: 6157.0000 - tn: 15466.0000 - fn: 148.0000 - accuracy: 0.7136 - precision: 0.0383 - recall: 0.6234 - auc: 0.7242 - val_loss: 1.1795 - val_tp: 190.0000 - val_fp: 9241.0000 - val_tn: 1573.0000 - val_fn: 4.0000 - val_accuracy: 0.1602 - val_precision: 0.0201 - val_recall: 0.9794 - val_auc: 0.7121\n",
            "Epoch 7/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.6599 - tp: 239.0000 - fp: 6408.0000 - tn: 15219.0000 - fn: 150.0000 - accuracy: 0.7021 - precision: 0.0360 - recall: 0.6144 - auc: 0.7260 - val_loss: 0.6071 - val_tp: 146.0000 - val_fp: 4089.0000 - val_tn: 6725.0000 - val_fn: 48.0000 - val_accuracy: 0.6242 - val_precision: 0.0345 - val_recall: 0.7526 - val_auc: 0.7821\n",
            "Epoch 8/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.6270 - tp: 245.0000 - fp: 6226.0000 - tn: 15399.0000 - fn: 146.0000 - accuracy: 0.7106 - precision: 0.0379 - recall: 0.6266 - auc: 0.7391 - val_loss: 0.5532 - val_tp: 112.0000 - val_fp: 2712.0000 - val_tn: 8102.0000 - val_fn: 82.0000 - val_accuracy: 0.7462 - val_precision: 0.0397 - val_recall: 0.5773 - val_auc: 0.7448\n",
            "Epoch 9/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.7115 - tp: 233.0000 - fp: 5668.0000 - tn: 15956.0000 - fn: 159.0000 - accuracy: 0.7353 - precision: 0.0395 - recall: 0.5944 - auc: 0.7359 - val_loss: 1.7298 - val_tp: 188.0000 - val_fp: 10475.0000 - val_tn: 339.0000 - val_fn: 6.0000 - val_accuracy: 0.0479 - val_precision: 0.0176 - val_recall: 0.9691 - val_auc: 0.5713\n",
            "Epoch 10/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.6467 - tp: 248.0000 - fp: 6146.0000 - tn: 15478.0000 - fn: 144.0000 - accuracy: 0.7143 - precision: 0.0388 - recall: 0.6327 - auc: 0.7485 - val_loss: 0.5422 - val_tp: 109.0000 - val_fp: 2600.0000 - val_tn: 8214.0000 - val_fn: 85.0000 - val_accuracy: 0.7561 - val_precision: 0.0402 - val_recall: 0.5619 - val_auc: 0.7459\n",
            "Epoch 11/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5799 - tp: 273.0000 - fp: 6566.0000 - tn: 15058.0000 - fn: 119.0000 - accuracy: 0.6964 - precision: 0.0399 - recall: 0.6964 - auc: 0.7707 - val_loss: 0.4566 - val_tp: 107.0000 - val_fp: 1873.0000 - val_tn: 8941.0000 - val_fn: 87.0000 - val_accuracy: 0.8219 - val_precision: 0.0540 - val_recall: 0.5515 - val_auc: 0.7669\n",
            "Epoch 12/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5973 - tp: 276.0000 - fp: 6497.0000 - tn: 15125.0000 - fn: 118.0000 - accuracy: 0.6995 - precision: 0.0408 - recall: 0.7005 - auc: 0.7706 - val_loss: 0.3467 - val_tp: 94.0000 - val_fp: 1520.0000 - val_tn: 9294.0000 - val_fn: 100.0000 - val_accuracy: 0.8528 - val_precision: 0.0582 - val_recall: 0.4845 - val_auc: 0.7857\n",
            "Epoch 13/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5740 - tp: 278.0000 - fp: 6679.0000 - tn: 14945.0000 - fn: 114.0000 - accuracy: 0.6915 - precision: 0.0400 - recall: 0.7092 - auc: 0.7729 - val_loss: 0.5064 - val_tp: 127.0000 - val_fp: 2773.0000 - val_tn: 8041.0000 - val_fn: 67.0000 - val_accuracy: 0.7420 - val_precision: 0.0438 - val_recall: 0.6546 - val_auc: 0.7934\n",
            "Epoch 14/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5462 - tp: 285.0000 - fp: 6629.0000 - tn: 14995.0000 - fn: 107.0000 - accuracy: 0.6940 - precision: 0.0412 - recall: 0.7270 - auc: 0.7903 - val_loss: 0.4177 - val_tp: 118.0000 - val_fp: 2032.0000 - val_tn: 8782.0000 - val_fn: 76.0000 - val_accuracy: 0.8085 - val_precision: 0.0549 - val_recall: 0.6082 - val_auc: 0.7974\n",
            "Epoch 15/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5665 - tp: 266.0000 - fp: 6602.0000 - tn: 15024.0000 - fn: 124.0000 - accuracy: 0.6945 - precision: 0.0387 - recall: 0.6821 - auc: 0.7758 - val_loss: 0.4329 - val_tp: 110.0000 - val_fp: 1903.0000 - val_tn: 8911.0000 - val_fn: 84.0000 - val_accuracy: 0.8195 - val_precision: 0.0546 - val_recall: 0.5670 - val_auc: 0.7932\n",
            "Epoch 16/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5497 - tp: 284.0000 - fp: 6402.0000 - tn: 15224.0000 - fn: 106.0000 - accuracy: 0.7044 - precision: 0.0425 - recall: 0.7282 - auc: 0.7928 - val_loss: 0.3696 - val_tp: 102.0000 - val_fp: 1441.0000 - val_tn: 9373.0000 - val_fn: 92.0000 - val_accuracy: 0.8607 - val_precision: 0.0661 - val_recall: 0.5258 - val_auc: 0.7933\n",
            "Epoch 17/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5518 - tp: 290.0000 - fp: 6470.0000 - tn: 15153.0000 - fn: 103.0000 - accuracy: 0.7014 - precision: 0.0429 - recall: 0.7379 - auc: 0.7954 - val_loss: 0.3527 - val_tp: 97.0000 - val_fp: 1377.0000 - val_tn: 9437.0000 - val_fn: 97.0000 - val_accuracy: 0.8661 - val_precision: 0.0658 - val_recall: 0.5000 - val_auc: 0.7934\n",
            "Epoch 18/100\n",
            "86/86 [==============================] - 14s 164ms/step - loss: 0.5666 - tp: 282.0000 - fp: 6789.0000 - tn: 14836.0000 - fn: 109.0000 - accuracy: 0.6867 - precision: 0.0399 - recall: 0.7212 - auc: 0.7716 - val_loss: 0.3506 - val_tp: 91.0000 - val_fp: 1222.0000 - val_tn: 9592.0000 - val_fn: 103.0000 - val_accuracy: 0.8796 - val_precision: 0.0693 - val_recall: 0.4691 - val_auc: 0.7883\n",
            "Epoch 19/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.5468 - tp: 274.0000 - fp: 6095.0000 - tn: 15532.0000 - fn: 115.0000 - accuracy: 0.7179 - precision: 0.0430 - recall: 0.7044 - auc: 0.7975 - val_loss: 0.4593 - val_tp: 107.0000 - val_fp: 1944.0000 - val_tn: 8870.0000 - val_fn: 87.0000 - val_accuracy: 0.8155 - val_precision: 0.0522 - val_recall: 0.5515 - val_auc: 0.7729\n",
            "Epoch 20/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5437 - tp: 290.0000 - fp: 6667.0000 - tn: 14955.0000 - fn: 104.0000 - accuracy: 0.6925 - precision: 0.0417 - recall: 0.7360 - auc: 0.7972 - val_loss: 0.3882 - val_tp: 105.0000 - val_fp: 1692.0000 - val_tn: 9122.0000 - val_fn: 89.0000 - val_accuracy: 0.8382 - val_precision: 0.0584 - val_recall: 0.5412 - val_auc: 0.7931\n",
            "Epoch 21/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.5541 - tp: 276.0000 - fp: 6331.0000 - tn: 15294.0000 - fn: 115.0000 - accuracy: 0.7072 - precision: 0.0418 - recall: 0.7059 - auc: 0.7859 - val_loss: 0.3746 - val_tp: 99.0000 - val_fp: 1423.0000 - val_tn: 9391.0000 - val_fn: 95.0000 - val_accuracy: 0.8621 - val_precision: 0.0650 - val_recall: 0.5103 - val_auc: 0.7975\n",
            "Epoch 22/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5587 - tp: 282.0000 - fp: 6569.0000 - tn: 15054.0000 - fn: 111.0000 - accuracy: 0.6966 - precision: 0.0412 - recall: 0.7176 - auc: 0.7876 - val_loss: 0.2776 - val_tp: 73.0000 - val_fp: 734.0000 - val_tn: 10080.0000 - val_fn: 121.0000 - val_accuracy: 0.9223 - val_precision: 0.0905 - val_recall: 0.3763 - val_auc: 0.7878\n",
            "Epoch 23/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5793 - tp: 271.0000 - fp: 6242.0000 - tn: 15382.0000 - fn: 121.0000 - accuracy: 0.7110 - precision: 0.0416 - recall: 0.6913 - auc: 0.7802 - val_loss: 0.2212 - val_tp: 63.0000 - val_fp: 700.0000 - val_tn: 10114.0000 - val_fn: 131.0000 - val_accuracy: 0.9245 - val_precision: 0.0826 - val_recall: 0.3247 - val_auc: 0.7901\n",
            "Epoch 24/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.6013 - tp: 258.0000 - fp: 6291.0000 - tn: 15334.0000 - fn: 133.0000 - accuracy: 0.7082 - precision: 0.0394 - recall: 0.6598 - auc: 0.7575 - val_loss: 0.4693 - val_tp: 109.0000 - val_fp: 2027.0000 - val_tn: 8787.0000 - val_fn: 85.0000 - val_accuracy: 0.8081 - val_precision: 0.0510 - val_recall: 0.5619 - val_auc: 0.7622\n",
            "Epoch 25/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5814 - tp: 282.0000 - fp: 6541.0000 - tn: 15079.0000 - fn: 114.0000 - accuracy: 0.6977 - precision: 0.0413 - recall: 0.7121 - auc: 0.7754 - val_loss: 0.1706 - val_tp: 11.0000 - val_fp: 143.0000 - val_tn: 10671.0000 - val_fn: 183.0000 - val_accuracy: 0.9704 - val_precision: 0.0714 - val_recall: 0.0567 - val_auc: 0.5815\n",
            "Epoch 26/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.6115 - tp: 276.0000 - fp: 6094.0000 - tn: 15528.0000 - fn: 118.0000 - accuracy: 0.7178 - precision: 0.0433 - recall: 0.7005 - auc: 0.7792 - val_loss: 0.2884 - val_tp: 67.0000 - val_fp: 642.0000 - val_tn: 10172.0000 - val_fn: 127.0000 - val_accuracy: 0.9301 - val_precision: 0.0945 - val_recall: 0.3454 - val_auc: 0.7586\n",
            "Epoch 27/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5878 - tp: 259.0000 - fp: 6023.0000 - tn: 15603.0000 - fn: 131.0000 - accuracy: 0.7205 - precision: 0.0412 - recall: 0.6641 - auc: 0.7779 - val_loss: 0.2802 - val_tp: 72.0000 - val_fp: 923.0000 - val_tn: 9891.0000 - val_fn: 122.0000 - val_accuracy: 0.9051 - val_precision: 0.0724 - val_recall: 0.3711 - val_auc: 0.7869\n",
            "Epoch 28/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5359 - tp: 294.0000 - fp: 6260.0000 - tn: 15362.0000 - fn: 100.0000 - accuracy: 0.7111 - precision: 0.0449 - recall: 0.7462 - auc: 0.8079 - val_loss: 0.3681 - val_tp: 100.0000 - val_fp: 1338.0000 - val_tn: 9476.0000 - val_fn: 94.0000 - val_accuracy: 0.8699 - val_precision: 0.0695 - val_recall: 0.5155 - val_auc: 0.7940\n",
            "Epoch 29/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.5228 - tp: 296.0000 - fp: 5835.0000 - tn: 15788.0000 - fn: 97.0000 - accuracy: 0.7306 - precision: 0.0483 - recall: 0.7532 - auc: 0.8169 - val_loss: 0.2757 - val_tp: 73.0000 - val_fp: 720.0000 - val_tn: 10094.0000 - val_fn: 121.0000 - val_accuracy: 0.9236 - val_precision: 0.0921 - val_recall: 0.3763 - val_auc: 0.7920\n",
            "Epoch 30/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5239 - tp: 295.0000 - fp: 5895.0000 - tn: 15731.0000 - fn: 95.0000 - accuracy: 0.7279 - precision: 0.0477 - recall: 0.7564 - auc: 0.8140 - val_loss: 0.2806 - val_tp: 80.0000 - val_fp: 757.0000 - val_tn: 10057.0000 - val_fn: 114.0000 - val_accuracy: 0.9209 - val_precision: 0.0956 - val_recall: 0.4124 - val_auc: 0.7802\n",
            "Epoch 31/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5099 - tp: 306.0000 - fp: 6271.0000 - tn: 15354.0000 - fn: 85.0000 - accuracy: 0.7113 - precision: 0.0465 - recall: 0.7826 - auc: 0.8227 - val_loss: 0.1592 - val_tp: 35.0000 - val_fp: 255.0000 - val_tn: 10559.0000 - val_fn: 159.0000 - val_accuracy: 0.9624 - val_precision: 0.1207 - val_recall: 0.1804 - val_auc: 0.8013\n",
            "Epoch 32/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5073 - tp: 307.0000 - fp: 5845.0000 - tn: 15777.0000 - fn: 87.0000 - accuracy: 0.7306 - precision: 0.0499 - recall: 0.7792 - auc: 0.8310 - val_loss: 0.2148 - val_tp: 59.0000 - val_fp: 482.0000 - val_tn: 10332.0000 - val_fn: 135.0000 - val_accuracy: 0.9439 - val_precision: 0.1091 - val_recall: 0.3041 - val_auc: 0.7905\n",
            "Epoch 33/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5108 - tp: 298.0000 - fp: 5679.0000 - tn: 15944.0000 - fn: 95.0000 - accuracy: 0.7377 - precision: 0.0499 - recall: 0.7583 - auc: 0.8242 - val_loss: 0.1664 - val_tp: 33.0000 - val_fp: 216.0000 - val_tn: 10598.0000 - val_fn: 161.0000 - val_accuracy: 0.9658 - val_precision: 0.1325 - val_recall: 0.1701 - val_auc: 0.7762\n",
            "Epoch 34/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.4994 - tp: 298.0000 - fp: 5726.0000 - tn: 15896.0000 - fn: 96.0000 - accuracy: 0.7356 - precision: 0.0495 - recall: 0.7563 - auc: 0.8342 - val_loss: 0.2128 - val_tp: 63.0000 - val_fp: 537.0000 - val_tn: 10277.0000 - val_fn: 131.0000 - val_accuracy: 0.9393 - val_precision: 0.1050 - val_recall: 0.3247 - val_auc: 0.7868\n",
            "Epoch 35/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4990 - tp: 303.0000 - fp: 6102.0000 - tn: 15523.0000 - fn: 88.0000 - accuracy: 0.7188 - precision: 0.0473 - recall: 0.7749 - auc: 0.8289 - val_loss: 0.2076 - val_tp: 62.0000 - val_fp: 510.0000 - val_tn: 10304.0000 - val_fn: 132.0000 - val_accuracy: 0.9417 - val_precision: 0.1084 - val_recall: 0.3196 - val_auc: 0.7969\n",
            "Epoch 36/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5142 - tp: 286.0000 - fp: 6210.0000 - tn: 15415.0000 - fn: 105.0000 - accuracy: 0.7132 - precision: 0.0440 - recall: 0.7315 - auc: 0.8175 - val_loss: 0.1118 - val_tp: 17.0000 - val_fp: 85.0000 - val_tn: 10729.0000 - val_fn: 177.0000 - val_accuracy: 0.9762 - val_precision: 0.1667 - val_recall: 0.0876 - val_auc: 0.7974\n",
            "Epoch 37/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.5170 - tp: 303.0000 - fp: 6081.0000 - tn: 15540.0000 - fn: 92.0000 - accuracy: 0.7196 - precision: 0.0475 - recall: 0.7671 - auc: 0.8211 - val_loss: 0.1012 - val_tp: 13.0000 - val_fp: 83.0000 - val_tn: 10731.0000 - val_fn: 181.0000 - val_accuracy: 0.9760 - val_precision: 0.1354 - val_recall: 0.0670 - val_auc: 0.7817\n",
            "Epoch 38/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.5003 - tp: 305.0000 - fp: 5829.0000 - tn: 15794.0000 - fn: 88.0000 - accuracy: 0.7312 - precision: 0.0497 - recall: 0.7761 - auc: 0.8322 - val_loss: 0.2878 - val_tp: 73.0000 - val_fp: 796.0000 - val_tn: 10018.0000 - val_fn: 121.0000 - val_accuracy: 0.9167 - val_precision: 0.0840 - val_recall: 0.3763 - val_auc: 0.7654\n",
            "Epoch 39/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5108 - tp: 289.0000 - fp: 6115.0000 - tn: 15511.0000 - fn: 101.0000 - accuracy: 0.7177 - precision: 0.0451 - recall: 0.7410 - auc: 0.8200 - val_loss: 0.1727 - val_tp: 58.0000 - val_fp: 508.0000 - val_tn: 10306.0000 - val_fn: 136.0000 - val_accuracy: 0.9415 - val_precision: 0.1025 - val_recall: 0.2990 - val_auc: 0.7990\n",
            "Epoch 40/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5163 - tp: 290.0000 - fp: 5882.0000 - tn: 15745.0000 - fn: 99.0000 - accuracy: 0.7283 - precision: 0.0470 - recall: 0.7455 - auc: 0.8203 - val_loss: 0.1624 - val_tp: 49.0000 - val_fp: 398.0000 - val_tn: 10416.0000 - val_fn: 145.0000 - val_accuracy: 0.9507 - val_precision: 0.1096 - val_recall: 0.2526 - val_auc: 0.7950\n",
            "Epoch 41/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5288 - tp: 286.0000 - fp: 6201.0000 - tn: 15423.0000 - fn: 106.0000 - accuracy: 0.7135 - precision: 0.0441 - recall: 0.7296 - auc: 0.8096 - val_loss: 0.1778 - val_tp: 42.0000 - val_fp: 315.0000 - val_tn: 10499.0000 - val_fn: 152.0000 - val_accuracy: 0.9576 - val_precision: 0.1176 - val_recall: 0.2165 - val_auc: 0.7891\n",
            "Epoch 42/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.4986 - tp: 310.0000 - fp: 5581.0000 - tn: 16040.0000 - fn: 85.0000 - accuracy: 0.7426 - precision: 0.0526 - recall: 0.7848 - auc: 0.8394 - val_loss: 0.2109 - val_tp: 61.0000 - val_fp: 599.0000 - val_tn: 10215.0000 - val_fn: 133.0000 - val_accuracy: 0.9335 - val_precision: 0.0924 - val_recall: 0.3144 - val_auc: 0.7941\n",
            "Epoch 43/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.4922 - tp: 297.0000 - fp: 5397.0000 - tn: 16230.0000 - fn: 92.0000 - accuracy: 0.7507 - precision: 0.0522 - recall: 0.7635 - auc: 0.8395 - val_loss: 0.1079 - val_tp: 11.0000 - val_fp: 60.0000 - val_tn: 10754.0000 - val_fn: 183.0000 - val_accuracy: 0.9779 - val_precision: 0.1549 - val_recall: 0.0567 - val_auc: 0.8021\n",
            "Epoch 44/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.4755 - tp: 309.0000 - fp: 5495.0000 - tn: 16130.0000 - fn: 82.0000 - accuracy: 0.7467 - precision: 0.0532 - recall: 0.7903 - auc: 0.8507 - val_loss: 0.2059 - val_tp: 39.0000 - val_fp: 294.0000 - val_tn: 10520.0000 - val_fn: 155.0000 - val_accuracy: 0.9592 - val_precision: 0.1171 - val_recall: 0.2010 - val_auc: 0.7333\n",
            "Epoch 45/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.4628 - tp: 302.0000 - fp: 5271.0000 - tn: 16356.0000 - fn: 87.0000 - accuracy: 0.7566 - precision: 0.0542 - recall: 0.7763 - auc: 0.8566 - val_loss: 0.1561 - val_tp: 38.0000 - val_fp: 257.0000 - val_tn: 10557.0000 - val_fn: 156.0000 - val_accuracy: 0.9625 - val_precision: 0.1288 - val_recall: 0.1959 - val_auc: 0.7878\n",
            "Epoch 46/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4423 - tp: 327.0000 - fp: 5273.0000 - tn: 16352.0000 - fn: 64.0000 - accuracy: 0.7576 - precision: 0.0584 - recall: 0.8363 - auc: 0.8755 - val_loss: 0.1945 - val_tp: 51.0000 - val_fp: 509.0000 - val_tn: 10305.0000 - val_fn: 143.0000 - val_accuracy: 0.9408 - val_precision: 0.0911 - val_recall: 0.2629 - val_auc: 0.7843\n",
            "Epoch 47/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.4380 - tp: 320.0000 - fp: 5078.0000 - tn: 16546.0000 - fn: 72.0000 - accuracy: 0.7661 - precision: 0.0593 - recall: 0.8163 - auc: 0.8748 - val_loss: 0.1835 - val_tp: 54.0000 - val_fp: 518.0000 - val_tn: 10296.0000 - val_fn: 140.0000 - val_accuracy: 0.9402 - val_precision: 0.0944 - val_recall: 0.2784 - val_auc: 0.7894\n",
            "Epoch 48/100\n",
            "86/86 [==============================] - 15s 173ms/step - loss: 0.4128 - tp: 327.0000 - fp: 4900.0000 - tn: 16726.0000 - fn: 63.0000 - accuracy: 0.7746 - precision: 0.0626 - recall: 0.8385 - auc: 0.8900 - val_loss: 0.1924 - val_tp: 57.0000 - val_fp: 431.0000 - val_tn: 10383.0000 - val_fn: 137.0000 - val_accuracy: 0.9484 - val_precision: 0.1168 - val_recall: 0.2938 - val_auc: 0.7794\n",
            "Epoch 49/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4245 - tp: 312.0000 - fp: 4895.0000 - tn: 16731.0000 - fn: 78.0000 - accuracy: 0.7741 - precision: 0.0599 - recall: 0.8000 - auc: 0.8822 - val_loss: 0.1711 - val_tp: 42.0000 - val_fp: 372.0000 - val_tn: 10442.0000 - val_fn: 152.0000 - val_accuracy: 0.9524 - val_precision: 0.1014 - val_recall: 0.2165 - val_auc: 0.7775\n",
            "Epoch 50/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.4161 - tp: 332.0000 - fp: 4967.0000 - tn: 16658.0000 - fn: 59.0000 - accuracy: 0.7717 - precision: 0.0627 - recall: 0.8491 - auc: 0.8887 - val_loss: 0.1463 - val_tp: 28.0000 - val_fp: 238.0000 - val_tn: 10576.0000 - val_fn: 166.0000 - val_accuracy: 0.9633 - val_precision: 0.1053 - val_recall: 0.1443 - val_auc: 0.7646\n",
            "Epoch 51/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4461 - tp: 315.0000 - fp: 5069.0000 - tn: 16558.0000 - fn: 74.0000 - accuracy: 0.7664 - precision: 0.0585 - recall: 0.8098 - auc: 0.8699 - val_loss: 0.1972 - val_tp: 56.0000 - val_fp: 525.0000 - val_tn: 10289.0000 - val_fn: 138.0000 - val_accuracy: 0.9398 - val_precision: 0.0964 - val_recall: 0.2887 - val_auc: 0.7601\n",
            "Epoch 52/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.4186 - tp: 324.0000 - fp: 4777.0000 - tn: 16848.0000 - fn: 67.0000 - accuracy: 0.7800 - precision: 0.0635 - recall: 0.8286 - auc: 0.8876 - val_loss: 0.2607 - val_tp: 81.0000 - val_fp: 867.0000 - val_tn: 9947.0000 - val_fn: 113.0000 - val_accuracy: 0.9110 - val_precision: 0.0854 - val_recall: 0.4175 - val_auc: 0.7761\n",
            "Epoch 53/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.4569 - tp: 307.0000 - fp: 5088.0000 - tn: 16538.0000 - fn: 83.0000 - accuracy: 0.7651 - precision: 0.0569 - recall: 0.7872 - auc: 0.8642 - val_loss: 0.2634 - val_tp: 58.0000 - val_fp: 632.0000 - val_tn: 10182.0000 - val_fn: 136.0000 - val_accuracy: 0.9302 - val_precision: 0.0841 - val_recall: 0.2990 - val_auc: 0.7169\n",
            "Epoch 54/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.4541 - tp: 303.0000 - fp: 4968.0000 - tn: 16655.0000 - fn: 90.0000 - accuracy: 0.7703 - precision: 0.0575 - recall: 0.7710 - auc: 0.8657 - val_loss: 0.2195 - val_tp: 68.0000 - val_fp: 693.0000 - val_tn: 10121.0000 - val_fn: 126.0000 - val_accuracy: 0.9256 - val_precision: 0.0894 - val_recall: 0.3505 - val_auc: 0.7851\n",
            "Epoch 55/100\n",
            "86/86 [==============================] - 14s 169ms/step - loss: 0.4502 - tp: 318.0000 - fp: 5240.0000 - tn: 16385.0000 - fn: 73.0000 - accuracy: 0.7587 - precision: 0.0572 - recall: 0.8133 - auc: 0.8664 - val_loss: 0.3484 - val_tp: 91.0000 - val_fp: 1306.0000 - val_tn: 9508.0000 - val_fn: 103.0000 - val_accuracy: 0.8720 - val_precision: 0.0651 - val_recall: 0.4691 - val_auc: 0.7504\n",
            "Epoch 56/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4504 - tp: 306.0000 - fp: 4976.0000 - tn: 16650.0000 - fn: 84.0000 - accuracy: 0.7702 - precision: 0.0579 - recall: 0.7846 - auc: 0.8658 - val_loss: 0.2271 - val_tp: 61.0000 - val_fp: 713.0000 - val_tn: 10101.0000 - val_fn: 133.0000 - val_accuracy: 0.9231 - val_precision: 0.0788 - val_recall: 0.3144 - val_auc: 0.7795\n",
            "Epoch 57/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4966 - tp: 301.0000 - fp: 5139.0000 - tn: 16486.0000 - fn: 90.0000 - accuracy: 0.7625 - precision: 0.0553 - recall: 0.7698 - auc: 0.8478 - val_loss: 0.2326 - val_tp: 57.0000 - val_fp: 610.0000 - val_tn: 10204.0000 - val_fn: 137.0000 - val_accuracy: 0.9321 - val_precision: 0.0855 - val_recall: 0.2938 - val_auc: 0.7633\n",
            "Epoch 58/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4387 - tp: 309.0000 - fp: 4906.0000 - tn: 16718.0000 - fn: 83.0000 - accuracy: 0.7734 - precision: 0.0593 - recall: 0.7883 - auc: 0.8738 - val_loss: 0.3458 - val_tp: 89.0000 - val_fp: 1393.0000 - val_tn: 9421.0000 - val_fn: 105.0000 - val_accuracy: 0.8639 - val_precision: 0.0601 - val_recall: 0.4588 - val_auc: 0.7732\n",
            "Epoch 59/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.4101 - tp: 329.0000 - fp: 4618.0000 - tn: 17005.0000 - fn: 64.0000 - accuracy: 0.7873 - precision: 0.0665 - recall: 0.8372 - auc: 0.8927 - val_loss: 0.3296 - val_tp: 81.0000 - val_fp: 1160.0000 - val_tn: 9654.0000 - val_fn: 113.0000 - val_accuracy: 0.8844 - val_precision: 0.0653 - val_recall: 0.4175 - val_auc: 0.7315\n",
            "Epoch 60/100\n",
            "86/86 [==============================] - 14s 169ms/step - loss: 0.4083 - tp: 319.0000 - fp: 4513.0000 - tn: 17113.0000 - fn: 71.0000 - accuracy: 0.7918 - precision: 0.0660 - recall: 0.8179 - auc: 0.8926 - val_loss: 0.2026 - val_tp: 53.0000 - val_fp: 657.0000 - val_tn: 10157.0000 - val_fn: 141.0000 - val_accuracy: 0.9275 - val_precision: 0.0746 - val_recall: 0.2732 - val_auc: 0.7733\n",
            "Epoch 61/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.3706 - tp: 339.0000 - fp: 4365.0000 - tn: 17256.0000 - fn: 56.0000 - accuracy: 0.7992 - precision: 0.0721 - recall: 0.8582 - auc: 0.9139 - val_loss: 0.2884 - val_tp: 82.0000 - val_fp: 1001.0000 - val_tn: 9813.0000 - val_fn: 112.0000 - val_accuracy: 0.8989 - val_precision: 0.0757 - val_recall: 0.4227 - val_auc: 0.7435\n",
            "Epoch 62/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.3575 - tp: 338.0000 - fp: 4111.0000 - tn: 17514.0000 - fn: 53.0000 - accuracy: 0.8109 - precision: 0.0760 - recall: 0.8645 - auc: 0.9193 - val_loss: 0.2469 - val_tp: 72.0000 - val_fp: 851.0000 - val_tn: 9963.0000 - val_fn: 122.0000 - val_accuracy: 0.9116 - val_precision: 0.0780 - val_recall: 0.3711 - val_auc: 0.7554\n",
            "Epoch 63/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.3457 - tp: 341.0000 - fp: 4128.0000 - tn: 17497.0000 - fn: 50.0000 - accuracy: 0.8102 - precision: 0.0763 - recall: 0.8721 - auc: 0.9250 - val_loss: 0.2339 - val_tp: 63.0000 - val_fp: 746.0000 - val_tn: 10068.0000 - val_fn: 131.0000 - val_accuracy: 0.9203 - val_precision: 0.0779 - val_recall: 0.3247 - val_auc: 0.7479\n",
            "Epoch 64/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.3160 - tp: 349.0000 - fp: 3702.0000 - tn: 17922.0000 - fn: 43.0000 - accuracy: 0.8299 - precision: 0.0862 - recall: 0.8903 - auc: 0.9402 - val_loss: 0.2018 - val_tp: 55.0000 - val_fp: 555.0000 - val_tn: 10259.0000 - val_fn: 139.0000 - val_accuracy: 0.9370 - val_precision: 0.0902 - val_recall: 0.2835 - val_auc: 0.7366\n",
            "Epoch 65/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.3339 - tp: 335.0000 - fp: 3764.0000 - tn: 17863.0000 - fn: 54.0000 - accuracy: 0.8266 - precision: 0.0817 - recall: 0.8612 - auc: 0.9303 - val_loss: 0.2109 - val_tp: 59.0000 - val_fp: 603.0000 - val_tn: 10211.0000 - val_fn: 135.0000 - val_accuracy: 0.9330 - val_precision: 0.0891 - val_recall: 0.3041 - val_auc: 0.7315\n",
            "Epoch 66/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.3424 - tp: 334.0000 - fp: 3985.0000 - tn: 17640.0000 - fn: 57.0000 - accuracy: 0.8164 - precision: 0.0773 - recall: 0.8542 - auc: 0.9267 - val_loss: 0.1602 - val_tp: 36.0000 - val_fp: 373.0000 - val_tn: 10441.0000 - val_fn: 158.0000 - val_accuracy: 0.9518 - val_precision: 0.0880 - val_recall: 0.1856 - val_auc: 0.7338\n",
            "Epoch 67/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.3482 - tp: 335.0000 - fp: 4126.0000 - tn: 17499.0000 - fn: 56.0000 - accuracy: 0.8100 - precision: 0.0751 - recall: 0.8568 - auc: 0.9226 - val_loss: 0.3403 - val_tp: 90.0000 - val_fp: 1322.0000 - val_tn: 9492.0000 - val_fn: 104.0000 - val_accuracy: 0.8705 - val_precision: 0.0637 - val_recall: 0.4639 - val_auc: 0.7489\n",
            "Epoch 68/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.3278 - tp: 338.0000 - fp: 3733.0000 - tn: 17892.0000 - fn: 53.0000 - accuracy: 0.8280 - precision: 0.0830 - recall: 0.8645 - auc: 0.9333 - val_loss: 0.2394 - val_tp: 55.0000 - val_fp: 682.0000 - val_tn: 10132.0000 - val_fn: 139.0000 - val_accuracy: 0.9254 - val_precision: 0.0746 - val_recall: 0.2835 - val_auc: 0.7029\n",
            "Epoch 69/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.3558 - tp: 331.0000 - fp: 4067.0000 - tn: 17557.0000 - fn: 61.0000 - accuracy: 0.8125 - precision: 0.0753 - recall: 0.8444 - auc: 0.9180 - val_loss: 0.2412 - val_tp: 72.0000 - val_fp: 795.0000 - val_tn: 10019.0000 - val_fn: 122.0000 - val_accuracy: 0.9167 - val_precision: 0.0830 - val_recall: 0.3711 - val_auc: 0.7437\n",
            "Epoch 70/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.3648 - tp: 330.0000 - fp: 3821.0000 - tn: 17800.0000 - fn: 65.0000 - accuracy: 0.8235 - precision: 0.0795 - recall: 0.8354 - auc: 0.9169 - val_loss: 0.1907 - val_tp: 53.0000 - val_fp: 515.0000 - val_tn: 10299.0000 - val_fn: 141.0000 - val_accuracy: 0.9404 - val_precision: 0.0933 - val_recall: 0.2732 - val_auc: 0.7660\n",
            "Epoch 71/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.3809 - tp: 318.0000 - fp: 3920.0000 - tn: 17704.0000 - fn: 74.0000 - accuracy: 0.8186 - precision: 0.0750 - recall: 0.8112 - auc: 0.9086 - val_loss: 0.1681 - val_tp: 48.0000 - val_fp: 391.0000 - val_tn: 10423.0000 - val_fn: 146.0000 - val_accuracy: 0.9512 - val_precision: 0.1093 - val_recall: 0.2474 - val_auc: 0.7330\n",
            "Epoch 72/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.3953 - tp: 331.0000 - fp: 4522.0000 - tn: 17103.0000 - fn: 60.0000 - accuracy: 0.7919 - precision: 0.0682 - recall: 0.8465 - auc: 0.8998 - val_loss: 0.2735 - val_tp: 67.0000 - val_fp: 966.0000 - val_tn: 9848.0000 - val_fn: 127.0000 - val_accuracy: 0.9007 - val_precision: 0.0649 - val_recall: 0.3454 - val_auc: 0.7597\n",
            "Epoch 73/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.3575 - tp: 329.0000 - fp: 3858.0000 - tn: 17767.0000 - fn: 62.0000 - accuracy: 0.8219 - precision: 0.0786 - recall: 0.8414 - auc: 0.9187 - val_loss: 0.2195 - val_tp: 60.0000 - val_fp: 622.0000 - val_tn: 10192.0000 - val_fn: 134.0000 - val_accuracy: 0.9313 - val_precision: 0.0880 - val_recall: 0.3093 - val_auc: 0.7655\n",
            "Epoch 74/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.3559 - tp: 329.0000 - fp: 3903.0000 - tn: 17721.0000 - fn: 63.0000 - accuracy: 0.8199 - precision: 0.0777 - recall: 0.8393 - auc: 0.9199 - val_loss: 0.2139 - val_tp: 63.0000 - val_fp: 698.0000 - val_tn: 10116.0000 - val_fn: 131.0000 - val_accuracy: 0.9247 - val_precision: 0.0828 - val_recall: 0.3247 - val_auc: 0.7380\n",
            "Epoch 75/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.3266 - tp: 339.0000 - fp: 3599.0000 - tn: 18023.0000 - fn: 55.0000 - accuracy: 0.8340 - precision: 0.0861 - recall: 0.8604 - auc: 0.9336 - val_loss: 0.2433 - val_tp: 62.0000 - val_fp: 809.0000 - val_tn: 10005.0000 - val_fn: 132.0000 - val_accuracy: 0.9145 - val_precision: 0.0712 - val_recall: 0.3196 - val_auc: 0.7546\n",
            "Epoch 76/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.3013 - tp: 344.0000 - fp: 3405.0000 - tn: 18220.0000 - fn: 47.0000 - accuracy: 0.8432 - precision: 0.0918 - recall: 0.8798 - auc: 0.9438 - val_loss: 0.2277 - val_tp: 58.0000 - val_fp: 719.0000 - val_tn: 10095.0000 - val_fn: 136.0000 - val_accuracy: 0.9223 - val_precision: 0.0746 - val_recall: 0.2990 - val_auc: 0.7409\n",
            "Epoch 77/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.2937 - tp: 347.0000 - fp: 3341.0000 - tn: 18282.0000 - fn: 46.0000 - accuracy: 0.8462 - precision: 0.0941 - recall: 0.8830 - auc: 0.9465 - val_loss: 0.2332 - val_tp: 58.0000 - val_fp: 770.0000 - val_tn: 10044.0000 - val_fn: 136.0000 - val_accuracy: 0.9177 - val_precision: 0.0700 - val_recall: 0.2990 - val_auc: 0.7189\n",
            "Epoch 78/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.2787 - tp: 348.0000 - fp: 3184.0000 - tn: 18443.0000 - fn: 41.0000 - accuracy: 0.8535 - precision: 0.0985 - recall: 0.8946 - auc: 0.9524 - val_loss: 0.2417 - val_tp: 66.0000 - val_fp: 851.0000 - val_tn: 9963.0000 - val_fn: 128.0000 - val_accuracy: 0.9111 - val_precision: 0.0720 - val_recall: 0.3402 - val_auc: 0.7477\n",
            "Epoch 79/100\n",
            "86/86 [==============================] - 15s 177ms/step - loss: 0.2772 - tp: 343.0000 - fp: 3141.0000 - tn: 18484.0000 - fn: 48.0000 - accuracy: 0.8552 - precision: 0.0985 - recall: 0.8772 - auc: 0.9519 - val_loss: 0.1578 - val_tp: 48.0000 - val_fp: 397.0000 - val_tn: 10417.0000 - val_fn: 146.0000 - val_accuracy: 0.9507 - val_precision: 0.1079 - val_recall: 0.2474 - val_auc: 0.7538\n",
            "Epoch 80/100\n",
            "86/86 [==============================] - 15s 175ms/step - loss: 0.2542 - tp: 359.0000 - fp: 3114.0000 - tn: 18507.0000 - fn: 36.0000 - accuracy: 0.8569 - precision: 0.1034 - recall: 0.9089 - auc: 0.9621 - val_loss: 0.1936 - val_tp: 55.0000 - val_fp: 584.0000 - val_tn: 10230.0000 - val_fn: 139.0000 - val_accuracy: 0.9343 - val_precision: 0.0861 - val_recall: 0.2835 - val_auc: 0.7512\n",
            "Epoch 81/100\n",
            "86/86 [==============================] - 15s 178ms/step - loss: 0.2417 - tp: 358.0000 - fp: 2747.0000 - tn: 18876.0000 - fn: 35.0000 - accuracy: 0.8736 - precision: 0.1153 - recall: 0.9109 - auc: 0.9662 - val_loss: 0.1629 - val_tp: 48.0000 - val_fp: 387.0000 - val_tn: 10427.0000 - val_fn: 146.0000 - val_accuracy: 0.9516 - val_precision: 0.1103 - val_recall: 0.2474 - val_auc: 0.7412\n",
            "Epoch 82/100\n",
            "86/86 [==============================] - 15s 173ms/step - loss: 0.2590 - tp: 349.0000 - fp: 2981.0000 - tn: 18643.0000 - fn: 43.0000 - accuracy: 0.8626 - precision: 0.1048 - recall: 0.8903 - auc: 0.9591 - val_loss: 0.1395 - val_tp: 35.0000 - val_fp: 253.0000 - val_tn: 10561.0000 - val_fn: 159.0000 - val_accuracy: 0.9626 - val_precision: 0.1215 - val_recall: 0.1804 - val_auc: 0.7471\n",
            "Epoch 83/100\n",
            "86/86 [==============================] - 15s 176ms/step - loss: 0.2432 - tp: 362.0000 - fp: 2764.0000 - tn: 18859.0000 - fn: 31.0000 - accuracy: 0.8730 - precision: 0.1158 - recall: 0.9211 - auc: 0.9652 - val_loss: 0.1151 - val_tp: 22.0000 - val_fp: 157.0000 - val_tn: 10657.0000 - val_fn: 172.0000 - val_accuracy: 0.9701 - val_precision: 0.1229 - val_recall: 0.1134 - val_auc: 0.7223\n",
            "Epoch 84/100\n",
            "86/86 [==============================] - 15s 172ms/step - loss: 0.2668 - tp: 352.0000 - fp: 3169.0000 - tn: 18455.0000 - fn: 40.0000 - accuracy: 0.8542 - precision: 0.1000 - recall: 0.8980 - auc: 0.9552 - val_loss: 0.1150 - val_tp: 20.0000 - val_fp: 170.0000 - val_tn: 10644.0000 - val_fn: 174.0000 - val_accuracy: 0.9688 - val_precision: 0.1053 - val_recall: 0.1031 - val_auc: 0.7469\n",
            "Epoch 1/100\n",
            " 2/86 [..............................] - ETA: 7s - loss: 2.2134 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 503.0000 - fn: 9.0000 - accuracy: 0.9824 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.3932WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0328s vs `on_train_batch_end` time: 0.1217s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0328s vs `on_train_batch_end` time: 0.1217s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "86/86 [==============================] - ETA: 0s - loss: 2.1175 - tp: 2.0000 - fp: 68.0000 - tn: 21557.0000 - fn: 389.0000 - accuracy: 0.9792 - precision: 0.0286 - recall: 0.0051 - auc: 0.5094WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0046s vs `on_test_batch_end` time: 0.0609s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0046s vs `on_test_batch_end` time: 0.0609s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r86/86 [==============================] - 25s 296ms/step - loss: 2.1175 - tp: 2.0000 - fp: 68.0000 - tn: 21557.0000 - fn: 389.0000 - accuracy: 0.9792 - precision: 0.0286 - recall: 0.0051 - auc: 0.5094 - val_loss: 0.1155 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 10815.0000 - val_fn: 193.0000 - val_accuracy: 0.9825 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
            "Epoch 2/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 1.6840 - tp: 21.0000 - fp: 646.0000 - tn: 20978.0000 - fn: 371.0000 - accuracy: 0.9538 - precision: 0.0315 - recall: 0.0536 - auc: 0.6065 - val_loss: 0.2127 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 10815.0000 - val_fn: 193.0000 - val_accuracy: 0.9825 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6600\n",
            "Epoch 3/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 1.0561 - tp: 126.0000 - fp: 3302.0000 - tn: 18322.0000 - fn: 266.0000 - accuracy: 0.8379 - precision: 0.0368 - recall: 0.3214 - auc: 0.6625 - val_loss: 0.1706 - val_tp: 7.0000 - val_fp: 43.0000 - val_tn: 10772.0000 - val_fn: 186.0000 - val_accuracy: 0.9792 - val_precision: 0.1400 - val_recall: 0.0363 - val_auc: 0.6963\n",
            "Epoch 4/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.7385 - tp: 225.0000 - fp: 5962.0000 - tn: 15664.0000 - fn: 165.0000 - accuracy: 0.7217 - precision: 0.0364 - recall: 0.5769 - auc: 0.7241 - val_loss: 0.0895 - val_tp: 2.0000 - val_fp: 8.0000 - val_tn: 10807.0000 - val_fn: 191.0000 - val_accuracy: 0.9819 - val_precision: 0.2000 - val_recall: 0.0104 - val_auc: 0.7416\n",
            "Epoch 5/100\n",
            "86/86 [==============================] - 15s 172ms/step - loss: 0.7175 - tp: 221.0000 - fp: 5661.0000 - tn: 15963.0000 - fn: 171.0000 - accuracy: 0.7351 - precision: 0.0376 - recall: 0.5638 - auc: 0.7257 - val_loss: 0.4592 - val_tp: 102.0000 - val_fp: 1849.0000 - val_tn: 8966.0000 - val_fn: 91.0000 - val_accuracy: 0.8238 - val_precision: 0.0523 - val_recall: 0.5285 - val_auc: 0.7420\n",
            "Epoch 6/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.6483 - tp: 241.0000 - fp: 6506.0000 - tn: 15120.0000 - fn: 149.0000 - accuracy: 0.6977 - precision: 0.0357 - recall: 0.6179 - auc: 0.7298 - val_loss: 0.3294 - val_tp: 81.0000 - val_fp: 1210.0000 - val_tn: 9605.0000 - val_fn: 112.0000 - val_accuracy: 0.8799 - val_precision: 0.0627 - val_recall: 0.4197 - val_auc: 0.7735\n",
            "Epoch 7/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.6245 - tp: 254.0000 - fp: 6662.0000 - tn: 14963.0000 - fn: 137.0000 - accuracy: 0.6912 - precision: 0.0367 - recall: 0.6496 - auc: 0.7508 - val_loss: 0.8717 - val_tp: 168.0000 - val_fp: 6754.0000 - val_tn: 4061.0000 - val_fn: 25.0000 - val_accuracy: 0.3842 - val_precision: 0.0243 - val_recall: 0.8705 - val_auc: 0.7214\n",
            "Epoch 8/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.6189 - tp: 249.0000 - fp: 6237.0000 - tn: 15389.0000 - fn: 141.0000 - accuracy: 0.7103 - precision: 0.0384 - recall: 0.6385 - auc: 0.7517 - val_loss: 0.8028 - val_tp: 156.0000 - val_fp: 5754.0000 - val_tn: 5061.0000 - val_fn: 37.0000 - val_accuracy: 0.4739 - val_precision: 0.0264 - val_recall: 0.8083 - val_auc: 0.7451\n",
            "Epoch 9/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.6147 - tp: 254.0000 - fp: 6476.0000 - tn: 15149.0000 - fn: 137.0000 - accuracy: 0.6996 - precision: 0.0377 - recall: 0.6496 - auc: 0.7516 - val_loss: 0.5312 - val_tp: 130.0000 - val_fp: 3550.0000 - val_tn: 7265.0000 - val_fn: 63.0000 - val_accuracy: 0.6718 - val_precision: 0.0353 - val_recall: 0.6736 - val_auc: 0.7632\n",
            "Epoch 10/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.6013 - tp: 251.0000 - fp: 6595.0000 - tn: 15030.0000 - fn: 140.0000 - accuracy: 0.6941 - precision: 0.0367 - recall: 0.6419 - auc: 0.7539 - val_loss: 0.5846 - val_tp: 127.0000 - val_fp: 3437.0000 - val_tn: 7378.0000 - val_fn: 66.0000 - val_accuracy: 0.6818 - val_precision: 0.0356 - val_recall: 0.6580 - val_auc: 0.7608\n",
            "Epoch 11/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.5734 - tp: 278.0000 - fp: 7220.0000 - tn: 14406.0000 - fn: 112.0000 - accuracy: 0.6670 - precision: 0.0371 - recall: 0.7128 - auc: 0.7656 - val_loss: 0.7491 - val_tp: 165.0000 - val_fp: 5681.0000 - val_tn: 5134.0000 - val_fn: 28.0000 - val_accuracy: 0.4814 - val_precision: 0.0282 - val_recall: 0.8549 - val_auc: 0.7663\n",
            "Epoch 12/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.5845 - tp: 273.0000 - fp: 6723.0000 - tn: 14901.0000 - fn: 119.0000 - accuracy: 0.6892 - precision: 0.0390 - recall: 0.6964 - auc: 0.7636 - val_loss: 0.4828 - val_tp: 117.0000 - val_fp: 2423.0000 - val_tn: 8392.0000 - val_fn: 76.0000 - val_accuracy: 0.7730 - val_precision: 0.0461 - val_recall: 0.6062 - val_auc: 0.7801\n",
            "Epoch 13/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5753 - tp: 264.0000 - fp: 6786.0000 - tn: 14840.0000 - fn: 126.0000 - accuracy: 0.6860 - precision: 0.0374 - recall: 0.6769 - auc: 0.7665 - val_loss: 0.3841 - val_tp: 106.0000 - val_fp: 2296.0000 - val_tn: 8519.0000 - val_fn: 87.0000 - val_accuracy: 0.7835 - val_precision: 0.0441 - val_recall: 0.5492 - val_auc: 0.7737\n",
            "Epoch 14/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.5591 - tp: 273.0000 - fp: 6959.0000 - tn: 14664.0000 - fn: 120.0000 - accuracy: 0.6785 - precision: 0.0377 - recall: 0.6947 - auc: 0.7774 - val_loss: 0.4883 - val_tp: 131.0000 - val_fp: 3195.0000 - val_tn: 7620.0000 - val_fn: 62.0000 - val_accuracy: 0.7041 - val_precision: 0.0394 - val_recall: 0.6788 - val_auc: 0.7882\n",
            "Epoch 15/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5584 - tp: 291.0000 - fp: 6782.0000 - tn: 14842.0000 - fn: 101.0000 - accuracy: 0.6874 - precision: 0.0411 - recall: 0.7423 - auc: 0.7885 - val_loss: 0.4616 - val_tp: 125.0000 - val_fp: 2985.0000 - val_tn: 7830.0000 - val_fn: 68.0000 - val_accuracy: 0.7227 - val_precision: 0.0402 - val_recall: 0.6477 - val_auc: 0.7835\n",
            "Epoch 16/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.5442 - tp: 298.0000 - fp: 6807.0000 - tn: 14817.0000 - fn: 94.0000 - accuracy: 0.6865 - precision: 0.0419 - recall: 0.7602 - auc: 0.7906 - val_loss: 0.3750 - val_tp: 107.0000 - val_fp: 2061.0000 - val_tn: 8754.0000 - val_fn: 86.0000 - val_accuracy: 0.8050 - val_precision: 0.0494 - val_recall: 0.5544 - val_auc: 0.7801\n",
            "Epoch 17/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.5406 - tp: 294.0000 - fp: 6891.0000 - tn: 14734.0000 - fn: 97.0000 - accuracy: 0.6826 - precision: 0.0409 - recall: 0.7519 - auc: 0.7922 - val_loss: 0.4294 - val_tp: 118.0000 - val_fp: 2552.0000 - val_tn: 8263.0000 - val_fn: 75.0000 - val_accuracy: 0.7614 - val_precision: 0.0442 - val_recall: 0.6114 - val_auc: 0.7837\n",
            "Epoch 18/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.5476 - tp: 292.0000 - fp: 6948.0000 - tn: 14677.0000 - fn: 99.0000 - accuracy: 0.6799 - precision: 0.0403 - recall: 0.7468 - auc: 0.7862 - val_loss: 0.4363 - val_tp: 118.0000 - val_fp: 2646.0000 - val_tn: 8169.0000 - val_fn: 75.0000 - val_accuracy: 0.7528 - val_precision: 0.0427 - val_recall: 0.6114 - val_auc: 0.7793\n",
            "Epoch 19/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.5534 - tp: 284.0000 - fp: 6738.0000 - tn: 14883.0000 - fn: 111.0000 - accuracy: 0.6889 - precision: 0.0404 - recall: 0.7190 - auc: 0.7879 - val_loss: 0.7797 - val_tp: 147.0000 - val_fp: 5307.0000 - val_tn: 5508.0000 - val_fn: 46.0000 - val_accuracy: 0.5137 - val_precision: 0.0270 - val_recall: 0.7617 - val_auc: 0.7163\n",
            "Epoch 20/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.6220 - tp: 264.0000 - fp: 5826.0000 - tn: 15799.0000 - fn: 127.0000 - accuracy: 0.7296 - precision: 0.0433 - recall: 0.6752 - auc: 0.7798 - val_loss: 0.8320 - val_tp: 175.0000 - val_fp: 5989.0000 - val_tn: 4826.0000 - val_fn: 18.0000 - val_accuracy: 0.4543 - val_precision: 0.0284 - val_recall: 0.9067 - val_auc: 0.7605\n",
            "Epoch 21/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.5722 - tp: 286.0000 - fp: 6576.0000 - tn: 15047.0000 - fn: 107.0000 - accuracy: 0.6964 - precision: 0.0417 - recall: 0.7277 - auc: 0.7769 - val_loss: 0.7128 - val_tp: 142.0000 - val_fp: 4836.0000 - val_tn: 5979.0000 - val_fn: 51.0000 - val_accuracy: 0.5561 - val_precision: 0.0285 - val_recall: 0.7358 - val_auc: 0.7042\n",
            "Epoch 22/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5690 - tp: 285.0000 - fp: 6811.0000 - tn: 14809.0000 - fn: 111.0000 - accuracy: 0.6856 - precision: 0.0402 - recall: 0.7197 - auc: 0.7773 - val_loss: 0.5943 - val_tp: 157.0000 - val_fp: 4437.0000 - val_tn: 6378.0000 - val_fn: 36.0000 - val_accuracy: 0.5937 - val_precision: 0.0342 - val_recall: 0.8135 - val_auc: 0.7785\n",
            "Epoch 23/100\n",
            "86/86 [==============================] - 14s 169ms/step - loss: 0.5517 - tp: 286.0000 - fp: 6736.0000 - tn: 14888.0000 - fn: 106.0000 - accuracy: 0.6892 - precision: 0.0407 - recall: 0.7296 - auc: 0.7843 - val_loss: 0.3834 - val_tp: 107.0000 - val_fp: 2203.0000 - val_tn: 8612.0000 - val_fn: 86.0000 - val_accuracy: 0.7921 - val_precision: 0.0463 - val_recall: 0.5544 - val_auc: 0.7689\n",
            "Epoch 24/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5858 - tp: 275.0000 - fp: 6611.0000 - tn: 15013.0000 - fn: 117.0000 - accuracy: 0.6944 - precision: 0.0399 - recall: 0.7015 - auc: 0.7771 - val_loss: 0.3896 - val_tp: 109.0000 - val_fp: 2283.0000 - val_tn: 8532.0000 - val_fn: 84.0000 - val_accuracy: 0.7850 - val_precision: 0.0456 - val_recall: 0.5648 - val_auc: 0.7785\n",
            "Epoch 25/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5794 - tp: 268.0000 - fp: 6362.0000 - tn: 15257.0000 - fn: 129.0000 - accuracy: 0.7052 - precision: 0.0404 - recall: 0.6751 - auc: 0.7750 - val_loss: 0.2673 - val_tp: 72.0000 - val_fp: 1056.0000 - val_tn: 9759.0000 - val_fn: 121.0000 - val_accuracy: 0.8931 - val_precision: 0.0638 - val_recall: 0.3731 - val_auc: 0.7852\n",
            "Epoch 26/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.5687 - tp: 273.0000 - fp: 6903.0000 - tn: 14720.0000 - fn: 120.0000 - accuracy: 0.6810 - precision: 0.0380 - recall: 0.6947 - auc: 0.7722 - val_loss: 0.3390 - val_tp: 98.0000 - val_fp: 1608.0000 - val_tn: 9207.0000 - val_fn: 95.0000 - val_accuracy: 0.8453 - val_precision: 0.0574 - val_recall: 0.5078 - val_auc: 0.7903\n",
            "Epoch 27/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5488 - tp: 279.0000 - fp: 6458.0000 - tn: 15165.0000 - fn: 114.0000 - accuracy: 0.7015 - precision: 0.0414 - recall: 0.7099 - auc: 0.7965 - val_loss: 0.3497 - val_tp: 100.0000 - val_fp: 1697.0000 - val_tn: 9118.0000 - val_fn: 93.0000 - val_accuracy: 0.8374 - val_precision: 0.0556 - val_recall: 0.5181 - val_auc: 0.7900\n",
            "Epoch 28/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5544 - tp: 272.0000 - fp: 6217.0000 - tn: 15404.0000 - fn: 123.0000 - accuracy: 0.7120 - precision: 0.0419 - recall: 0.6886 - auc: 0.7882 - val_loss: 0.4599 - val_tp: 94.0000 - val_fp: 1831.0000 - val_tn: 8984.0000 - val_fn: 99.0000 - val_accuracy: 0.8247 - val_precision: 0.0488 - val_recall: 0.4870 - val_auc: 0.7323\n",
            "Epoch 29/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5282 - tp: 298.0000 - fp: 6580.0000 - tn: 15043.0000 - fn: 95.0000 - accuracy: 0.6968 - precision: 0.0433 - recall: 0.7583 - auc: 0.8055 - val_loss: 0.4523 - val_tp: 99.0000 - val_fp: 2153.0000 - val_tn: 8662.0000 - val_fn: 94.0000 - val_accuracy: 0.7959 - val_precision: 0.0440 - val_recall: 0.5130 - val_auc: 0.7726\n",
            "Epoch 30/100\n",
            "86/86 [==============================] - 15s 172ms/step - loss: 0.5239 - tp: 298.0000 - fp: 6403.0000 - tn: 15221.0000 - fn: 94.0000 - accuracy: 0.7049 - precision: 0.0445 - recall: 0.7602 - auc: 0.8068 - val_loss: 0.3193 - val_tp: 85.0000 - val_fp: 1133.0000 - val_tn: 9682.0000 - val_fn: 108.0000 - val_accuracy: 0.8873 - val_precision: 0.0698 - val_recall: 0.4404 - val_auc: 0.7979\n",
            "Epoch 31/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5084 - tp: 304.0000 - fp: 6426.0000 - tn: 15200.0000 - fn: 86.0000 - accuracy: 0.7042 - precision: 0.0452 - recall: 0.7795 - auc: 0.8183 - val_loss: 0.4138 - val_tp: 100.0000 - val_fp: 1667.0000 - val_tn: 9148.0000 - val_fn: 93.0000 - val_accuracy: 0.8401 - val_precision: 0.0566 - val_recall: 0.5181 - val_auc: 0.7763\n",
            "Epoch 32/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5040 - tp: 310.0000 - fp: 6135.0000 - tn: 15486.0000 - fn: 85.0000 - accuracy: 0.7175 - precision: 0.0481 - recall: 0.7848 - auc: 0.8275 - val_loss: 0.4175 - val_tp: 110.0000 - val_fp: 1794.0000 - val_tn: 9021.0000 - val_fn: 83.0000 - val_accuracy: 0.8295 - val_precision: 0.0578 - val_recall: 0.5699 - val_auc: 0.7885\n",
            "Epoch 33/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5005 - tp: 306.0000 - fp: 6172.0000 - tn: 15449.0000 - fn: 89.0000 - accuracy: 0.7156 - precision: 0.0472 - recall: 0.7747 - auc: 0.8279 - val_loss: 0.4024 - val_tp: 109.0000 - val_fp: 1780.0000 - val_tn: 9035.0000 - val_fn: 84.0000 - val_accuracy: 0.8307 - val_precision: 0.0577 - val_recall: 0.5648 - val_auc: 0.7910\n",
            "Epoch 34/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4976 - tp: 310.0000 - fp: 6155.0000 - tn: 15470.0000 - fn: 81.0000 - accuracy: 0.7168 - precision: 0.0480 - recall: 0.7928 - auc: 0.8324 - val_loss: 0.4125 - val_tp: 103.0000 - val_fp: 1766.0000 - val_tn: 9049.0000 - val_fn: 90.0000 - val_accuracy: 0.8314 - val_precision: 0.0551 - val_recall: 0.5337 - val_auc: 0.7828\n",
            "Epoch 35/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5506 - tp: 282.0000 - fp: 5729.0000 - tn: 15898.0000 - fn: 107.0000 - accuracy: 0.7349 - precision: 0.0469 - recall: 0.7249 - auc: 0.8175 - val_loss: 0.1995 - val_tp: 36.0000 - val_fp: 333.0000 - val_tn: 10482.0000 - val_fn: 157.0000 - val_accuracy: 0.9555 - val_precision: 0.0976 - val_recall: 0.1865 - val_auc: 0.7729\n",
            "Epoch 36/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5290 - tp: 295.0000 - fp: 6191.0000 - tn: 15434.0000 - fn: 96.0000 - accuracy: 0.7144 - precision: 0.0455 - recall: 0.7545 - auc: 0.8112 - val_loss: 0.3253 - val_tp: 83.0000 - val_fp: 1315.0000 - val_tn: 9500.0000 - val_fn: 110.0000 - val_accuracy: 0.8705 - val_precision: 0.0594 - val_recall: 0.4301 - val_auc: 0.7751\n",
            "Epoch 37/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5168 - tp: 291.0000 - fp: 6131.0000 - tn: 15493.0000 - fn: 101.0000 - accuracy: 0.7169 - precision: 0.0453 - recall: 0.7423 - auc: 0.8176 - val_loss: 0.6692 - val_tp: 142.0000 - val_fp: 4329.0000 - val_tn: 6486.0000 - val_fn: 51.0000 - val_accuracy: 0.6021 - val_precision: 0.0318 - val_recall: 0.7358 - val_auc: 0.7535\n",
            "Epoch 38/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5242 - tp: 299.0000 - fp: 6217.0000 - tn: 15403.0000 - fn: 97.0000 - accuracy: 0.7132 - precision: 0.0459 - recall: 0.7551 - auc: 0.8163 - val_loss: 0.6280 - val_tp: 155.0000 - val_fp: 4241.0000 - val_tn: 6574.0000 - val_fn: 38.0000 - val_accuracy: 0.6113 - val_precision: 0.0353 - val_recall: 0.8031 - val_auc: 0.7877\n",
            "Epoch 39/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5164 - tp: 293.0000 - fp: 6236.0000 - tn: 15388.0000 - fn: 99.0000 - accuracy: 0.7123 - precision: 0.0449 - recall: 0.7474 - auc: 0.8148 - val_loss: 0.2160 - val_tp: 45.0000 - val_fp: 548.0000 - val_tn: 10267.0000 - val_fn: 148.0000 - val_accuracy: 0.9368 - val_precision: 0.0759 - val_recall: 0.2332 - val_auc: 0.7783\n",
            "Epoch 40/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5252 - tp: 293.0000 - fp: 6306.0000 - tn: 15320.0000 - fn: 97.0000 - accuracy: 0.7092 - precision: 0.0444 - recall: 0.7513 - auc: 0.8096 - val_loss: 0.4660 - val_tp: 126.0000 - val_fp: 2711.0000 - val_tn: 8104.0000 - val_fn: 67.0000 - val_accuracy: 0.7476 - val_precision: 0.0444 - val_recall: 0.6528 - val_auc: 0.7847\n",
            "Epoch 41/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.4960 - tp: 304.0000 - fp: 6058.0000 - tn: 15567.0000 - fn: 87.0000 - accuracy: 0.7209 - precision: 0.0478 - recall: 0.7775 - auc: 0.8303 - val_loss: 0.6327 - val_tp: 160.0000 - val_fp: 4359.0000 - val_tn: 6456.0000 - val_fn: 33.0000 - val_accuracy: 0.6010 - val_precision: 0.0354 - val_recall: 0.8290 - val_auc: 0.7890\n",
            "Epoch 42/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5026 - tp: 305.0000 - fp: 5951.0000 - tn: 15673.0000 - fn: 87.0000 - accuracy: 0.7257 - precision: 0.0488 - recall: 0.7781 - auc: 0.8286 - val_loss: 0.2020 - val_tp: 40.0000 - val_fp: 577.0000 - val_tn: 10238.0000 - val_fn: 153.0000 - val_accuracy: 0.9337 - val_precision: 0.0648 - val_recall: 0.2073 - val_auc: 0.7495\n",
            "Epoch 43/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4836 - tp: 316.0000 - fp: 5874.0000 - tn: 15749.0000 - fn: 77.0000 - accuracy: 0.7297 - precision: 0.0511 - recall: 0.8041 - auc: 0.8410 - val_loss: 0.2940 - val_tp: 79.0000 - val_fp: 1179.0000 - val_tn: 9636.0000 - val_fn: 114.0000 - val_accuracy: 0.8825 - val_precision: 0.0628 - val_recall: 0.4093 - val_auc: 0.7817\n",
            "Epoch 44/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4818 - tp: 310.0000 - fp: 5554.0000 - tn: 16071.0000 - fn: 81.0000 - accuracy: 0.7440 - precision: 0.0529 - recall: 0.7928 - auc: 0.8467 - val_loss: 0.4966 - val_tp: 122.0000 - val_fp: 2806.0000 - val_tn: 8009.0000 - val_fn: 71.0000 - val_accuracy: 0.7386 - val_precision: 0.0417 - val_recall: 0.6321 - val_auc: 0.7820\n",
            "Epoch 45/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.4710 - tp: 308.0000 - fp: 5368.0000 - tn: 16256.0000 - fn: 84.0000 - accuracy: 0.7524 - precision: 0.0543 - recall: 0.7857 - auc: 0.8525 - val_loss: 0.3343 - val_tp: 88.0000 - val_fp: 1554.0000 - val_tn: 9261.0000 - val_fn: 105.0000 - val_accuracy: 0.8493 - val_precision: 0.0536 - val_recall: 0.4560 - val_auc: 0.7869\n",
            "Epoch 46/100\n",
            "86/86 [==============================] - 15s 172ms/step - loss: 0.4471 - tp: 321.0000 - fp: 5196.0000 - tn: 16428.0000 - fn: 71.0000 - accuracy: 0.7608 - precision: 0.0582 - recall: 0.8189 - auc: 0.8698 - val_loss: 0.2712 - val_tp: 61.0000 - val_fp: 766.0000 - val_tn: 10049.0000 - val_fn: 132.0000 - val_accuracy: 0.9184 - val_precision: 0.0738 - val_recall: 0.3161 - val_auc: 0.7721\n",
            "Epoch 47/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.4406 - tp: 323.0000 - fp: 5380.0000 - tn: 16244.0000 - fn: 69.0000 - accuracy: 0.7525 - precision: 0.0566 - recall: 0.8240 - auc: 0.8714 - val_loss: 0.3581 - val_tp: 87.0000 - val_fp: 1565.0000 - val_tn: 9250.0000 - val_fn: 106.0000 - val_accuracy: 0.8482 - val_precision: 0.0527 - val_recall: 0.4508 - val_auc: 0.7714\n",
            "Epoch 48/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.4299 - tp: 327.0000 - fp: 5148.0000 - tn: 16476.0000 - fn: 65.0000 - accuracy: 0.7632 - precision: 0.0597 - recall: 0.8342 - auc: 0.8792 - val_loss: 0.3038 - val_tp: 78.0000 - val_fp: 1203.0000 - val_tn: 9612.0000 - val_fn: 115.0000 - val_accuracy: 0.8803 - val_precision: 0.0609 - val_recall: 0.4041 - val_auc: 0.7710\n",
            "Epoch 49/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.4272 - tp: 323.0000 - fp: 4984.0000 - tn: 16640.0000 - fn: 69.0000 - accuracy: 0.7705 - precision: 0.0609 - recall: 0.8240 - auc: 0.8794 - val_loss: 0.3194 - val_tp: 86.0000 - val_fp: 1352.0000 - val_tn: 9463.0000 - val_fn: 107.0000 - val_accuracy: 0.8675 - val_precision: 0.0598 - val_recall: 0.4456 - val_auc: 0.7784\n",
            "Epoch 50/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.4170 - tp: 325.0000 - fp: 5017.0000 - tn: 16605.0000 - fn: 69.0000 - accuracy: 0.7690 - precision: 0.0608 - recall: 0.8249 - auc: 0.8878 - val_loss: 0.3327 - val_tp: 83.0000 - val_fp: 1448.0000 - val_tn: 9367.0000 - val_fn: 110.0000 - val_accuracy: 0.8585 - val_precision: 0.0542 - val_recall: 0.4301 - val_auc: 0.7743\n",
            "Epoch 51/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4221 - tp: 324.0000 - fp: 4847.0000 - tn: 16778.0000 - fn: 67.0000 - accuracy: 0.7768 - precision: 0.0627 - recall: 0.8286 - auc: 0.8836 - val_loss: 0.2097 - val_tp: 54.0000 - val_fp: 616.0000 - val_tn: 10199.0000 - val_fn: 139.0000 - val_accuracy: 0.9314 - val_precision: 0.0806 - val_recall: 0.2798 - val_auc: 0.7741\n",
            "Epoch 52/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.4270 - tp: 317.0000 - fp: 5140.0000 - tn: 16485.0000 - fn: 74.0000 - accuracy: 0.7632 - precision: 0.0581 - recall: 0.8107 - auc: 0.8790 - val_loss: 0.2312 - val_tp: 56.0000 - val_fp: 818.0000 - val_tn: 9997.0000 - val_fn: 137.0000 - val_accuracy: 0.9132 - val_precision: 0.0641 - val_recall: 0.2902 - val_auc: 0.7710\n",
            "Epoch 53/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.4407 - tp: 317.0000 - fp: 4939.0000 - tn: 16681.0000 - fn: 79.0000 - accuracy: 0.7721 - precision: 0.0603 - recall: 0.8005 - auc: 0.8738 - val_loss: 0.2053 - val_tp: 49.0000 - val_fp: 594.0000 - val_tn: 10221.0000 - val_fn: 144.0000 - val_accuracy: 0.9330 - val_precision: 0.0762 - val_recall: 0.2539 - val_auc: 0.7778\n",
            "Epoch 54/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.4323 - tp: 314.0000 - fp: 5196.0000 - tn: 16431.0000 - fn: 75.0000 - accuracy: 0.7606 - precision: 0.0570 - recall: 0.8072 - auc: 0.8755 - val_loss: 0.2386 - val_tp: 61.0000 - val_fp: 835.0000 - val_tn: 9980.0000 - val_fn: 132.0000 - val_accuracy: 0.9122 - val_precision: 0.0681 - val_recall: 0.3161 - val_auc: 0.7662\n",
            "Epoch 55/100\n",
            "86/86 [==============================] - 14s 169ms/step - loss: 0.4561 - tp: 308.0000 - fp: 5250.0000 - tn: 16378.0000 - fn: 80.0000 - accuracy: 0.7579 - precision: 0.0554 - recall: 0.7938 - auc: 0.8611 - val_loss: 0.1516 - val_tp: 15.0000 - val_fp: 232.0000 - val_tn: 10583.0000 - val_fn: 178.0000 - val_accuracy: 0.9628 - val_precision: 0.0607 - val_recall: 0.0777 - val_auc: 0.7065\n",
            "Epoch 56/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.4637 - tp: 311.0000 - fp: 5422.0000 - tn: 16202.0000 - fn: 81.0000 - accuracy: 0.7500 - precision: 0.0542 - recall: 0.7934 - auc: 0.8564 - val_loss: 0.1443 - val_tp: 24.0000 - val_fp: 233.0000 - val_tn: 10582.0000 - val_fn: 169.0000 - val_accuracy: 0.9635 - val_precision: 0.0934 - val_recall: 0.1244 - val_auc: 0.7885\n",
            "Epoch 57/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4411 - tp: 314.0000 - fp: 4942.0000 - tn: 16683.0000 - fn: 77.0000 - accuracy: 0.7720 - precision: 0.0597 - recall: 0.8031 - auc: 0.8717 - val_loss: 0.2367 - val_tp: 64.0000 - val_fp: 832.0000 - val_tn: 9983.0000 - val_fn: 129.0000 - val_accuracy: 0.9127 - val_precision: 0.0714 - val_recall: 0.3316 - val_auc: 0.7588\n",
            "Epoch 58/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4151 - tp: 324.0000 - fp: 4879.0000 - tn: 16743.0000 - fn: 70.0000 - accuracy: 0.7752 - precision: 0.0623 - recall: 0.8223 - auc: 0.8884 - val_loss: 0.1874 - val_tp: 34.0000 - val_fp: 391.0000 - val_tn: 10424.0000 - val_fn: 159.0000 - val_accuracy: 0.9500 - val_precision: 0.0800 - val_recall: 0.1762 - val_auc: 0.7509\n",
            "Epoch 59/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4156 - tp: 327.0000 - fp: 4876.0000 - tn: 16749.0000 - fn: 64.0000 - accuracy: 0.7756 - precision: 0.0628 - recall: 0.8363 - auc: 0.8863 - val_loss: 0.2502 - val_tp: 55.0000 - val_fp: 842.0000 - val_tn: 9973.0000 - val_fn: 138.0000 - val_accuracy: 0.9110 - val_precision: 0.0613 - val_recall: 0.2850 - val_auc: 0.7629\n",
            "Epoch 60/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.4149 - tp: 319.0000 - fp: 4779.0000 - tn: 16845.0000 - fn: 73.0000 - accuracy: 0.7796 - precision: 0.0626 - recall: 0.8138 - auc: 0.8868 - val_loss: 0.1778 - val_tp: 25.0000 - val_fp: 414.0000 - val_tn: 10401.0000 - val_fn: 168.0000 - val_accuracy: 0.9471 - val_precision: 0.0569 - val_recall: 0.1295 - val_auc: 0.7503\n",
            "Epoch 61/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.3693 - tp: 334.0000 - fp: 4129.0000 - tn: 17493.0000 - fn: 60.0000 - accuracy: 0.8097 - precision: 0.0748 - recall: 0.8477 - auc: 0.9131 - val_loss: 0.1981 - val_tp: 46.0000 - val_fp: 576.0000 - val_tn: 10239.0000 - val_fn: 147.0000 - val_accuracy: 0.9343 - val_precision: 0.0740 - val_recall: 0.2383 - val_auc: 0.7598\n",
            "Epoch 62/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.3596 - tp: 340.0000 - fp: 3974.0000 - tn: 17649.0000 - fn: 53.0000 - accuracy: 0.8171 - precision: 0.0788 - recall: 0.8651 - auc: 0.9187 - val_loss: 0.1939 - val_tp: 36.0000 - val_fp: 486.0000 - val_tn: 10329.0000 - val_fn: 157.0000 - val_accuracy: 0.9416 - val_precision: 0.0690 - val_recall: 0.1865 - val_auc: 0.7391\n",
            "Epoch 63/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.3429 - tp: 340.0000 - fp: 4100.0000 - tn: 17524.0000 - fn: 52.0000 - accuracy: 0.8114 - precision: 0.0766 - recall: 0.8673 - auc: 0.9258 - val_loss: 0.3230 - val_tp: 66.0000 - val_fp: 1207.0000 - val_tn: 9608.0000 - val_fn: 127.0000 - val_accuracy: 0.8788 - val_precision: 0.0518 - val_recall: 0.3420 - val_auc: 0.6989\n",
            "Epoch 64/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.3345 - tp: 341.0000 - fp: 3667.0000 - tn: 17955.0000 - fn: 53.0000 - accuracy: 0.8310 - precision: 0.0851 - recall: 0.8655 - auc: 0.9297 - val_loss: 0.2279 - val_tp: 45.0000 - val_fp: 705.0000 - val_tn: 10110.0000 - val_fn: 148.0000 - val_accuracy: 0.9225 - val_precision: 0.0600 - val_recall: 0.2332 - val_auc: 0.7246\n",
            "Epoch 65/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.3166 - tp: 347.0000 - fp: 3604.0000 - tn: 18017.0000 - fn: 48.0000 - accuracy: 0.8341 - precision: 0.0878 - recall: 0.8785 - auc: 0.9377 - val_loss: 0.2441 - val_tp: 49.0000 - val_fp: 810.0000 - val_tn: 10005.0000 - val_fn: 144.0000 - val_accuracy: 0.9133 - val_precision: 0.0570 - val_recall: 0.2539 - val_auc: 0.7297\n",
            "Epoch 66/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.3135 - tp: 342.0000 - fp: 3605.0000 - tn: 18020.0000 - fn: 49.0000 - accuracy: 0.8340 - precision: 0.0866 - recall: 0.8747 - auc: 0.9379 - val_loss: 0.1999 - val_tp: 36.0000 - val_fp: 535.0000 - val_tn: 10280.0000 - val_fn: 157.0000 - val_accuracy: 0.9371 - val_precision: 0.0630 - val_recall: 0.1865 - val_auc: 0.7034\n",
            "Epoch 67/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.3408 - tp: 334.0000 - fp: 3836.0000 - tn: 17786.0000 - fn: 60.0000 - accuracy: 0.8230 - precision: 0.0801 - recall: 0.8477 - auc: 0.9254 - val_loss: 0.1599 - val_tp: 21.0000 - val_fp: 290.0000 - val_tn: 10525.0000 - val_fn: 172.0000 - val_accuracy: 0.9580 - val_precision: 0.0675 - val_recall: 0.1088 - val_auc: 0.6903\n",
            "Epoch 68/100\n",
            "86/86 [==============================] - 15s 177ms/step - loss: 0.3306 - tp: 340.0000 - fp: 3843.0000 - tn: 17784.0000 - fn: 49.0000 - accuracy: 0.8232 - precision: 0.0813 - recall: 0.8740 - auc: 0.9293 - val_loss: 0.2069 - val_tp: 41.0000 - val_fp: 505.0000 - val_tn: 10310.0000 - val_fn: 152.0000 - val_accuracy: 0.9403 - val_precision: 0.0751 - val_recall: 0.2124 - val_auc: 0.7309\n",
            "Epoch 69/100\n",
            "86/86 [==============================] - 16s 183ms/step - loss: 0.3641 - tp: 332.0000 - fp: 3972.0000 - tn: 17647.0000 - fn: 65.0000 - accuracy: 0.8166 - precision: 0.0771 - recall: 0.8363 - auc: 0.9159 - val_loss: 0.2316 - val_tp: 54.0000 - val_fp: 796.0000 - val_tn: 10019.0000 - val_fn: 139.0000 - val_accuracy: 0.9151 - val_precision: 0.0635 - val_recall: 0.2798 - val_auc: 0.7414\n",
            "Epoch 70/100\n",
            "86/86 [==============================] - 15s 176ms/step - loss: 0.3391 - tp: 340.0000 - fp: 3900.0000 - tn: 17725.0000 - fn: 51.0000 - accuracy: 0.8205 - precision: 0.0802 - recall: 0.8696 - auc: 0.9267 - val_loss: 0.1717 - val_tp: 40.0000 - val_fp: 487.0000 - val_tn: 10328.0000 - val_fn: 153.0000 - val_accuracy: 0.9419 - val_precision: 0.0759 - val_recall: 0.2073 - val_auc: 0.7500\n",
            "Epoch 71/100\n",
            "86/86 [==============================] - 15s 178ms/step - loss: 0.3469 - tp: 332.0000 - fp: 3953.0000 - tn: 17672.0000 - fn: 59.0000 - accuracy: 0.8178 - precision: 0.0775 - recall: 0.8491 - auc: 0.9222 - val_loss: 0.1590 - val_tp: 25.0000 - val_fp: 258.0000 - val_tn: 10557.0000 - val_fn: 168.0000 - val_accuracy: 0.9613 - val_precision: 0.0883 - val_recall: 0.1295 - val_auc: 0.6882\n",
            "Epoch 72/100\n",
            "86/86 [==============================] - 15s 180ms/step - loss: 0.3645 - tp: 332.0000 - fp: 4104.0000 - tn: 17519.0000 - fn: 61.0000 - accuracy: 0.8108 - precision: 0.0748 - recall: 0.8448 - auc: 0.9153 - val_loss: 0.5872 - val_tp: 118.0000 - val_fp: 3233.0000 - val_tn: 7582.0000 - val_fn: 75.0000 - val_accuracy: 0.6995 - val_precision: 0.0352 - val_recall: 0.6114 - val_auc: 0.7442\n",
            "Epoch 73/100\n",
            "86/86 [==============================] - 15s 172ms/step - loss: 0.3762 - tp: 332.0000 - fp: 4166.0000 - tn: 17453.0000 - fn: 65.0000 - accuracy: 0.8078 - precision: 0.0738 - recall: 0.8363 - auc: 0.9099 - val_loss: 0.2368 - val_tp: 56.0000 - val_fp: 800.0000 - val_tn: 10015.0000 - val_fn: 137.0000 - val_accuracy: 0.9149 - val_precision: 0.0654 - val_recall: 0.2902 - val_auc: 0.7452\n",
            "Epoch 74/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.3339 - tp: 338.0000 - fp: 3857.0000 - tn: 17767.0000 - fn: 54.0000 - accuracy: 0.8224 - precision: 0.0806 - recall: 0.8622 - auc: 0.9288 - val_loss: 0.3030 - val_tp: 68.0000 - val_fp: 1331.0000 - val_tn: 9484.0000 - val_fn: 125.0000 - val_accuracy: 0.8677 - val_precision: 0.0486 - val_recall: 0.3523 - val_auc: 0.7339\n",
            "Epoch 75/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.3464 - tp: 330.0000 - fp: 4106.0000 - tn: 17521.0000 - fn: 59.0000 - accuracy: 0.8108 - precision: 0.0744 - recall: 0.8483 - auc: 0.9216 - val_loss: 0.2787 - val_tp: 65.0000 - val_fp: 1234.0000 - val_tn: 9581.0000 - val_fn: 128.0000 - val_accuracy: 0.8763 - val_precision: 0.0500 - val_recall: 0.3368 - val_auc: 0.7573\n",
            "Epoch 76/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.2951 - tp: 349.0000 - fp: 3205.0000 - tn: 18415.0000 - fn: 47.0000 - accuracy: 0.8523 - precision: 0.0982 - recall: 0.8813 - auc: 0.9468 - val_loss: 0.1977 - val_tp: 48.0000 - val_fp: 560.0000 - val_tn: 10255.0000 - val_fn: 145.0000 - val_accuracy: 0.9360 - val_precision: 0.0789 - val_recall: 0.2487 - val_auc: 0.7498\n",
            "Epoch 77/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.2786 - tp: 357.0000 - fp: 3209.0000 - tn: 18411.0000 - fn: 39.0000 - accuracy: 0.8525 - precision: 0.1001 - recall: 0.9015 - auc: 0.9522 - val_loss: 0.1830 - val_tp: 32.0000 - val_fp: 436.0000 - val_tn: 10379.0000 - val_fn: 161.0000 - val_accuracy: 0.9458 - val_precision: 0.0684 - val_recall: 0.1658 - val_auc: 0.7270\n",
            "Epoch 78/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.2909 - tp: 349.0000 - fp: 3223.0000 - tn: 18402.0000 - fn: 42.0000 - accuracy: 0.8517 - precision: 0.0977 - recall: 0.8926 - auc: 0.9472 - val_loss: 0.1786 - val_tp: 36.0000 - val_fp: 489.0000 - val_tn: 10326.0000 - val_fn: 157.0000 - val_accuracy: 0.9413 - val_precision: 0.0686 - val_recall: 0.1865 - val_auc: 0.7230\n",
            "Epoch 79/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.2658 - tp: 348.0000 - fp: 3054.0000 - tn: 18573.0000 - fn: 41.0000 - accuracy: 0.8594 - precision: 0.1023 - recall: 0.8946 - auc: 0.9564 - val_loss: 0.2628 - val_tp: 58.0000 - val_fp: 977.0000 - val_tn: 9838.0000 - val_fn: 135.0000 - val_accuracy: 0.8990 - val_precision: 0.0560 - val_recall: 0.3005 - val_auc: 0.7112\n",
            "Epoch 80/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.2367 - tp: 365.0000 - fp: 2841.0000 - tn: 18780.0000 - fn: 30.0000 - accuracy: 0.8696 - precision: 0.1138 - recall: 0.9241 - auc: 0.9674 - val_loss: 0.2925 - val_tp: 65.0000 - val_fp: 1198.0000 - val_tn: 9617.0000 - val_fn: 128.0000 - val_accuracy: 0.8795 - val_precision: 0.0515 - val_recall: 0.3368 - val_auc: 0.6929\n",
            "Epoch 81/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.2482 - tp: 354.0000 - fp: 2744.0000 - tn: 18879.0000 - fn: 39.0000 - accuracy: 0.8736 - precision: 0.1143 - recall: 0.9008 - auc: 0.9627 - val_loss: 0.2104 - val_tp: 50.0000 - val_fp: 680.0000 - val_tn: 10135.0000 - val_fn: 143.0000 - val_accuracy: 0.9252 - val_precision: 0.0685 - val_recall: 0.2591 - val_auc: 0.7086\n",
            "Epoch 82/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.2512 - tp: 351.0000 - fp: 3028.0000 - tn: 18596.0000 - fn: 41.0000 - accuracy: 0.8606 - precision: 0.1039 - recall: 0.8954 - auc: 0.9610 - val_loss: 0.1967 - val_tp: 41.0000 - val_fp: 594.0000 - val_tn: 10221.0000 - val_fn: 152.0000 - val_accuracy: 0.9322 - val_precision: 0.0646 - val_recall: 0.2124 - val_auc: 0.6763\n",
            "Epoch 83/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.2574 - tp: 354.0000 - fp: 2988.0000 - tn: 18635.0000 - fn: 39.0000 - accuracy: 0.8625 - precision: 0.1059 - recall: 0.9008 - auc: 0.9588 - val_loss: 0.3308 - val_tp: 69.0000 - val_fp: 1603.0000 - val_tn: 9212.0000 - val_fn: 124.0000 - val_accuracy: 0.8431 - val_precision: 0.0413 - val_recall: 0.3575 - val_auc: 0.6983\n",
            "Epoch 84/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.2404 - tp: 362.0000 - fp: 2805.0000 - tn: 18817.0000 - fn: 32.0000 - accuracy: 0.8711 - precision: 0.1143 - recall: 0.9188 - auc: 0.9655 - val_loss: 0.1770 - val_tp: 31.0000 - val_fp: 459.0000 - val_tn: 10356.0000 - val_fn: 162.0000 - val_accuracy: 0.9436 - val_precision: 0.0633 - val_recall: 0.1606 - val_auc: 0.6878\n",
            "Epoch 85/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.2666 - tp: 350.0000 - fp: 2772.0000 - tn: 18851.0000 - fn: 43.0000 - accuracy: 0.8721 - precision: 0.1121 - recall: 0.8906 - auc: 0.9562 - val_loss: 0.2464 - val_tp: 55.0000 - val_fp: 811.0000 - val_tn: 10004.0000 - val_fn: 138.0000 - val_accuracy: 0.9138 - val_precision: 0.0635 - val_recall: 0.2850 - val_auc: 0.6604\n",
            "Epoch 86/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.2800 - tp: 348.0000 - fp: 3326.0000 - tn: 18299.0000 - fn: 43.0000 - accuracy: 0.8470 - precision: 0.0947 - recall: 0.8900 - auc: 0.9503 - val_loss: 0.2615 - val_tp: 53.0000 - val_fp: 1091.0000 - val_tn: 9724.0000 - val_fn: 140.0000 - val_accuracy: 0.8882 - val_precision: 0.0463 - val_recall: 0.2746 - val_auc: 0.7048\n",
            "Epoch 87/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.2753 - tp: 342.0000 - fp: 2760.0000 - tn: 18863.0000 - fn: 51.0000 - accuracy: 0.8723 - precision: 0.1103 - recall: 0.8702 - auc: 0.9533 - val_loss: 0.2410 - val_tp: 59.0000 - val_fp: 972.0000 - val_tn: 9843.0000 - val_fn: 134.0000 - val_accuracy: 0.8995 - val_precision: 0.0572 - val_recall: 0.3057 - val_auc: 0.7499\n",
            "Epoch 88/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.3067 - tp: 344.0000 - fp: 3560.0000 - tn: 18066.0000 - fn: 46.0000 - accuracy: 0.8362 - precision: 0.0881 - recall: 0.8821 - auc: 0.9400 - val_loss: 0.2156 - val_tp: 46.0000 - val_fp: 674.0000 - val_tn: 10141.0000 - val_fn: 147.0000 - val_accuracy: 0.9254 - val_precision: 0.0639 - val_recall: 0.2383 - val_auc: 0.6560\n",
            "Epoch 89/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.2911 - tp: 337.0000 - fp: 3223.0000 - tn: 18402.0000 - fn: 54.0000 - accuracy: 0.8512 - precision: 0.0947 - recall: 0.8619 - auc: 0.9461 - val_loss: 0.2113 - val_tp: 46.0000 - val_fp: 788.0000 - val_tn: 10027.0000 - val_fn: 147.0000 - val_accuracy: 0.9151 - val_precision: 0.0552 - val_recall: 0.2383 - val_auc: 0.7007\n",
            "Epoch 90/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.2924 - tp: 338.0000 - fp: 3179.0000 - tn: 18449.0000 - fn: 50.0000 - accuracy: 0.8533 - precision: 0.0961 - recall: 0.8711 - auc: 0.9452 - val_loss: 0.1885 - val_tp: 46.0000 - val_fp: 586.0000 - val_tn: 10229.0000 - val_fn: 147.0000 - val_accuracy: 0.9334 - val_precision: 0.0728 - val_recall: 0.2383 - val_auc: 0.7186\n",
            "Epoch 91/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.2753 - tp: 348.0000 - fp: 3215.0000 - tn: 18410.0000 - fn: 43.0000 - accuracy: 0.8520 - precision: 0.0977 - recall: 0.8900 - auc: 0.9518 - val_loss: 0.2060 - val_tp: 47.0000 - val_fp: 638.0000 - val_tn: 10177.0000 - val_fn: 146.0000 - val_accuracy: 0.9288 - val_precision: 0.0686 - val_recall: 0.2435 - val_auc: 0.7322\n",
            "Epoch 92/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.2446 - tp: 350.0000 - fp: 2662.0000 - tn: 18962.0000 - fn: 42.0000 - accuracy: 0.8772 - precision: 0.1162 - recall: 0.8929 - auc: 0.9628 - val_loss: 0.1786 - val_tp: 26.0000 - val_fp: 406.0000 - val_tn: 10409.0000 - val_fn: 167.0000 - val_accuracy: 0.9479 - val_precision: 0.0602 - val_recall: 0.1347 - val_auc: 0.6612\n",
            "Epoch 93/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.2315 - tp: 355.0000 - fp: 2706.0000 - tn: 18919.0000 - fn: 36.0000 - accuracy: 0.8755 - precision: 0.1160 - recall: 0.9079 - auc: 0.9667 - val_loss: 0.2658 - val_tp: 54.0000 - val_fp: 972.0000 - val_tn: 9843.0000 - val_fn: 139.0000 - val_accuracy: 0.8991 - val_precision: 0.0526 - val_recall: 0.2798 - val_auc: 0.6903\n",
            "Epoch 94/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.2110 - tp: 360.0000 - fp: 2304.0000 - tn: 19321.0000 - fn: 31.0000 - accuracy: 0.8939 - precision: 0.1351 - recall: 0.9207 - auc: 0.9731 - val_loss: 0.2034 - val_tp: 40.0000 - val_fp: 632.0000 - val_tn: 10183.0000 - val_fn: 153.0000 - val_accuracy: 0.9287 - val_precision: 0.0595 - val_recall: 0.2073 - val_auc: 0.6816\n",
            "Epoch 95/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.2067 - tp: 362.0000 - fp: 2465.0000 - tn: 19158.0000 - fn: 31.0000 - accuracy: 0.8866 - precision: 0.1281 - recall: 0.9211 - auc: 0.9744 - val_loss: 0.2093 - val_tp: 41.0000 - val_fp: 686.0000 - val_tn: 10129.0000 - val_fn: 152.0000 - val_accuracy: 0.9239 - val_precision: 0.0564 - val_recall: 0.2124 - val_auc: 0.6926\n",
            "Epoch 96/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.2235 - tp: 351.0000 - fp: 2535.0000 - tn: 19089.0000 - fn: 41.0000 - accuracy: 0.8830 - precision: 0.1216 - recall: 0.8954 - auc: 0.9688 - val_loss: 0.1700 - val_tp: 29.0000 - val_fp: 429.0000 - val_tn: 10386.0000 - val_fn: 164.0000 - val_accuracy: 0.9461 - val_precision: 0.0633 - val_recall: 0.1503 - val_auc: 0.6670\n",
            "Epoch 97/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.1977 - tp: 365.0000 - fp: 2553.0000 - tn: 19074.0000 - fn: 24.0000 - accuracy: 0.8829 - precision: 0.1251 - recall: 0.9383 - auc: 0.9769 - val_loss: 0.2744 - val_tp: 55.0000 - val_fp: 1118.0000 - val_tn: 9697.0000 - val_fn: 138.0000 - val_accuracy: 0.8859 - val_precision: 0.0469 - val_recall: 0.2850 - val_auc: 0.6907\n",
            "Epoch 98/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.1915 - tp: 366.0000 - fp: 2082.0000 - tn: 19542.0000 - fn: 26.0000 - accuracy: 0.9043 - precision: 0.1495 - recall: 0.9337 - auc: 0.9782 - val_loss: 0.1815 - val_tp: 34.0000 - val_fp: 505.0000 - val_tn: 10310.0000 - val_fn: 159.0000 - val_accuracy: 0.9397 - val_precision: 0.0631 - val_recall: 0.1762 - val_auc: 0.6788\n",
            "Epoch 99/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.1827 - tp: 365.0000 - fp: 2226.0000 - tn: 19399.0000 - fn: 26.0000 - accuracy: 0.8977 - precision: 0.1409 - recall: 0.9335 - auc: 0.9812 - val_loss: 0.2975 - val_tp: 62.0000 - val_fp: 1210.0000 - val_tn: 9605.0000 - val_fn: 131.0000 - val_accuracy: 0.8782 - val_precision: 0.0487 - val_recall: 0.3212 - val_auc: 0.6928\n",
            "Epoch 100/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.1958 - tp: 356.0000 - fp: 2133.0000 - tn: 19492.0000 - fn: 35.0000 - accuracy: 0.9015 - precision: 0.1430 - recall: 0.9105 - auc: 0.9767 - val_loss: 0.3224 - val_tp: 66.0000 - val_fp: 1376.0000 - val_tn: 9439.0000 - val_fn: 127.0000 - val_accuracy: 0.8635 - val_precision: 0.0458 - val_recall: 0.3420 - val_auc: 0.6600\n",
            "Epoch 1/100\n",
            " 2/86 [..............................] - ETA: 5s - loss: 2.1447 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 502.0000 - fn: 10.0000 - accuracy: 0.9805 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4758WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0114s vs `on_train_batch_end` time: 0.1095s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0114s vs `on_train_batch_end` time: 0.1095s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "86/86 [==============================] - ETA: 0s - loss: 1.7882 - tp: 1.0000 - fp: 17.0000 - tn: 21611.0000 - fn: 387.0000 - accuracy: 0.9816 - precision: 0.0556 - recall: 0.0026 - auc: 0.5894WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0049s vs `on_test_batch_end` time: 0.0603s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0049s vs `on_test_batch_end` time: 0.0603s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r86/86 [==============================] - 25s 292ms/step - loss: 1.7882 - tp: 1.0000 - fp: 17.0000 - tn: 21611.0000 - fn: 387.0000 - accuracy: 0.9816 - precision: 0.0556 - recall: 0.0026 - auc: 0.5894 - val_loss: 0.0876 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 10813.0000 - val_fn: 195.0000 - val_accuracy: 0.9823 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6640\n",
            "Epoch 2/100\n",
            "86/86 [==============================] - 16s 184ms/step - loss: 1.5346 - tp: 29.0000 - fp: 601.0000 - tn: 21021.0000 - fn: 365.0000 - accuracy: 0.9561 - precision: 0.0460 - recall: 0.0736 - auc: 0.6300 - val_loss: 0.0908 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 10813.0000 - val_fn: 195.0000 - val_accuracy: 0.9823 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6398\n",
            "Epoch 3/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 1.0416 - tp: 128.0000 - fp: 2800.0000 - tn: 18824.0000 - fn: 264.0000 - accuracy: 0.8608 - precision: 0.0437 - recall: 0.3265 - auc: 0.6892 - val_loss: 0.0995 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 10813.0000 - val_fn: 195.0000 - val_accuracy: 0.9823 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6385\n",
            "Epoch 4/100\n",
            "86/86 [==============================] - 16s 184ms/step - loss: 0.7669 - tp: 217.0000 - fp: 5951.0000 - tn: 15677.0000 - fn: 171.0000 - accuracy: 0.7219 - precision: 0.0352 - recall: 0.5593 - auc: 0.7194 - val_loss: 0.1915 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 10813.0000 - val_fn: 195.0000 - val_accuracy: 0.9823 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4998\n",
            "Epoch 5/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.7463 - tp: 208.0000 - fp: 5286.0000 - tn: 16338.0000 - fn: 184.0000 - accuracy: 0.7515 - precision: 0.0379 - recall: 0.5306 - auc: 0.7221 - val_loss: 0.3034 - val_tp: 59.0000 - val_fp: 766.0000 - val_tn: 10047.0000 - val_fn: 136.0000 - val_accuracy: 0.9181 - val_precision: 0.0715 - val_recall: 0.3026 - val_auc: 0.7504\n",
            "Epoch 6/100\n",
            "86/86 [==============================] - 15s 177ms/step - loss: 0.7759 - tp: 219.0000 - fp: 5719.0000 - tn: 15906.0000 - fn: 172.0000 - accuracy: 0.7324 - precision: 0.0369 - recall: 0.5601 - auc: 0.7181 - val_loss: 0.1740 - val_tp: 37.0000 - val_fp: 354.0000 - val_tn: 10459.0000 - val_fn: 158.0000 - val_accuracy: 0.9535 - val_precision: 0.0946 - val_recall: 0.1897 - val_auc: 0.7913\n",
            "Epoch 7/100\n",
            "86/86 [==============================] - 15s 174ms/step - loss: 0.6736 - tp: 229.0000 - fp: 6241.0000 - tn: 15385.0000 - fn: 161.0000 - accuracy: 0.7092 - precision: 0.0354 - recall: 0.5872 - auc: 0.7319 - val_loss: 0.3150 - val_tp: 86.0000 - val_fp: 1343.0000 - val_tn: 9470.0000 - val_fn: 109.0000 - val_accuracy: 0.8681 - val_precision: 0.0602 - val_recall: 0.4410 - val_auc: 0.7909\n",
            "Epoch 8/100\n",
            "86/86 [==============================] - 15s 175ms/step - loss: 0.6095 - tp: 252.0000 - fp: 6692.0000 - tn: 14935.0000 - fn: 137.0000 - accuracy: 0.6898 - precision: 0.0363 - recall: 0.6478 - auc: 0.7415 - val_loss: 0.4218 - val_tp: 93.0000 - val_fp: 1516.0000 - val_tn: 9297.0000 - val_fn: 102.0000 - val_accuracy: 0.8530 - val_precision: 0.0578 - val_recall: 0.4769 - val_auc: 0.7758\n",
            "Epoch 9/100\n",
            "86/86 [==============================] - 15s 173ms/step - loss: 0.6524 - tp: 252.0000 - fp: 6537.0000 - tn: 15086.0000 - fn: 141.0000 - accuracy: 0.6967 - precision: 0.0371 - recall: 0.6412 - auc: 0.7525 - val_loss: 0.5635 - val_tp: 141.0000 - val_fp: 3077.0000 - val_tn: 7736.0000 - val_fn: 54.0000 - val_accuracy: 0.7156 - val_precision: 0.0438 - val_recall: 0.7231 - val_auc: 0.7933\n",
            "Epoch 10/100\n",
            "86/86 [==============================] - 15s 179ms/step - loss: 0.6480 - tp: 231.0000 - fp: 5915.0000 - tn: 15709.0000 - fn: 161.0000 - accuracy: 0.7240 - precision: 0.0376 - recall: 0.5893 - auc: 0.7443 - val_loss: 0.3531 - val_tp: 69.0000 - val_fp: 932.0000 - val_tn: 9881.0000 - val_fn: 126.0000 - val_accuracy: 0.9039 - val_precision: 0.0689 - val_recall: 0.3538 - val_auc: 0.7928\n",
            "Epoch 11/100\n",
            "86/86 [==============================] - 15s 175ms/step - loss: 0.6247 - tp: 260.0000 - fp: 6692.0000 - tn: 14930.0000 - fn: 134.0000 - accuracy: 0.6900 - precision: 0.0374 - recall: 0.6599 - auc: 0.7509 - val_loss: 0.1125 - val_tp: 8.0000 - val_fp: 94.0000 - val_tn: 10719.0000 - val_fn: 187.0000 - val_accuracy: 0.9745 - val_precision: 0.0784 - val_recall: 0.0410 - val_auc: 0.7274\n",
            "Epoch 12/100\n",
            "86/86 [==============================] - 15s 175ms/step - loss: 0.6068 - tp: 255.0000 - fp: 6844.0000 - tn: 14780.0000 - fn: 137.0000 - accuracy: 0.6829 - precision: 0.0359 - recall: 0.6505 - auc: 0.7477 - val_loss: 0.2579 - val_tp: 55.0000 - val_fp: 550.0000 - val_tn: 10263.0000 - val_fn: 140.0000 - val_accuracy: 0.9373 - val_precision: 0.0909 - val_recall: 0.2821 - val_auc: 0.8117\n",
            "Epoch 13/100\n",
            "86/86 [==============================] - 15s 174ms/step - loss: 0.5910 - tp: 272.0000 - fp: 6620.0000 - tn: 15004.0000 - fn: 120.0000 - accuracy: 0.6939 - precision: 0.0395 - recall: 0.6939 - auc: 0.7688 - val_loss: 0.3328 - val_tp: 74.0000 - val_fp: 889.0000 - val_tn: 9924.0000 - val_fn: 121.0000 - val_accuracy: 0.9082 - val_precision: 0.0768 - val_recall: 0.3795 - val_auc: 0.8080\n",
            "Epoch 14/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5653 - tp: 276.0000 - fp: 6667.0000 - tn: 14959.0000 - fn: 114.0000 - accuracy: 0.6920 - precision: 0.0398 - recall: 0.7077 - auc: 0.7785 - val_loss: 0.2341 - val_tp: 54.0000 - val_fp: 563.0000 - val_tn: 10250.0000 - val_fn: 141.0000 - val_accuracy: 0.9360 - val_precision: 0.0875 - val_recall: 0.2769 - val_auc: 0.8093\n",
            "Epoch 15/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.5621 - tp: 272.0000 - fp: 6712.0000 - tn: 14913.0000 - fn: 119.0000 - accuracy: 0.6897 - precision: 0.0389 - recall: 0.6957 - auc: 0.7786 - val_loss: 0.2588 - val_tp: 65.0000 - val_fp: 727.0000 - val_tn: 10086.0000 - val_fn: 130.0000 - val_accuracy: 0.9221 - val_precision: 0.0821 - val_recall: 0.3333 - val_auc: 0.8086\n",
            "Epoch 16/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5523 - tp: 268.0000 - fp: 6659.0000 - tn: 14968.0000 - fn: 121.0000 - accuracy: 0.6920 - precision: 0.0387 - recall: 0.6889 - auc: 0.7829 - val_loss: 0.3341 - val_tp: 83.0000 - val_fp: 1151.0000 - val_tn: 9662.0000 - val_fn: 112.0000 - val_accuracy: 0.8853 - val_precision: 0.0673 - val_recall: 0.4256 - val_auc: 0.8112\n",
            "Epoch 17/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5595 - tp: 285.0000 - fp: 6504.0000 - tn: 15123.0000 - fn: 104.0000 - accuracy: 0.6999 - precision: 0.0420 - recall: 0.7326 - auc: 0.7887 - val_loss: 0.3256 - val_tp: 81.0000 - val_fp: 1094.0000 - val_tn: 9719.0000 - val_fn: 114.0000 - val_accuracy: 0.8903 - val_precision: 0.0689 - val_recall: 0.4154 - val_auc: 0.8115\n",
            "Epoch 18/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5561 - tp: 280.0000 - fp: 6791.0000 - tn: 14833.0000 - fn: 112.0000 - accuracy: 0.6865 - precision: 0.0396 - recall: 0.7143 - auc: 0.7851 - val_loss: 0.3241 - val_tp: 88.0000 - val_fp: 1245.0000 - val_tn: 9568.0000 - val_fn: 107.0000 - val_accuracy: 0.8772 - val_precision: 0.0660 - val_recall: 0.4513 - val_auc: 0.8099\n",
            "Epoch 19/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5556 - tp: 282.0000 - fp: 6747.0000 - tn: 14881.0000 - fn: 106.0000 - accuracy: 0.6887 - precision: 0.0401 - recall: 0.7268 - auc: 0.7809 - val_loss: 0.2539 - val_tp: 50.0000 - val_fp: 516.0000 - val_tn: 10297.0000 - val_fn: 145.0000 - val_accuracy: 0.9400 - val_precision: 0.0883 - val_recall: 0.2564 - val_auc: 0.8060\n",
            "Epoch 20/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.6136 - tp: 247.0000 - fp: 6086.0000 - tn: 15541.0000 - fn: 142.0000 - accuracy: 0.7171 - precision: 0.0390 - recall: 0.6350 - auc: 0.7563 - val_loss: 0.3981 - val_tp: 80.0000 - val_fp: 1032.0000 - val_tn: 9781.0000 - val_fn: 115.0000 - val_accuracy: 0.8958 - val_precision: 0.0719 - val_recall: 0.4103 - val_auc: 0.7944\n",
            "Epoch 21/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.6545 - tp: 254.0000 - fp: 6372.0000 - tn: 15253.0000 - fn: 137.0000 - accuracy: 0.7044 - precision: 0.0383 - recall: 0.6496 - auc: 0.7539 - val_loss: 0.2047 - val_tp: 38.0000 - val_fp: 368.0000 - val_tn: 10445.0000 - val_fn: 157.0000 - val_accuracy: 0.9523 - val_precision: 0.0936 - val_recall: 0.1949 - val_auc: 0.8093\n",
            "Epoch 22/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5818 - tp: 281.0000 - fp: 7013.0000 - tn: 14606.0000 - fn: 116.0000 - accuracy: 0.6762 - precision: 0.0385 - recall: 0.7078 - auc: 0.7706 - val_loss: 0.2846 - val_tp: 78.0000 - val_fp: 910.0000 - val_tn: 9903.0000 - val_fn: 117.0000 - val_accuracy: 0.9067 - val_precision: 0.0789 - val_recall: 0.4000 - val_auc: 0.7936\n",
            "Epoch 23/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5575 - tp: 279.0000 - fp: 6538.0000 - tn: 15087.0000 - fn: 112.0000 - accuracy: 0.6979 - precision: 0.0409 - recall: 0.7136 - auc: 0.7861 - val_loss: 0.2119 - val_tp: 55.0000 - val_fp: 630.0000 - val_tn: 10183.0000 - val_fn: 140.0000 - val_accuracy: 0.9301 - val_precision: 0.0803 - val_recall: 0.2821 - val_auc: 0.7881\n",
            "Epoch 24/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5599 - tp: 275.0000 - fp: 6501.0000 - tn: 15124.0000 - fn: 116.0000 - accuracy: 0.6994 - precision: 0.0406 - recall: 0.7033 - auc: 0.7782 - val_loss: 0.2125 - val_tp: 46.0000 - val_fp: 521.0000 - val_tn: 10292.0000 - val_fn: 149.0000 - val_accuracy: 0.9391 - val_precision: 0.0811 - val_recall: 0.2359 - val_auc: 0.7798\n",
            "Epoch 25/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5623 - tp: 274.0000 - fp: 6323.0000 - tn: 15301.0000 - fn: 118.0000 - accuracy: 0.7074 - precision: 0.0415 - recall: 0.6990 - auc: 0.7876 - val_loss: 0.2960 - val_tp: 59.0000 - val_fp: 598.0000 - val_tn: 10215.0000 - val_fn: 136.0000 - val_accuracy: 0.9333 - val_precision: 0.0898 - val_recall: 0.3026 - val_auc: 0.7987\n",
            "Epoch 26/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.5432 - tp: 286.0000 - fp: 6296.0000 - tn: 15329.0000 - fn: 105.0000 - accuracy: 0.7093 - precision: 0.0435 - recall: 0.7315 - auc: 0.7995 - val_loss: 0.2880 - val_tp: 79.0000 - val_fp: 860.0000 - val_tn: 9953.0000 - val_fn: 116.0000 - val_accuracy: 0.9113 - val_precision: 0.0841 - val_recall: 0.4051 - val_auc: 0.8101\n",
            "Epoch 27/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5300 - tp: 282.0000 - fp: 6388.0000 - tn: 15238.0000 - fn: 108.0000 - accuracy: 0.7049 - precision: 0.0423 - recall: 0.7231 - auc: 0.8030 - val_loss: 0.3289 - val_tp: 87.0000 - val_fp: 1081.0000 - val_tn: 9732.0000 - val_fn: 108.0000 - val_accuracy: 0.8920 - val_precision: 0.0745 - val_recall: 0.4462 - val_auc: 0.8054\n",
            "Epoch 28/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5419 - tp: 289.0000 - fp: 6227.0000 - tn: 15396.0000 - fn: 104.0000 - accuracy: 0.7124 - precision: 0.0444 - recall: 0.7354 - auc: 0.8027 - val_loss: 0.2787 - val_tp: 72.0000 - val_fp: 779.0000 - val_tn: 10034.0000 - val_fn: 123.0000 - val_accuracy: 0.9181 - val_precision: 0.0846 - val_recall: 0.3692 - val_auc: 0.8095\n",
            "Epoch 29/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5363 - tp: 292.0000 - fp: 6117.0000 - tn: 15506.0000 - fn: 101.0000 - accuracy: 0.7176 - precision: 0.0456 - recall: 0.7430 - auc: 0.8095 - val_loss: 0.2455 - val_tp: 45.0000 - val_fp: 434.0000 - val_tn: 10379.0000 - val_fn: 150.0000 - val_accuracy: 0.9469 - val_precision: 0.0939 - val_recall: 0.2308 - val_auc: 0.7961\n",
            "Epoch 30/100\n",
            "86/86 [==============================] - 14s 169ms/step - loss: 0.4958 - tp: 307.0000 - fp: 5974.0000 - tn: 15651.0000 - fn: 84.0000 - accuracy: 0.7248 - precision: 0.0489 - recall: 0.7852 - auc: 0.8334 - val_loss: 0.2802 - val_tp: 68.0000 - val_fp: 687.0000 - val_tn: 10126.0000 - val_fn: 127.0000 - val_accuracy: 0.9261 - val_precision: 0.0901 - val_recall: 0.3487 - val_auc: 0.8100\n",
            "Epoch 31/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4971 - tp: 295.0000 - fp: 5967.0000 - tn: 15659.0000 - fn: 95.0000 - accuracy: 0.7247 - precision: 0.0471 - recall: 0.7564 - auc: 0.8289 - val_loss: 0.1673 - val_tp: 27.0000 - val_fp: 227.0000 - val_tn: 10586.0000 - val_fn: 168.0000 - val_accuracy: 0.9641 - val_precision: 0.1063 - val_recall: 0.1385 - val_auc: 0.8076\n",
            "Epoch 32/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.4962 - tp: 304.0000 - fp: 5717.0000 - tn: 15909.0000 - fn: 86.0000 - accuracy: 0.7364 - precision: 0.0505 - recall: 0.7795 - auc: 0.8347 - val_loss: 0.2214 - val_tp: 50.0000 - val_fp: 475.0000 - val_tn: 10338.0000 - val_fn: 145.0000 - val_accuracy: 0.9437 - val_precision: 0.0952 - val_recall: 0.2564 - val_auc: 0.8116\n",
            "Epoch 33/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.4924 - tp: 317.0000 - fp: 5766.0000 - tn: 15855.0000 - fn: 78.0000 - accuracy: 0.7346 - precision: 0.0521 - recall: 0.8025 - auc: 0.8424 - val_loss: 0.2016 - val_tp: 43.0000 - val_fp: 392.0000 - val_tn: 10421.0000 - val_fn: 152.0000 - val_accuracy: 0.9506 - val_precision: 0.0989 - val_recall: 0.2205 - val_auc: 0.8100\n",
            "Epoch 34/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.5038 - tp: 305.0000 - fp: 6077.0000 - tn: 15548.0000 - fn: 86.0000 - accuracy: 0.7201 - precision: 0.0478 - recall: 0.7801 - auc: 0.8269 - val_loss: 0.2157 - val_tp: 51.0000 - val_fp: 499.0000 - val_tn: 10314.0000 - val_fn: 144.0000 - val_accuracy: 0.9416 - val_precision: 0.0927 - val_recall: 0.2615 - val_auc: 0.8140\n",
            "Epoch 35/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5120 - tp: 297.0000 - fp: 5859.0000 - tn: 15770.0000 - fn: 90.0000 - accuracy: 0.7298 - precision: 0.0482 - recall: 0.7674 - auc: 0.8251 - val_loss: 0.1882 - val_tp: 46.0000 - val_fp: 383.0000 - val_tn: 10430.0000 - val_fn: 149.0000 - val_accuracy: 0.9517 - val_precision: 0.1072 - val_recall: 0.2359 - val_auc: 0.8105\n",
            "Epoch 36/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.4945 - tp: 306.0000 - fp: 5880.0000 - tn: 15746.0000 - fn: 84.0000 - accuracy: 0.7291 - precision: 0.0495 - recall: 0.7846 - auc: 0.8349 - val_loss: 0.2217 - val_tp: 42.0000 - val_fp: 386.0000 - val_tn: 10427.0000 - val_fn: 153.0000 - val_accuracy: 0.9510 - val_precision: 0.0981 - val_recall: 0.2154 - val_auc: 0.7937\n",
            "Epoch 37/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5144 - tp: 298.0000 - fp: 5916.0000 - tn: 15706.0000 - fn: 96.0000 - accuracy: 0.7269 - precision: 0.0480 - recall: 0.7563 - auc: 0.8226 - val_loss: 0.1676 - val_tp: 34.0000 - val_fp: 340.0000 - val_tn: 10473.0000 - val_fn: 161.0000 - val_accuracy: 0.9545 - val_precision: 0.0909 - val_recall: 0.1744 - val_auc: 0.7892\n",
            "Epoch 38/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5014 - tp: 295.0000 - fp: 5896.0000 - tn: 15729.0000 - fn: 96.0000 - accuracy: 0.7278 - precision: 0.0476 - recall: 0.7545 - auc: 0.8303 - val_loss: 0.1833 - val_tp: 40.0000 - val_fp: 291.0000 - val_tn: 10522.0000 - val_fn: 155.0000 - val_accuracy: 0.9595 - val_precision: 0.1208 - val_recall: 0.2051 - val_auc: 0.8036\n",
            "Epoch 39/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5188 - tp: 300.0000 - fp: 5932.0000 - tn: 15693.0000 - fn: 91.0000 - accuracy: 0.7264 - precision: 0.0481 - recall: 0.7673 - auc: 0.8215 - val_loss: 0.1127 - val_tp: 6.0000 - val_fp: 67.0000 - val_tn: 10746.0000 - val_fn: 189.0000 - val_accuracy: 0.9767 - val_precision: 0.0822 - val_recall: 0.0308 - val_auc: 0.7293\n",
            "Epoch 40/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.5064 - tp: 285.0000 - fp: 6093.0000 - tn: 15536.0000 - fn: 102.0000 - accuracy: 0.7186 - precision: 0.0447 - recall: 0.7364 - auc: 0.8242 - val_loss: 0.1835 - val_tp: 36.0000 - val_fp: 334.0000 - val_tn: 10479.0000 - val_fn: 159.0000 - val_accuracy: 0.9552 - val_precision: 0.0973 - val_recall: 0.1846 - val_auc: 0.7936\n",
            "Epoch 41/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5364 - tp: 290.0000 - fp: 6036.0000 - tn: 15587.0000 - fn: 103.0000 - accuracy: 0.7212 - precision: 0.0458 - recall: 0.7379 - auc: 0.8087 - val_loss: 0.1490 - val_tp: 27.0000 - val_fp: 252.0000 - val_tn: 10561.0000 - val_fn: 168.0000 - val_accuracy: 0.9618 - val_precision: 0.0968 - val_recall: 0.1385 - val_auc: 0.7991\n",
            "Epoch 42/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5124 - tp: 293.0000 - fp: 5838.0000 - tn: 15789.0000 - fn: 96.0000 - accuracy: 0.7305 - precision: 0.0478 - recall: 0.7532 - auc: 0.8218 - val_loss: 0.2554 - val_tp: 56.0000 - val_fp: 630.0000 - val_tn: 10183.0000 - val_fn: 139.0000 - val_accuracy: 0.9301 - val_precision: 0.0816 - val_recall: 0.2872 - val_auc: 0.7870\n",
            "Epoch 43/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.4931 - tp: 303.0000 - fp: 5937.0000 - tn: 15689.0000 - fn: 87.0000 - accuracy: 0.7264 - precision: 0.0486 - recall: 0.7769 - auc: 0.8342 - val_loss: 0.2976 - val_tp: 70.0000 - val_fp: 845.0000 - val_tn: 9968.0000 - val_fn: 125.0000 - val_accuracy: 0.9119 - val_precision: 0.0765 - val_recall: 0.3590 - val_auc: 0.7786\n",
            "Epoch 44/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.4792 - tp: 304.0000 - fp: 5207.0000 - tn: 16418.0000 - fn: 87.0000 - accuracy: 0.7595 - precision: 0.0552 - recall: 0.7775 - auc: 0.8512 - val_loss: 0.2133 - val_tp: 53.0000 - val_fp: 497.0000 - val_tn: 10316.0000 - val_fn: 142.0000 - val_accuracy: 0.9420 - val_precision: 0.0964 - val_recall: 0.2718 - val_auc: 0.8089\n",
            "Epoch 45/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.4624 - tp: 305.0000 - fp: 5316.0000 - tn: 16310.0000 - fn: 85.0000 - accuracy: 0.7547 - precision: 0.0543 - recall: 0.7821 - auc: 0.8580 - val_loss: 0.2078 - val_tp: 49.0000 - val_fp: 443.0000 - val_tn: 10370.0000 - val_fn: 146.0000 - val_accuracy: 0.9465 - val_precision: 0.0996 - val_recall: 0.2513 - val_auc: 0.8013\n",
            "Epoch 46/100\n",
            "86/86 [==============================] - 14s 164ms/step - loss: 0.4505 - tp: 314.0000 - fp: 5455.0000 - tn: 16169.0000 - fn: 78.0000 - accuracy: 0.7487 - precision: 0.0544 - recall: 0.8010 - auc: 0.8659 - val_loss: 0.2063 - val_tp: 56.0000 - val_fp: 473.0000 - val_tn: 10340.0000 - val_fn: 139.0000 - val_accuracy: 0.9444 - val_precision: 0.1059 - val_recall: 0.2872 - val_auc: 0.8048\n",
            "Epoch 47/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.4473 - tp: 308.0000 - fp: 5116.0000 - tn: 16509.0000 - fn: 83.0000 - accuracy: 0.7639 - precision: 0.0568 - recall: 0.7877 - auc: 0.8667 - val_loss: 0.1702 - val_tp: 35.0000 - val_fp: 265.0000 - val_tn: 10548.0000 - val_fn: 160.0000 - val_accuracy: 0.9614 - val_precision: 0.1167 - val_recall: 0.1795 - val_auc: 0.7933\n",
            "Epoch 48/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.4301 - tp: 331.0000 - fp: 4956.0000 - tn: 16667.0000 - fn: 62.0000 - accuracy: 0.7721 - precision: 0.0626 - recall: 0.8422 - auc: 0.8814 - val_loss: 0.1832 - val_tp: 42.0000 - val_fp: 339.0000 - val_tn: 10474.0000 - val_fn: 153.0000 - val_accuracy: 0.9553 - val_precision: 0.1102 - val_recall: 0.2154 - val_auc: 0.7973\n",
            "Epoch 49/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.4229 - tp: 320.0000 - fp: 5076.0000 - tn: 16549.0000 - fn: 71.0000 - accuracy: 0.7662 - precision: 0.0593 - recall: 0.8184 - auc: 0.8840 - val_loss: 0.1897 - val_tp: 49.0000 - val_fp: 412.0000 - val_tn: 10401.0000 - val_fn: 146.0000 - val_accuracy: 0.9493 - val_precision: 0.1063 - val_recall: 0.2513 - val_auc: 0.7972\n",
            "Epoch 50/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4088 - tp: 317.0000 - fp: 4719.0000 - tn: 16907.0000 - fn: 73.0000 - accuracy: 0.7823 - precision: 0.0629 - recall: 0.8128 - auc: 0.8929 - val_loss: 0.2306 - val_tp: 59.0000 - val_fp: 595.0000 - val_tn: 10218.0000 - val_fn: 136.0000 - val_accuracy: 0.9336 - val_precision: 0.0902 - val_recall: 0.3026 - val_auc: 0.7878\n",
            "Epoch 51/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.4438 - tp: 304.0000 - fp: 4854.0000 - tn: 16774.0000 - fn: 84.0000 - accuracy: 0.7757 - precision: 0.0589 - recall: 0.7835 - auc: 0.8717 - val_loss: 0.1401 - val_tp: 25.0000 - val_fp: 228.0000 - val_tn: 10585.0000 - val_fn: 170.0000 - val_accuracy: 0.9638 - val_precision: 0.0988 - val_recall: 0.1282 - val_auc: 0.7806\n",
            "Epoch 52/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.4320 - tp: 318.0000 - fp: 4875.0000 - tn: 16749.0000 - fn: 74.0000 - accuracy: 0.7752 - precision: 0.0612 - recall: 0.8112 - auc: 0.8784 - val_loss: 0.2274 - val_tp: 56.0000 - val_fp: 553.0000 - val_tn: 10260.0000 - val_fn: 139.0000 - val_accuracy: 0.9371 - val_precision: 0.0920 - val_recall: 0.2872 - val_auc: 0.7747\n",
            "Epoch 53/100\n",
            "86/86 [==============================] - 15s 178ms/step - loss: 0.4202 - tp: 318.0000 - fp: 4703.0000 - tn: 16926.0000 - fn: 69.0000 - accuracy: 0.7832 - precision: 0.0633 - recall: 0.8217 - auc: 0.8861 - val_loss: 0.5622 - val_tp: 137.0000 - val_fp: 3380.0000 - val_tn: 7433.0000 - val_fn: 58.0000 - val_accuracy: 0.6877 - val_precision: 0.0390 - val_recall: 0.7026 - val_auc: 0.7676\n",
            "Epoch 54/100\n",
            "86/86 [==============================] - 15s 175ms/step - loss: 0.4505 - tp: 313.0000 - fp: 5135.0000 - tn: 16488.0000 - fn: 80.0000 - accuracy: 0.7631 - precision: 0.0575 - recall: 0.7964 - auc: 0.8679 - val_loss: 0.2013 - val_tp: 51.0000 - val_fp: 534.0000 - val_tn: 10279.0000 - val_fn: 144.0000 - val_accuracy: 0.9384 - val_precision: 0.0872 - val_recall: 0.2615 - val_auc: 0.7920\n",
            "Epoch 55/100\n",
            "86/86 [==============================] - 15s 176ms/step - loss: 0.4659 - tp: 306.0000 - fp: 4877.0000 - tn: 16750.0000 - fn: 83.0000 - accuracy: 0.7747 - precision: 0.0590 - recall: 0.7866 - auc: 0.8615 - val_loss: 0.2193 - val_tp: 39.0000 - val_fp: 469.0000 - val_tn: 10344.0000 - val_fn: 156.0000 - val_accuracy: 0.9432 - val_precision: 0.0768 - val_recall: 0.2000 - val_auc: 0.7089\n",
            "Epoch 56/100\n",
            "86/86 [==============================] - 15s 173ms/step - loss: 0.4443 - tp: 312.0000 - fp: 5147.0000 - tn: 16480.0000 - fn: 77.0000 - accuracy: 0.7627 - precision: 0.0572 - recall: 0.8021 - auc: 0.8700 - val_loss: 0.2510 - val_tp: 78.0000 - val_fp: 864.0000 - val_tn: 9949.0000 - val_fn: 117.0000 - val_accuracy: 0.9109 - val_precision: 0.0828 - val_recall: 0.4000 - val_auc: 0.7986\n",
            "Epoch 57/100\n",
            "86/86 [==============================] - 15s 174ms/step - loss: 0.4590 - tp: 305.0000 - fp: 4784.0000 - tn: 16840.0000 - fn: 87.0000 - accuracy: 0.7788 - precision: 0.0599 - recall: 0.7781 - auc: 0.8663 - val_loss: 0.2749 - val_tp: 46.0000 - val_fp: 605.0000 - val_tn: 10208.0000 - val_fn: 149.0000 - val_accuracy: 0.9315 - val_precision: 0.0707 - val_recall: 0.2359 - val_auc: 0.7519\n",
            "Epoch 58/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.4311 - tp: 314.0000 - fp: 4727.0000 - tn: 16900.0000 - fn: 75.0000 - accuracy: 0.7819 - precision: 0.0623 - recall: 0.8072 - auc: 0.8807 - val_loss: 0.3357 - val_tp: 69.0000 - val_fp: 888.0000 - val_tn: 9925.0000 - val_fn: 126.0000 - val_accuracy: 0.9079 - val_precision: 0.0721 - val_recall: 0.3538 - val_auc: 0.7345\n",
            "Epoch 59/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.4205 - tp: 317.0000 - fp: 4803.0000 - tn: 16822.0000 - fn: 74.0000 - accuracy: 0.7785 - precision: 0.0619 - recall: 0.8107 - auc: 0.8848 - val_loss: 0.3443 - val_tp: 83.0000 - val_fp: 1185.0000 - val_tn: 9628.0000 - val_fn: 112.0000 - val_accuracy: 0.8822 - val_precision: 0.0655 - val_recall: 0.4256 - val_auc: 0.7694\n",
            "Epoch 60/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.3875 - tp: 326.0000 - fp: 4393.0000 - tn: 17234.0000 - fn: 63.0000 - accuracy: 0.7976 - precision: 0.0691 - recall: 0.8380 - auc: 0.9040 - val_loss: 0.3630 - val_tp: 81.0000 - val_fp: 1281.0000 - val_tn: 9532.0000 - val_fn: 114.0000 - val_accuracy: 0.8733 - val_precision: 0.0595 - val_recall: 0.4154 - val_auc: 0.7451\n",
            "Epoch 61/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.3856 - tp: 325.0000 - fp: 4062.0000 - tn: 17564.0000 - fn: 65.0000 - accuracy: 0.8125 - precision: 0.0741 - recall: 0.8333 - auc: 0.9066 - val_loss: 0.3238 - val_tp: 77.0000 - val_fp: 1121.0000 - val_tn: 9692.0000 - val_fn: 118.0000 - val_accuracy: 0.8874 - val_precision: 0.0643 - val_recall: 0.3949 - val_auc: 0.7408\n",
            "Epoch 62/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.3725 - tp: 341.0000 - fp: 4361.0000 - tn: 17262.0000 - fn: 52.0000 - accuracy: 0.7996 - precision: 0.0725 - recall: 0.8677 - auc: 0.9124 - val_loss: 0.2662 - val_tp: 69.0000 - val_fp: 957.0000 - val_tn: 9856.0000 - val_fn: 126.0000 - val_accuracy: 0.9016 - val_precision: 0.0673 - val_recall: 0.3538 - val_auc: 0.7773\n",
            "Epoch 63/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.3463 - tp: 341.0000 - fp: 3890.0000 - tn: 17733.0000 - fn: 52.0000 - accuracy: 0.8209 - precision: 0.0806 - recall: 0.8677 - auc: 0.9255 - val_loss: 0.2354 - val_tp: 51.0000 - val_fp: 644.0000 - val_tn: 10169.0000 - val_fn: 144.0000 - val_accuracy: 0.9284 - val_precision: 0.0734 - val_recall: 0.2615 - val_auc: 0.7364\n",
            "Epoch 64/100\n",
            "86/86 [==============================] - 14s 169ms/step - loss: 0.3491 - tp: 323.0000 - fp: 3876.0000 - tn: 17751.0000 - fn: 66.0000 - accuracy: 0.8209 - precision: 0.0769 - recall: 0.8303 - auc: 0.9221 - val_loss: 0.2187 - val_tp: 45.0000 - val_fp: 559.0000 - val_tn: 10254.0000 - val_fn: 150.0000 - val_accuracy: 0.9356 - val_precision: 0.0745 - val_recall: 0.2308 - val_auc: 0.7423\n",
            "Epoch 65/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.3401 - tp: 340.0000 - fp: 3888.0000 - tn: 17738.0000 - fn: 50.0000 - accuracy: 0.8211 - precision: 0.0804 - recall: 0.8718 - auc: 0.9272 - val_loss: 0.1916 - val_tp: 34.0000 - val_fp: 428.0000 - val_tn: 10385.0000 - val_fn: 161.0000 - val_accuracy: 0.9465 - val_precision: 0.0736 - val_recall: 0.1744 - val_auc: 0.7357\n",
            "Epoch 66/100\n",
            "86/86 [==============================] - 14s 169ms/step - loss: 0.3286 - tp: 342.0000 - fp: 3726.0000 - tn: 17893.0000 - fn: 55.0000 - accuracy: 0.8283 - precision: 0.0841 - recall: 0.8615 - auc: 0.9339 - val_loss: 0.2187 - val_tp: 44.0000 - val_fp: 568.0000 - val_tn: 10245.0000 - val_fn: 151.0000 - val_accuracy: 0.9347 - val_precision: 0.0719 - val_recall: 0.2256 - val_auc: 0.7430\n",
            "Epoch 67/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.3362 - tp: 340.0000 - fp: 3855.0000 - tn: 17772.0000 - fn: 49.0000 - accuracy: 0.8227 - precision: 0.0810 - recall: 0.8740 - auc: 0.9291 - val_loss: 0.1762 - val_tp: 33.0000 - val_fp: 362.0000 - val_tn: 10451.0000 - val_fn: 162.0000 - val_accuracy: 0.9524 - val_precision: 0.0835 - val_recall: 0.1692 - val_auc: 0.7190\n",
            "Epoch 68/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.3386 - tp: 336.0000 - fp: 3756.0000 - tn: 17866.0000 - fn: 58.0000 - accuracy: 0.8268 - precision: 0.0821 - recall: 0.8528 - auc: 0.9284 - val_loss: 0.2963 - val_tp: 72.0000 - val_fp: 1159.0000 - val_tn: 9654.0000 - val_fn: 123.0000 - val_accuracy: 0.8835 - val_precision: 0.0585 - val_recall: 0.3692 - val_auc: 0.7515\n",
            "Epoch 69/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.3457 - tp: 340.0000 - fp: 3875.0000 - tn: 17751.0000 - fn: 50.0000 - accuracy: 0.8217 - precision: 0.0807 - recall: 0.8718 - auc: 0.9246 - val_loss: 0.1987 - val_tp: 37.0000 - val_fp: 536.0000 - val_tn: 10277.0000 - val_fn: 158.0000 - val_accuracy: 0.9370 - val_precision: 0.0646 - val_recall: 0.1897 - val_auc: 0.7446\n",
            "Epoch 70/100\n",
            "86/86 [==============================] - 14s 169ms/step - loss: 0.3547 - tp: 320.0000 - fp: 3783.0000 - tn: 17845.0000 - fn: 68.0000 - accuracy: 0.8251 - precision: 0.0780 - recall: 0.8247 - auc: 0.9204 - val_loss: 0.1484 - val_tp: 20.0000 - val_fp: 209.0000 - val_tn: 10604.0000 - val_fn: 175.0000 - val_accuracy: 0.9651 - val_precision: 0.0873 - val_recall: 0.1026 - val_auc: 0.7162\n",
            "Epoch 71/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.3632 - tp: 327.0000 - fp: 3988.0000 - tn: 17634.0000 - fn: 67.0000 - accuracy: 0.8158 - precision: 0.0758 - recall: 0.8299 - auc: 0.9162 - val_loss: 0.0997 - val_tp: 4.0000 - val_fp: 59.0000 - val_tn: 10754.0000 - val_fn: 191.0000 - val_accuracy: 0.9773 - val_precision: 0.0635 - val_recall: 0.0205 - val_auc: 0.7594\n",
            "Epoch 1/100\n",
            " 2/86 [..............................] - ETA: 5s - loss: 2.0202 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 503.0000 - fn: 9.0000 - accuracy: 0.9824 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5318WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0113s vs `on_train_batch_end` time: 0.1079s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0113s vs `on_train_batch_end` time: 0.1079s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "86/86 [==============================] - ETA: 0s - loss: 1.9677 - tp: 0.0000e+00 - fp: 6.0000 - tn: 21622.0000 - fn: 388.0000 - accuracy: 0.9821 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5550WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0050s vs `on_test_batch_end` time: 0.0605s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0050s vs `on_test_batch_end` time: 0.0605s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r86/86 [==============================] - 25s 294ms/step - loss: 1.9677 - tp: 0.0000e+00 - fp: 6.0000 - tn: 21622.0000 - fn: 388.0000 - accuracy: 0.9821 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5550 - val_loss: 0.1163 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 10813.0000 - val_fn: 195.0000 - val_accuracy: 0.9823 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
            "Epoch 2/100\n",
            "86/86 [==============================] - 15s 176ms/step - loss: 1.4805 - tp: 37.0000 - fp: 1310.0000 - tn: 20315.0000 - fn: 354.0000 - accuracy: 0.9244 - precision: 0.0275 - recall: 0.0946 - auc: 0.6422 - val_loss: 0.0889 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 10813.0000 - val_fn: 195.0000 - val_accuracy: 0.9823 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7186\n",
            "Epoch 3/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 1.0055 - tp: 144.0000 - fp: 4197.0000 - tn: 17427.0000 - fn: 248.0000 - accuracy: 0.7981 - precision: 0.0332 - recall: 0.3673 - auc: 0.6662 - val_loss: 0.0846 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 10813.0000 - val_fn: 195.0000 - val_accuracy: 0.9823 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7274\n",
            "Epoch 4/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.7664 - tp: 200.0000 - fp: 5514.0000 - tn: 16114.0000 - fn: 188.0000 - accuracy: 0.7410 - precision: 0.0350 - recall: 0.5155 - auc: 0.7056 - val_loss: 0.3644 - val_tp: 88.0000 - val_fp: 1238.0000 - val_tn: 9575.0000 - val_fn: 107.0000 - val_accuracy: 0.8778 - val_precision: 0.0664 - val_recall: 0.4513 - val_auc: 0.7746\n",
            "Epoch 5/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.6927 - tp: 237.0000 - fp: 6714.0000 - tn: 14914.0000 - fn: 151.0000 - accuracy: 0.6882 - precision: 0.0341 - recall: 0.6108 - auc: 0.7078 - val_loss: 0.2393 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 10812.0000 - val_fn: 195.0000 - val_accuracy: 0.9822 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5122\n",
            "Epoch 6/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.6884 - tp: 237.0000 - fp: 6267.0000 - tn: 15356.0000 - fn: 156.0000 - accuracy: 0.7083 - precision: 0.0364 - recall: 0.6031 - auc: 0.7162 - val_loss: 0.3231 - val_tp: 97.0000 - val_fp: 1595.0000 - val_tn: 9218.0000 - val_fn: 98.0000 - val_accuracy: 0.8462 - val_precision: 0.0573 - val_recall: 0.4974 - val_auc: 0.7816\n",
            "Epoch 7/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.6341 - tp: 252.0000 - fp: 6866.0000 - tn: 14763.0000 - fn: 135.0000 - accuracy: 0.6820 - precision: 0.0354 - recall: 0.6512 - auc: 0.7374 - val_loss: 0.2360 - val_tp: 0.0000e+00 - val_fp: 31.0000 - val_tn: 10782.0000 - val_fn: 195.0000 - val_accuracy: 0.9795 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5429\n",
            "Epoch 8/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.6010 - tp: 253.0000 - fp: 6481.0000 - tn: 15146.0000 - fn: 136.0000 - accuracy: 0.6994 - precision: 0.0376 - recall: 0.6504 - auc: 0.7525 - val_loss: 0.2650 - val_tp: 72.0000 - val_fp: 823.0000 - val_tn: 9990.0000 - val_fn: 123.0000 - val_accuracy: 0.9141 - val_precision: 0.0804 - val_recall: 0.3692 - val_auc: 0.7852\n",
            "Epoch 9/100\n",
            "86/86 [==============================] - 15s 172ms/step - loss: 0.6327 - tp: 244.0000 - fp: 6721.0000 - tn: 14905.0000 - fn: 146.0000 - accuracy: 0.6881 - precision: 0.0350 - recall: 0.6256 - auc: 0.7292 - val_loss: 0.1852 - val_tp: 19.0000 - val_fp: 384.0000 - val_tn: 10429.0000 - val_fn: 176.0000 - val_accuracy: 0.9491 - val_precision: 0.0471 - val_recall: 0.0974 - val_auc: 0.6280\n",
            "Epoch 10/100\n",
            "86/86 [==============================] - 15s 172ms/step - loss: 0.6024 - tp: 266.0000 - fp: 7023.0000 - tn: 14600.0000 - fn: 127.0000 - accuracy: 0.6752 - precision: 0.0365 - recall: 0.6768 - auc: 0.7522 - val_loss: 0.2733 - val_tp: 2.0000 - val_fp: 16.0000 - val_tn: 10797.0000 - val_fn: 193.0000 - val_accuracy: 0.9810 - val_precision: 0.1111 - val_recall: 0.0103 - val_auc: 0.5144\n",
            "Epoch 11/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.5929 - tp: 253.0000 - fp: 6561.0000 - tn: 15065.0000 - fn: 137.0000 - accuracy: 0.6958 - precision: 0.0371 - recall: 0.6487 - auc: 0.7555 - val_loss: 0.2809 - val_tp: 98.0000 - val_fp: 1304.0000 - val_tn: 9509.0000 - val_fn: 97.0000 - val_accuracy: 0.8727 - val_precision: 0.0699 - val_recall: 0.5026 - val_auc: 0.7819\n",
            "Epoch 12/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.7119 - tp: 244.0000 - fp: 6348.0000 - tn: 15276.0000 - fn: 148.0000 - accuracy: 0.7049 - precision: 0.0370 - recall: 0.6224 - auc: 0.7341 - val_loss: 0.8659 - val_tp: 166.0000 - val_fp: 5682.0000 - val_tn: 5131.0000 - val_fn: 29.0000 - val_accuracy: 0.4812 - val_precision: 0.0284 - val_recall: 0.8513 - val_auc: 0.7559\n",
            "Epoch 13/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.6292 - tp: 245.0000 - fp: 5949.0000 - tn: 15672.0000 - fn: 150.0000 - accuracy: 0.7230 - precision: 0.0396 - recall: 0.6203 - auc: 0.7453 - val_loss: 0.2482 - val_tp: 51.0000 - val_fp: 445.0000 - val_tn: 10368.0000 - val_fn: 144.0000 - val_accuracy: 0.9465 - val_precision: 0.1028 - val_recall: 0.2615 - val_auc: 0.8071\n",
            "Epoch 14/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.6021 - tp: 257.0000 - fp: 6447.0000 - tn: 15177.0000 - fn: 135.0000 - accuracy: 0.7010 - precision: 0.0383 - recall: 0.6556 - auc: 0.7626 - val_loss: 0.2043 - val_tp: 35.0000 - val_fp: 191.0000 - val_tn: 10622.0000 - val_fn: 160.0000 - val_accuracy: 0.9681 - val_precision: 0.1549 - val_recall: 0.1795 - val_auc: 0.8096\n",
            "Epoch 15/100\n",
            "86/86 [==============================] - 15s 173ms/step - loss: 0.6171 - tp: 266.0000 - fp: 6737.0000 - tn: 14889.0000 - fn: 124.0000 - accuracy: 0.6884 - precision: 0.0380 - recall: 0.6821 - auc: 0.7638 - val_loss: 0.2739 - val_tp: 66.0000 - val_fp: 637.0000 - val_tn: 10176.0000 - val_fn: 129.0000 - val_accuracy: 0.9304 - val_precision: 0.0939 - val_recall: 0.3385 - val_auc: 0.8148\n",
            "Epoch 16/100\n",
            "86/86 [==============================] - 15s 175ms/step - loss: 0.5773 - tp: 247.0000 - fp: 6235.0000 - tn: 15391.0000 - fn: 143.0000 - accuracy: 0.7103 - precision: 0.0381 - recall: 0.6333 - auc: 0.7655 - val_loss: 0.2563 - val_tp: 61.0000 - val_fp: 565.0000 - val_tn: 10248.0000 - val_fn: 134.0000 - val_accuracy: 0.9365 - val_precision: 0.0974 - val_recall: 0.3128 - val_auc: 0.8153\n",
            "Epoch 17/100\n",
            "86/86 [==============================] - 15s 172ms/step - loss: 0.5964 - tp: 264.0000 - fp: 6317.0000 - tn: 15310.0000 - fn: 125.0000 - accuracy: 0.7074 - precision: 0.0401 - recall: 0.6787 - auc: 0.7703 - val_loss: 0.2662 - val_tp: 60.0000 - val_fp: 543.0000 - val_tn: 10270.0000 - val_fn: 135.0000 - val_accuracy: 0.9384 - val_precision: 0.0995 - val_recall: 0.3077 - val_auc: 0.8112\n",
            "Epoch 18/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.5736 - tp: 275.0000 - fp: 6779.0000 - tn: 14845.0000 - fn: 117.0000 - accuracy: 0.6868 - precision: 0.0390 - recall: 0.7015 - auc: 0.7675 - val_loss: 0.2802 - val_tp: 63.0000 - val_fp: 562.0000 - val_tn: 10251.0000 - val_fn: 132.0000 - val_accuracy: 0.9370 - val_precision: 0.1008 - val_recall: 0.3231 - val_auc: 0.8009\n",
            "Epoch 19/100\n",
            "86/86 [==============================] - 15s 176ms/step - loss: 0.5777 - tp: 262.0000 - fp: 6355.0000 - tn: 15272.0000 - fn: 127.0000 - accuracy: 0.7056 - precision: 0.0396 - recall: 0.6735 - auc: 0.7717 - val_loss: 0.4214 - val_tp: 104.0000 - val_fp: 1436.0000 - val_tn: 9377.0000 - val_fn: 91.0000 - val_accuracy: 0.8613 - val_precision: 0.0675 - val_recall: 0.5333 - val_auc: 0.7956\n",
            "Epoch 20/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.5903 - tp: 255.0000 - fp: 6794.0000 - tn: 14830.0000 - fn: 137.0000 - accuracy: 0.6852 - precision: 0.0362 - recall: 0.6505 - auc: 0.7560 - val_loss: 0.3618 - val_tp: 94.0000 - val_fp: 1154.0000 - val_tn: 9659.0000 - val_fn: 101.0000 - val_accuracy: 0.8860 - val_precision: 0.0753 - val_recall: 0.4821 - val_auc: 0.8073\n",
            "Epoch 21/100\n",
            "86/86 [==============================] - 14s 169ms/step - loss: 0.5838 - tp: 263.0000 - fp: 7025.0000 - tn: 14599.0000 - fn: 129.0000 - accuracy: 0.6751 - precision: 0.0361 - recall: 0.6709 - auc: 0.7587 - val_loss: 0.2300 - val_tp: 41.0000 - val_fp: 344.0000 - val_tn: 10469.0000 - val_fn: 154.0000 - val_accuracy: 0.9548 - val_precision: 0.1065 - val_recall: 0.2103 - val_auc: 0.8102\n",
            "Epoch 22/100\n",
            "86/86 [==============================] - 15s 175ms/step - loss: 0.6478 - tp: 260.0000 - fp: 6215.0000 - tn: 15407.0000 - fn: 134.0000 - accuracy: 0.7116 - precision: 0.0402 - recall: 0.6599 - auc: 0.7593 - val_loss: 0.9314 - val_tp: 144.0000 - val_fp: 4240.0000 - val_tn: 6573.0000 - val_fn: 51.0000 - val_accuracy: 0.6102 - val_precision: 0.0328 - val_recall: 0.7385 - val_auc: 0.7412\n",
            "Epoch 23/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.6452 - tp: 255.0000 - fp: 6511.0000 - tn: 15116.0000 - fn: 134.0000 - accuracy: 0.6982 - precision: 0.0377 - recall: 0.6555 - auc: 0.7526 - val_loss: 0.5679 - val_tp: 114.0000 - val_fp: 3026.0000 - val_tn: 7787.0000 - val_fn: 81.0000 - val_accuracy: 0.7178 - val_precision: 0.0363 - val_recall: 0.5846 - val_auc: 0.6999\n",
            "Epoch 24/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5879 - tp: 269.0000 - fp: 6666.0000 - tn: 14959.0000 - fn: 122.0000 - accuracy: 0.6917 - precision: 0.0388 - recall: 0.6880 - auc: 0.7593 - val_loss: 0.2135 - val_tp: 30.0000 - val_fp: 248.0000 - val_tn: 10565.0000 - val_fn: 165.0000 - val_accuracy: 0.9625 - val_precision: 0.1079 - val_recall: 0.1538 - val_auc: 0.8115\n",
            "Epoch 25/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5705 - tp: 272.0000 - fp: 7050.0000 - tn: 14573.0000 - fn: 121.0000 - accuracy: 0.6743 - precision: 0.0371 - recall: 0.6921 - auc: 0.7689 - val_loss: 0.2138 - val_tp: 1.0000 - val_fp: 12.0000 - val_tn: 10801.0000 - val_fn: 194.0000 - val_accuracy: 0.9813 - val_precision: 0.0769 - val_recall: 0.0051 - val_auc: 0.5610\n",
            "Epoch 26/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.6104 - tp: 278.0000 - fp: 6428.0000 - tn: 15195.0000 - fn: 115.0000 - accuracy: 0.7028 - precision: 0.0415 - recall: 0.7074 - auc: 0.7789 - val_loss: 0.1841 - val_tp: 47.0000 - val_fp: 564.0000 - val_tn: 10249.0000 - val_fn: 148.0000 - val_accuracy: 0.9353 - val_precision: 0.0769 - val_recall: 0.2410 - val_auc: 0.7690\n",
            "Epoch 27/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5553 - tp: 275.0000 - fp: 6392.0000 - tn: 15235.0000 - fn: 114.0000 - accuracy: 0.7045 - precision: 0.0412 - recall: 0.7069 - auc: 0.7894 - val_loss: 0.2410 - val_tp: 58.0000 - val_fp: 608.0000 - val_tn: 10205.0000 - val_fn: 137.0000 - val_accuracy: 0.9323 - val_precision: 0.0871 - val_recall: 0.2974 - val_auc: 0.7749\n",
            "Epoch 28/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5380 - tp: 293.0000 - fp: 6432.0000 - tn: 15195.0000 - fn: 96.0000 - accuracy: 0.7035 - precision: 0.0436 - recall: 0.7532 - auc: 0.8011 - val_loss: 0.1121 - val_tp: 9.0000 - val_fp: 47.0000 - val_tn: 10766.0000 - val_fn: 186.0000 - val_accuracy: 0.9788 - val_precision: 0.1607 - val_recall: 0.0462 - val_auc: 0.7742\n",
            "Epoch 29/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5204 - tp: 290.0000 - fp: 6339.0000 - tn: 15287.0000 - fn: 100.0000 - accuracy: 0.7075 - precision: 0.0437 - recall: 0.7436 - auc: 0.8087 - val_loss: 0.1369 - val_tp: 19.0000 - val_fp: 154.0000 - val_tn: 10659.0000 - val_fn: 176.0000 - val_accuracy: 0.9700 - val_precision: 0.1098 - val_recall: 0.0974 - val_auc: 0.7323\n",
            "Epoch 30/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5442 - tp: 288.0000 - fp: 6335.0000 - tn: 15291.0000 - fn: 102.0000 - accuracy: 0.7076 - precision: 0.0435 - recall: 0.7385 - auc: 0.8089 - val_loss: 0.2103 - val_tp: 55.0000 - val_fp: 759.0000 - val_tn: 10054.0000 - val_fn: 140.0000 - val_accuracy: 0.9183 - val_precision: 0.0676 - val_recall: 0.2821 - val_auc: 0.7466\n",
            "Epoch 31/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5155 - tp: 305.0000 - fp: 6521.0000 - tn: 15105.0000 - fn: 85.0000 - accuracy: 0.6999 - precision: 0.0447 - recall: 0.7821 - auc: 0.8158 - val_loss: 0.1708 - val_tp: 44.0000 - val_fp: 471.0000 - val_tn: 10342.0000 - val_fn: 151.0000 - val_accuracy: 0.9435 - val_precision: 0.0854 - val_recall: 0.2256 - val_auc: 0.7436\n",
            "Epoch 32/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.5006 - tp: 302.0000 - fp: 6246.0000 - tn: 15383.0000 - fn: 85.0000 - accuracy: 0.7124 - precision: 0.0461 - recall: 0.7804 - auc: 0.8262 - val_loss: 0.2213 - val_tp: 59.0000 - val_fp: 839.0000 - val_tn: 9974.0000 - val_fn: 136.0000 - val_accuracy: 0.9114 - val_precision: 0.0657 - val_recall: 0.3026 - val_auc: 0.7590\n",
            "Epoch 33/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5128 - tp: 305.0000 - fp: 6273.0000 - tn: 15351.0000 - fn: 87.0000 - accuracy: 0.7111 - precision: 0.0464 - recall: 0.7781 - auc: 0.8199 - val_loss: 0.2178 - val_tp: 55.0000 - val_fp: 767.0000 - val_tn: 10046.0000 - val_fn: 140.0000 - val_accuracy: 0.9176 - val_precision: 0.0669 - val_recall: 0.2821 - val_auc: 0.7316\n",
            "Epoch 34/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5145 - tp: 294.0000 - fp: 6231.0000 - tn: 15392.0000 - fn: 99.0000 - accuracy: 0.7125 - precision: 0.0451 - recall: 0.7481 - auc: 0.8208 - val_loss: 0.2455 - val_tp: 62.0000 - val_fp: 1022.0000 - val_tn: 9791.0000 - val_fn: 133.0000 - val_accuracy: 0.8951 - val_precision: 0.0572 - val_recall: 0.3179 - val_auc: 0.7361\n",
            "Epoch 35/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5130 - tp: 287.0000 - fp: 5893.0000 - tn: 15732.0000 - fn: 104.0000 - accuracy: 0.7276 - precision: 0.0464 - recall: 0.7340 - auc: 0.8209 - val_loss: 0.1416 - val_tp: 30.0000 - val_fp: 262.0000 - val_tn: 10551.0000 - val_fn: 165.0000 - val_accuracy: 0.9612 - val_precision: 0.1027 - val_recall: 0.1538 - val_auc: 0.7510\n",
            "Epoch 36/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.5176 - tp: 292.0000 - fp: 6479.0000 - tn: 15147.0000 - fn: 98.0000 - accuracy: 0.7013 - precision: 0.0431 - recall: 0.7487 - auc: 0.8122 - val_loss: 0.1686 - val_tp: 41.0000 - val_fp: 450.0000 - val_tn: 10363.0000 - val_fn: 154.0000 - val_accuracy: 0.9451 - val_precision: 0.0835 - val_recall: 0.2103 - val_auc: 0.7501\n",
            "Epoch 37/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5263 - tp: 296.0000 - fp: 5907.0000 - tn: 15715.0000 - fn: 98.0000 - accuracy: 0.7272 - precision: 0.0477 - recall: 0.7513 - auc: 0.8174 - val_loss: 0.1688 - val_tp: 23.0000 - val_fp: 307.0000 - val_tn: 10506.0000 - val_fn: 172.0000 - val_accuracy: 0.9565 - val_precision: 0.0697 - val_recall: 0.1179 - val_auc: 0.7821\n",
            "Epoch 38/100\n",
            "86/86 [==============================] - 15s 172ms/step - loss: 0.5250 - tp: 295.0000 - fp: 6280.0000 - tn: 15347.0000 - fn: 94.0000 - accuracy: 0.7105 - precision: 0.0449 - recall: 0.7584 - auc: 0.8118 - val_loss: 0.1683 - val_tp: 34.0000 - val_fp: 423.0000 - val_tn: 10390.0000 - val_fn: 161.0000 - val_accuracy: 0.9469 - val_precision: 0.0744 - val_recall: 0.1744 - val_auc: 0.7430\n",
            "Epoch 39/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5309 - tp: 294.0000 - fp: 6388.0000 - tn: 15239.0000 - fn: 95.0000 - accuracy: 0.7055 - precision: 0.0440 - recall: 0.7558 - auc: 0.8078 - val_loss: 0.2035 - val_tp: 1.0000 - val_fp: 29.0000 - val_tn: 10784.0000 - val_fn: 194.0000 - val_accuracy: 0.9797 - val_precision: 0.0333 - val_recall: 0.0051 - val_auc: 0.5702\n",
            "Epoch 40/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5333 - tp: 279.0000 - fp: 6314.0000 - tn: 15314.0000 - fn: 109.0000 - accuracy: 0.7083 - precision: 0.0423 - recall: 0.7191 - auc: 0.8015 - val_loss: 0.1598 - val_tp: 14.0000 - val_fp: 145.0000 - val_tn: 10668.0000 - val_fn: 181.0000 - val_accuracy: 0.9704 - val_precision: 0.0881 - val_recall: 0.0718 - val_auc: 0.6616\n",
            "Epoch 41/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.5356 - tp: 273.0000 - fp: 6029.0000 - tn: 15599.0000 - fn: 115.0000 - accuracy: 0.7209 - precision: 0.0433 - recall: 0.7036 - auc: 0.8055 - val_loss: 0.1634 - val_tp: 20.0000 - val_fp: 250.0000 - val_tn: 10563.0000 - val_fn: 175.0000 - val_accuracy: 0.9614 - val_precision: 0.0741 - val_recall: 0.1026 - val_auc: 0.6706\n",
            "Epoch 42/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5299 - tp: 290.0000 - fp: 5969.0000 - tn: 15656.0000 - fn: 101.0000 - accuracy: 0.7243 - precision: 0.0463 - recall: 0.7417 - auc: 0.8129 - val_loss: 0.1955 - val_tp: 33.0000 - val_fp: 421.0000 - val_tn: 10392.0000 - val_fn: 162.0000 - val_accuracy: 0.9470 - val_precision: 0.0727 - val_recall: 0.1692 - val_auc: 0.7866\n",
            "Epoch 43/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4802 - tp: 314.0000 - fp: 5703.0000 - tn: 15922.0000 - fn: 77.0000 - accuracy: 0.7375 - precision: 0.0522 - recall: 0.8031 - auc: 0.8469 - val_loss: 0.1736 - val_tp: 35.0000 - val_fp: 371.0000 - val_tn: 10442.0000 - val_fn: 160.0000 - val_accuracy: 0.9518 - val_precision: 0.0862 - val_recall: 0.1795 - val_auc: 0.8056\n",
            "Epoch 44/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5055 - tp: 291.0000 - fp: 6042.0000 - tn: 15583.0000 - fn: 100.0000 - accuracy: 0.7210 - precision: 0.0459 - recall: 0.7442 - auc: 0.8265 - val_loss: 0.1285 - val_tp: 17.0000 - val_fp: 143.0000 - val_tn: 10670.0000 - val_fn: 178.0000 - val_accuracy: 0.9708 - val_precision: 0.1063 - val_recall: 0.0872 - val_auc: 0.7790\n",
            "Epoch 45/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.4725 - tp: 312.0000 - fp: 5960.0000 - tn: 15666.0000 - fn: 78.0000 - accuracy: 0.7257 - precision: 0.0497 - recall: 0.8000 - auc: 0.8484 - val_loss: 0.1226 - val_tp: 24.0000 - val_fp: 169.0000 - val_tn: 10644.0000 - val_fn: 171.0000 - val_accuracy: 0.9691 - val_precision: 0.1244 - val_recall: 0.1231 - val_auc: 0.7783\n",
            "Epoch 46/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.4648 - tp: 307.0000 - fp: 5305.0000 - tn: 16322.0000 - fn: 82.0000 - accuracy: 0.7553 - precision: 0.0547 - recall: 0.7892 - auc: 0.8578 - val_loss: 0.2170 - val_tp: 61.0000 - val_fp: 740.0000 - val_tn: 10073.0000 - val_fn: 134.0000 - val_accuracy: 0.9206 - val_precision: 0.0762 - val_recall: 0.3128 - val_auc: 0.7946\n",
            "Epoch 47/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.4695 - tp: 302.0000 - fp: 5430.0000 - tn: 16194.0000 - fn: 90.0000 - accuracy: 0.7493 - precision: 0.0527 - recall: 0.7704 - auc: 0.8524 - val_loss: 0.1658 - val_tp: 37.0000 - val_fp: 449.0000 - val_tn: 10364.0000 - val_fn: 158.0000 - val_accuracy: 0.9449 - val_precision: 0.0761 - val_recall: 0.1897 - val_auc: 0.7902\n",
            "Epoch 48/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.4346 - tp: 316.0000 - fp: 5169.0000 - tn: 16458.0000 - fn: 73.0000 - accuracy: 0.7619 - precision: 0.0576 - recall: 0.8123 - auc: 0.8767 - val_loss: 0.1914 - val_tp: 53.0000 - val_fp: 651.0000 - val_tn: 10162.0000 - val_fn: 142.0000 - val_accuracy: 0.9280 - val_precision: 0.0753 - val_recall: 0.2718 - val_auc: 0.7869\n",
            "Epoch 49/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.4393 - tp: 319.0000 - fp: 5190.0000 - tn: 16438.0000 - fn: 69.0000 - accuracy: 0.7611 - precision: 0.0579 - recall: 0.8222 - auc: 0.8736 - val_loss: 0.1754 - val_tp: 46.0000 - val_fp: 525.0000 - val_tn: 10288.0000 - val_fn: 149.0000 - val_accuracy: 0.9388 - val_precision: 0.0806 - val_recall: 0.2359 - val_auc: 0.7889\n",
            "Epoch 50/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4465 - tp: 305.0000 - fp: 5204.0000 - tn: 16423.0000 - fn: 84.0000 - accuracy: 0.7598 - precision: 0.0554 - recall: 0.7841 - auc: 0.8673 - val_loss: 0.1779 - val_tp: 40.0000 - val_fp: 498.0000 - val_tn: 10315.0000 - val_fn: 155.0000 - val_accuracy: 0.9407 - val_precision: 0.0743 - val_recall: 0.2051 - val_auc: 0.7873\n",
            "Epoch 51/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.4327 - tp: 327.0000 - fp: 5166.0000 - tn: 16458.0000 - fn: 65.0000 - accuracy: 0.7624 - precision: 0.0595 - recall: 0.8342 - auc: 0.8792 - val_loss: 0.1943 - val_tp: 56.0000 - val_fp: 683.0000 - val_tn: 10130.0000 - val_fn: 139.0000 - val_accuracy: 0.9253 - val_precision: 0.0758 - val_recall: 0.2872 - val_auc: 0.7763\n",
            "Epoch 52/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.4441 - tp: 312.0000 - fp: 5064.0000 - tn: 16563.0000 - fn: 77.0000 - accuracy: 0.7665 - precision: 0.0580 - recall: 0.8021 - auc: 0.8697 - val_loss: 0.1488 - val_tp: 47.0000 - val_fp: 351.0000 - val_tn: 10462.0000 - val_fn: 148.0000 - val_accuracy: 0.9547 - val_precision: 0.1181 - val_recall: 0.2410 - val_auc: 0.7960\n",
            "Epoch 53/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.4280 - tp: 317.0000 - fp: 4908.0000 - tn: 16718.0000 - fn: 73.0000 - accuracy: 0.7738 - precision: 0.0607 - recall: 0.8128 - auc: 0.8819 - val_loss: 0.1479 - val_tp: 15.0000 - val_fp: 254.0000 - val_tn: 10559.0000 - val_fn: 180.0000 - val_accuracy: 0.9606 - val_precision: 0.0558 - val_recall: 0.0769 - val_auc: 0.7668\n",
            "Epoch 54/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.4289 - tp: 311.0000 - fp: 4856.0000 - tn: 16770.0000 - fn: 79.0000 - accuracy: 0.7758 - precision: 0.0602 - recall: 0.7974 - auc: 0.8786 - val_loss: 0.2358 - val_tp: 65.0000 - val_fp: 1011.0000 - val_tn: 9802.0000 - val_fn: 130.0000 - val_accuracy: 0.8963 - val_precision: 0.0604 - val_recall: 0.3333 - val_auc: 0.7753\n",
            "Epoch 55/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.4836 - tp: 302.0000 - fp: 5314.0000 - tn: 16312.0000 - fn: 88.0000 - accuracy: 0.7546 - precision: 0.0538 - recall: 0.7744 - auc: 0.8485 - val_loss: 0.1241 - val_tp: 1.0000 - val_fp: 20.0000 - val_tn: 10793.0000 - val_fn: 194.0000 - val_accuracy: 0.9806 - val_precision: 0.0476 - val_recall: 0.0051 - val_auc: 0.6623\n",
            "Epoch 1/100\n",
            " 2/86 [..............................] - ETA: 5s - loss: 2.8036 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 500.0000 - fn: 12.0000 - accuracy: 0.9766 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4626WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0128s vs `on_train_batch_end` time: 0.1129s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0128s vs `on_train_batch_end` time: 0.1129s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "86/86 [==============================] - ETA: 0s - loss: 1.9041 - tp: 0.0000e+00 - fp: 26.0000 - tn: 21601.0000 - fn: 389.0000 - accuracy: 0.9812 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5842WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0050s vs `on_test_batch_end` time: 0.0632s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0050s vs `on_test_batch_end` time: 0.0632s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r86/86 [==============================] - 26s 304ms/step - loss: 1.9041 - tp: 0.0000e+00 - fp: 26.0000 - tn: 21601.0000 - fn: 389.0000 - accuracy: 0.9812 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5842 - val_loss: 0.0865 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 10813.0000 - val_fn: 195.0000 - val_accuracy: 0.9823 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6776\n",
            "Epoch 2/100\n",
            "86/86 [==============================] - 15s 174ms/step - loss: 1.4350 - tp: 52.0000 - fp: 1244.0000 - tn: 20377.0000 - fn: 343.0000 - accuracy: 0.9279 - precision: 0.0401 - recall: 0.1316 - auc: 0.6318 - val_loss: 0.0894 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 10813.0000 - val_fn: 195.0000 - val_accuracy: 0.9823 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7058\n",
            "Epoch 3/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.8910 - tp: 171.0000 - fp: 4762.0000 - tn: 16863.0000 - fn: 220.0000 - accuracy: 0.7737 - precision: 0.0347 - recall: 0.4373 - auc: 0.6824 - val_loss: 0.1183 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 10813.0000 - val_fn: 195.0000 - val_accuracy: 0.9823 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5659\n",
            "Epoch 4/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.7779 - tp: 202.0000 - fp: 5922.0000 - tn: 15704.0000 - fn: 188.0000 - accuracy: 0.7225 - precision: 0.0330 - recall: 0.5179 - auc: 0.6989 - val_loss: 0.4876 - val_tp: 106.0000 - val_fp: 1913.0000 - val_tn: 8900.0000 - val_fn: 89.0000 - val_accuracy: 0.8181 - val_precision: 0.0525 - val_recall: 0.5436 - val_auc: 0.7635\n",
            "Epoch 5/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.8036 - tp: 201.0000 - fp: 5183.0000 - tn: 16444.0000 - fn: 188.0000 - accuracy: 0.7560 - precision: 0.0373 - recall: 0.5167 - auc: 0.6955 - val_loss: 0.3945 - val_tp: 95.0000 - val_fp: 1369.0000 - val_tn: 9444.0000 - val_fn: 100.0000 - val_accuracy: 0.8666 - val_precision: 0.0649 - val_recall: 0.4872 - val_auc: 0.7769\n",
            "Epoch 6/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.7039 - tp: 237.0000 - fp: 6230.0000 - tn: 15398.0000 - fn: 151.0000 - accuracy: 0.7102 - precision: 0.0366 - recall: 0.6108 - auc: 0.7300 - val_loss: 1.0870 - val_tp: 184.0000 - val_fp: 8803.0000 - val_tn: 2010.0000 - val_fn: 11.0000 - val_accuracy: 0.1993 - val_precision: 0.0205 - val_recall: 0.9436 - val_auc: 0.7059\n",
            "Epoch 7/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.6689 - tp: 233.0000 - fp: 6369.0000 - tn: 15258.0000 - fn: 156.0000 - accuracy: 0.7036 - precision: 0.0353 - recall: 0.5990 - auc: 0.7206 - val_loss: 0.4081 - val_tp: 95.0000 - val_fp: 1548.0000 - val_tn: 9265.0000 - val_fn: 100.0000 - val_accuracy: 0.8503 - val_precision: 0.0578 - val_recall: 0.4872 - val_auc: 0.7875\n",
            "Epoch 8/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.6012 - tp: 254.0000 - fp: 6808.0000 - tn: 14818.0000 - fn: 136.0000 - accuracy: 0.6846 - precision: 0.0360 - recall: 0.6513 - auc: 0.7471 - val_loss: 0.5186 - val_tp: 123.0000 - val_fp: 2528.0000 - val_tn: 8285.0000 - val_fn: 72.0000 - val_accuracy: 0.7638 - val_precision: 0.0464 - val_recall: 0.6308 - val_auc: 0.7837\n",
            "Epoch 9/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.7144 - tp: 237.0000 - fp: 5983.0000 - tn: 15639.0000 - fn: 157.0000 - accuracy: 0.7211 - precision: 0.0381 - recall: 0.6015 - auc: 0.7410 - val_loss: 0.8591 - val_tp: 173.0000 - val_fp: 6498.0000 - val_tn: 4315.0000 - val_fn: 22.0000 - val_accuracy: 0.4077 - val_precision: 0.0259 - val_recall: 0.8872 - val_auc: 0.7394\n",
            "Epoch 10/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.6614 - tp: 241.0000 - fp: 6225.0000 - tn: 15400.0000 - fn: 150.0000 - accuracy: 0.7104 - precision: 0.0373 - recall: 0.6164 - auc: 0.7396 - val_loss: 0.5977 - val_tp: 126.0000 - val_fp: 3297.0000 - val_tn: 7516.0000 - val_fn: 69.0000 - val_accuracy: 0.6942 - val_precision: 0.0368 - val_recall: 0.6462 - val_auc: 0.7575\n",
            "Epoch 11/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5789 - tp: 266.0000 - fp: 6728.0000 - tn: 14895.0000 - fn: 127.0000 - accuracy: 0.6886 - precision: 0.0380 - recall: 0.6768 - auc: 0.7611 - val_loss: 0.3792 - val_tp: 91.0000 - val_fp: 1224.0000 - val_tn: 9589.0000 - val_fn: 104.0000 - val_accuracy: 0.8794 - val_precision: 0.0692 - val_recall: 0.4667 - val_auc: 0.7851\n",
            "Epoch 12/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5607 - tp: 273.0000 - fp: 6794.0000 - tn: 14829.0000 - fn: 120.0000 - accuracy: 0.6860 - precision: 0.0386 - recall: 0.6947 - auc: 0.7756 - val_loss: 0.2909 - val_tp: 69.0000 - val_fp: 815.0000 - val_tn: 9998.0000 - val_fn: 126.0000 - val_accuracy: 0.9145 - val_precision: 0.0781 - val_recall: 0.3538 - val_auc: 0.8009\n",
            "Epoch 13/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5733 - tp: 271.0000 - fp: 6349.0000 - tn: 15277.0000 - fn: 119.0000 - accuracy: 0.7062 - precision: 0.0409 - recall: 0.6949 - auc: 0.7784 - val_loss: 0.2925 - val_tp: 63.0000 - val_fp: 769.0000 - val_tn: 10044.0000 - val_fn: 132.0000 - val_accuracy: 0.9182 - val_precision: 0.0757 - val_recall: 0.3231 - val_auc: 0.7945\n",
            "Epoch 14/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5537 - tp: 274.0000 - fp: 6484.0000 - tn: 15143.0000 - fn: 115.0000 - accuracy: 0.7003 - precision: 0.0405 - recall: 0.7044 - auc: 0.7843 - val_loss: 0.3459 - val_tp: 82.0000 - val_fp: 1076.0000 - val_tn: 9737.0000 - val_fn: 113.0000 - val_accuracy: 0.8920 - val_precision: 0.0708 - val_recall: 0.4205 - val_auc: 0.8007\n",
            "Epoch 15/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5568 - tp: 280.0000 - fp: 7145.0000 - tn: 14480.0000 - fn: 111.0000 - accuracy: 0.6704 - precision: 0.0377 - recall: 0.7161 - auc: 0.7777 - val_loss: 0.3013 - val_tp: 65.0000 - val_fp: 881.0000 - val_tn: 9932.0000 - val_fn: 130.0000 - val_accuracy: 0.9082 - val_precision: 0.0687 - val_recall: 0.3333 - val_auc: 0.7953\n",
            "Epoch 16/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5390 - tp: 288.0000 - fp: 6973.0000 - tn: 14653.0000 - fn: 102.0000 - accuracy: 0.6786 - precision: 0.0397 - recall: 0.7385 - auc: 0.7910 - val_loss: 0.3086 - val_tp: 68.0000 - val_fp: 873.0000 - val_tn: 9940.0000 - val_fn: 127.0000 - val_accuracy: 0.9092 - val_precision: 0.0723 - val_recall: 0.3487 - val_auc: 0.7980\n",
            "Epoch 17/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5588 - tp: 273.0000 - fp: 6786.0000 - tn: 14840.0000 - fn: 117.0000 - accuracy: 0.6865 - precision: 0.0387 - recall: 0.7000 - auc: 0.7751 - val_loss: 0.3420 - val_tp: 77.0000 - val_fp: 1061.0000 - val_tn: 9752.0000 - val_fn: 118.0000 - val_accuracy: 0.8929 - val_precision: 0.0677 - val_recall: 0.3949 - val_auc: 0.7998\n",
            "Epoch 18/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5456 - tp: 279.0000 - fp: 6468.0000 - tn: 15157.0000 - fn: 112.0000 - accuracy: 0.7011 - precision: 0.0414 - recall: 0.7136 - auc: 0.7917 - val_loss: 0.4335 - val_tp: 104.0000 - val_fp: 1622.0000 - val_tn: 9191.0000 - val_fn: 91.0000 - val_accuracy: 0.8444 - val_precision: 0.0603 - val_recall: 0.5333 - val_auc: 0.8020\n",
            "Epoch 19/100\n",
            "86/86 [==============================] - 14s 169ms/step - loss: 0.5445 - tp: 291.0000 - fp: 6911.0000 - tn: 14714.0000 - fn: 100.0000 - accuracy: 0.6815 - precision: 0.0404 - recall: 0.7442 - auc: 0.7887 - val_loss: 0.2647 - val_tp: 60.0000 - val_fp: 717.0000 - val_tn: 10096.0000 - val_fn: 135.0000 - val_accuracy: 0.9226 - val_precision: 0.0772 - val_recall: 0.3077 - val_auc: 0.7856\n",
            "Epoch 20/100\n",
            "86/86 [==============================] - 15s 173ms/step - loss: 0.5497 - tp: 283.0000 - fp: 6911.0000 - tn: 14713.0000 - fn: 109.0000 - accuracy: 0.6811 - precision: 0.0393 - recall: 0.7219 - auc: 0.7875 - val_loss: 0.2133 - val_tp: 39.0000 - val_fp: 391.0000 - val_tn: 10422.0000 - val_fn: 156.0000 - val_accuracy: 0.9503 - val_precision: 0.0907 - val_recall: 0.2000 - val_auc: 0.7828\n",
            "Epoch 21/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5702 - tp: 275.0000 - fp: 6152.0000 - tn: 15471.0000 - fn: 118.0000 - accuracy: 0.7152 - precision: 0.0428 - recall: 0.6997 - auc: 0.7877 - val_loss: 0.1413 - val_tp: 12.0000 - val_fp: 103.0000 - val_tn: 10710.0000 - val_fn: 183.0000 - val_accuracy: 0.9740 - val_precision: 0.1043 - val_recall: 0.0615 - val_auc: 0.7845\n",
            "Epoch 22/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.5815 - tp: 266.0000 - fp: 6667.0000 - tn: 14955.0000 - fn: 128.0000 - accuracy: 0.6914 - precision: 0.0384 - recall: 0.6751 - auc: 0.7657 - val_loss: 0.3377 - val_tp: 56.0000 - val_fp: 633.0000 - val_tn: 10180.0000 - val_fn: 139.0000 - val_accuracy: 0.9299 - val_precision: 0.0813 - val_recall: 0.2872 - val_auc: 0.7802\n",
            "Epoch 23/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5680 - tp: 287.0000 - fp: 6717.0000 - tn: 14908.0000 - fn: 104.0000 - accuracy: 0.6902 - precision: 0.0410 - recall: 0.7340 - auc: 0.7806 - val_loss: 0.2073 - val_tp: 25.0000 - val_fp: 200.0000 - val_tn: 10613.0000 - val_fn: 170.0000 - val_accuracy: 0.9664 - val_precision: 0.1111 - val_recall: 0.1282 - val_auc: 0.7899\n",
            "Epoch 24/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5752 - tp: 262.0000 - fp: 6642.0000 - tn: 14982.0000 - fn: 130.0000 - accuracy: 0.6924 - precision: 0.0379 - recall: 0.6684 - auc: 0.7652 - val_loss: 0.1530 - val_tp: 20.0000 - val_fp: 161.0000 - val_tn: 10652.0000 - val_fn: 175.0000 - val_accuracy: 0.9695 - val_precision: 0.1105 - val_recall: 0.1026 - val_auc: 0.7898\n",
            "Epoch 25/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5920 - tp: 267.0000 - fp: 6351.0000 - tn: 15270.0000 - fn: 128.0000 - accuracy: 0.7057 - precision: 0.0403 - recall: 0.6759 - auc: 0.7772 - val_loss: 0.3910 - val_tp: 87.0000 - val_fp: 1455.0000 - val_tn: 9358.0000 - val_fn: 108.0000 - val_accuracy: 0.8580 - val_precision: 0.0564 - val_recall: 0.4462 - val_auc: 0.7869\n",
            "Epoch 26/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5478 - tp: 279.0000 - fp: 6558.0000 - tn: 15068.0000 - fn: 111.0000 - accuracy: 0.6971 - precision: 0.0408 - recall: 0.7154 - auc: 0.7905 - val_loss: 0.2931 - val_tp: 65.0000 - val_fp: 764.0000 - val_tn: 10049.0000 - val_fn: 130.0000 - val_accuracy: 0.9188 - val_precision: 0.0784 - val_recall: 0.3333 - val_auc: 0.7968\n",
            "Epoch 27/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5440 - tp: 287.0000 - fp: 6534.0000 - tn: 15090.0000 - fn: 105.0000 - accuracy: 0.6984 - precision: 0.0421 - recall: 0.7321 - auc: 0.7950 - val_loss: 0.2910 - val_tp: 75.0000 - val_fp: 971.0000 - val_tn: 9842.0000 - val_fn: 120.0000 - val_accuracy: 0.9009 - val_precision: 0.0717 - val_recall: 0.3846 - val_auc: 0.7957\n",
            "Epoch 28/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5361 - tp: 294.0000 - fp: 6350.0000 - tn: 15273.0000 - fn: 99.0000 - accuracy: 0.7071 - precision: 0.0443 - recall: 0.7481 - auc: 0.8019 - val_loss: 0.1457 - val_tp: 18.0000 - val_fp: 128.0000 - val_tn: 10685.0000 - val_fn: 177.0000 - val_accuracy: 0.9723 - val_precision: 0.1233 - val_recall: 0.0923 - val_auc: 0.7863\n",
            "Epoch 29/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5269 - tp: 293.0000 - fp: 5985.0000 - tn: 15641.0000 - fn: 97.0000 - accuracy: 0.7237 - precision: 0.0467 - recall: 0.7513 - auc: 0.8082 - val_loss: 0.1984 - val_tp: 33.0000 - val_fp: 332.0000 - val_tn: 10481.0000 - val_fn: 162.0000 - val_accuracy: 0.9551 - val_precision: 0.0904 - val_recall: 0.1692 - val_auc: 0.7929\n",
            "Epoch 30/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5156 - tp: 303.0000 - fp: 6234.0000 - tn: 15391.0000 - fn: 88.0000 - accuracy: 0.7128 - precision: 0.0464 - recall: 0.7749 - auc: 0.8262 - val_loss: 0.1921 - val_tp: 32.0000 - val_fp: 308.0000 - val_tn: 10505.0000 - val_fn: 163.0000 - val_accuracy: 0.9572 - val_precision: 0.0941 - val_recall: 0.1641 - val_auc: 0.7898\n",
            "Epoch 31/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5271 - tp: 292.0000 - fp: 5885.0000 - tn: 15740.0000 - fn: 99.0000 - accuracy: 0.7282 - precision: 0.0473 - recall: 0.7468 - auc: 0.8131 - val_loss: 0.2422 - val_tp: 51.0000 - val_fp: 526.0000 - val_tn: 10287.0000 - val_fn: 144.0000 - val_accuracy: 0.9391 - val_precision: 0.0884 - val_recall: 0.2615 - val_auc: 0.7999\n",
            "Epoch 32/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.4876 - tp: 313.0000 - fp: 6011.0000 - tn: 15610.0000 - fn: 82.0000 - accuracy: 0.7232 - precision: 0.0495 - recall: 0.7924 - auc: 0.8425 - val_loss: 0.2266 - val_tp: 44.0000 - val_fp: 478.0000 - val_tn: 10335.0000 - val_fn: 151.0000 - val_accuracy: 0.9429 - val_precision: 0.0843 - val_recall: 0.2256 - val_auc: 0.7987\n",
            "Epoch 33/100\n",
            "86/86 [==============================] - 15s 176ms/step - loss: 0.4951 - tp: 302.0000 - fp: 5841.0000 - tn: 15782.0000 - fn: 91.0000 - accuracy: 0.7306 - precision: 0.0492 - recall: 0.7684 - auc: 0.8354 - val_loss: 0.2305 - val_tp: 48.0000 - val_fp: 531.0000 - val_tn: 10282.0000 - val_fn: 147.0000 - val_accuracy: 0.9384 - val_precision: 0.0829 - val_recall: 0.2462 - val_auc: 0.7965\n",
            "Epoch 34/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5039 - tp: 304.0000 - fp: 5938.0000 - tn: 15689.0000 - fn: 85.0000 - accuracy: 0.7264 - precision: 0.0487 - recall: 0.7815 - auc: 0.8277 - val_loss: 0.2287 - val_tp: 46.0000 - val_fp: 492.0000 - val_tn: 10321.0000 - val_fn: 149.0000 - val_accuracy: 0.9418 - val_precision: 0.0855 - val_recall: 0.2359 - val_auc: 0.7949\n",
            "Epoch 35/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.4891 - tp: 302.0000 - fp: 5707.0000 - tn: 15919.0000 - fn: 88.0000 - accuracy: 0.7368 - precision: 0.0503 - recall: 0.7744 - auc: 0.8376 - val_loss: 0.2119 - val_tp: 47.0000 - val_fp: 450.0000 - val_tn: 10363.0000 - val_fn: 148.0000 - val_accuracy: 0.9457 - val_precision: 0.0946 - val_recall: 0.2410 - val_auc: 0.7801\n",
            "Epoch 36/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5107 - tp: 290.0000 - fp: 5918.0000 - tn: 15708.0000 - fn: 100.0000 - accuracy: 0.7267 - precision: 0.0467 - recall: 0.7436 - auc: 0.8251 - val_loss: 0.1878 - val_tp: 36.0000 - val_fp: 400.0000 - val_tn: 10413.0000 - val_fn: 159.0000 - val_accuracy: 0.9492 - val_precision: 0.0826 - val_recall: 0.1846 - val_auc: 0.7709\n",
            "Epoch 37/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5188 - tp: 282.0000 - fp: 5814.0000 - tn: 15812.0000 - fn: 108.0000 - accuracy: 0.7310 - precision: 0.0463 - recall: 0.7231 - auc: 0.8184 - val_loss: 0.1741 - val_tp: 26.0000 - val_fp: 274.0000 - val_tn: 10539.0000 - val_fn: 169.0000 - val_accuracy: 0.9598 - val_precision: 0.0867 - val_recall: 0.1333 - val_auc: 0.7868\n",
            "Epoch 38/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5231 - tp: 286.0000 - fp: 6019.0000 - tn: 15604.0000 - fn: 107.0000 - accuracy: 0.7217 - precision: 0.0454 - recall: 0.7277 - auc: 0.8161 - val_loss: 0.3094 - val_tp: 81.0000 - val_fp: 1291.0000 - val_tn: 9522.0000 - val_fn: 114.0000 - val_accuracy: 0.8724 - val_precision: 0.0590 - val_recall: 0.4154 - val_auc: 0.7780\n",
            "Epoch 39/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5154 - tp: 287.0000 - fp: 5968.0000 - tn: 15659.0000 - fn: 102.0000 - accuracy: 0.7243 - precision: 0.0459 - recall: 0.7378 - auc: 0.8166 - val_loss: 0.1644 - val_tp: 27.0000 - val_fp: 295.0000 - val_tn: 10518.0000 - val_fn: 168.0000 - val_accuracy: 0.9579 - val_precision: 0.0839 - val_recall: 0.1385 - val_auc: 0.7739\n",
            "Epoch 40/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5190 - tp: 297.0000 - fp: 5745.0000 - tn: 15878.0000 - fn: 96.0000 - accuracy: 0.7347 - precision: 0.0492 - recall: 0.7557 - auc: 0.8206 - val_loss: 0.4179 - val_tp: 106.0000 - val_fp: 1840.0000 - val_tn: 8973.0000 - val_fn: 89.0000 - val_accuracy: 0.8248 - val_precision: 0.0545 - val_recall: 0.5436 - val_auc: 0.7822\n",
            "Epoch 41/100\n",
            "86/86 [==============================] - 15s 174ms/step - loss: 0.5280 - tp: 290.0000 - fp: 6290.0000 - tn: 15335.0000 - fn: 101.0000 - accuracy: 0.7097 - precision: 0.0441 - recall: 0.7417 - auc: 0.8093 - val_loss: 0.2636 - val_tp: 55.0000 - val_fp: 609.0000 - val_tn: 10204.0000 - val_fn: 140.0000 - val_accuracy: 0.9320 - val_precision: 0.0828 - val_recall: 0.2821 - val_auc: 0.7915\n",
            "Epoch 42/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5061 - tp: 293.0000 - fp: 5700.0000 - tn: 15927.0000 - fn: 96.0000 - accuracy: 0.7367 - precision: 0.0489 - recall: 0.7532 - auc: 0.8290 - val_loss: 0.1579 - val_tp: 22.0000 - val_fp: 238.0000 - val_tn: 10575.0000 - val_fn: 173.0000 - val_accuracy: 0.9627 - val_precision: 0.0846 - val_recall: 0.1128 - val_auc: 0.7852\n",
            "Epoch 43/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5202 - tp: 291.0000 - fp: 5691.0000 - tn: 15935.0000 - fn: 99.0000 - accuracy: 0.7370 - precision: 0.0486 - recall: 0.7462 - auc: 0.8243 - val_loss: 0.2413 - val_tp: 45.0000 - val_fp: 414.0000 - val_tn: 10399.0000 - val_fn: 150.0000 - val_accuracy: 0.9488 - val_precision: 0.0980 - val_recall: 0.2308 - val_auc: 0.7933\n",
            "Epoch 44/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.4851 - tp: 293.0000 - fp: 5663.0000 - tn: 15963.0000 - fn: 97.0000 - accuracy: 0.7384 - precision: 0.0492 - recall: 0.7513 - auc: 0.8419 - val_loss: 0.2741 - val_tp: 65.0000 - val_fp: 710.0000 - val_tn: 10103.0000 - val_fn: 130.0000 - val_accuracy: 0.9237 - val_precision: 0.0839 - val_recall: 0.3333 - val_auc: 0.7842\n",
            "Epoch 45/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4748 - tp: 305.0000 - fp: 5318.0000 - tn: 16308.0000 - fn: 85.0000 - accuracy: 0.7546 - precision: 0.0542 - recall: 0.7821 - auc: 0.8529 - val_loss: 0.2428 - val_tp: 53.0000 - val_fp: 697.0000 - val_tn: 10116.0000 - val_fn: 142.0000 - val_accuracy: 0.9238 - val_precision: 0.0707 - val_recall: 0.2718 - val_auc: 0.7785\n",
            "Epoch 46/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4570 - tp: 311.0000 - fp: 5360.0000 - tn: 16264.0000 - fn: 81.0000 - accuracy: 0.7529 - precision: 0.0548 - recall: 0.7934 - auc: 0.8621 - val_loss: 0.2686 - val_tp: 65.0000 - val_fp: 931.0000 - val_tn: 9882.0000 - val_fn: 130.0000 - val_accuracy: 0.9036 - val_precision: 0.0653 - val_recall: 0.3333 - val_auc: 0.7771\n",
            "Epoch 47/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.4496 - tp: 317.0000 - fp: 5151.0000 - tn: 16475.0000 - fn: 73.0000 - accuracy: 0.7627 - precision: 0.0580 - recall: 0.8128 - auc: 0.8681 - val_loss: 0.2599 - val_tp: 61.0000 - val_fp: 811.0000 - val_tn: 10002.0000 - val_fn: 134.0000 - val_accuracy: 0.9142 - val_precision: 0.0700 - val_recall: 0.3128 - val_auc: 0.7788\n",
            "Epoch 48/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.4270 - tp: 326.0000 - fp: 5384.0000 - tn: 16241.0000 - fn: 65.0000 - accuracy: 0.7525 - precision: 0.0571 - recall: 0.8338 - auc: 0.8815 - val_loss: 0.2666 - val_tp: 64.0000 - val_fp: 919.0000 - val_tn: 9894.0000 - val_fn: 131.0000 - val_accuracy: 0.9046 - val_precision: 0.0651 - val_recall: 0.3282 - val_auc: 0.7784\n",
            "Epoch 49/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.4240 - tp: 325.0000 - fp: 5001.0000 - tn: 16624.0000 - fn: 66.0000 - accuracy: 0.7698 - precision: 0.0610 - recall: 0.8312 - auc: 0.8837 - val_loss: 0.2955 - val_tp: 76.0000 - val_fp: 1123.0000 - val_tn: 9690.0000 - val_fn: 119.0000 - val_accuracy: 0.8872 - val_precision: 0.0634 - val_recall: 0.3897 - val_auc: 0.7815\n",
            "Epoch 50/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.4388 - tp: 316.0000 - fp: 4974.0000 - tn: 16653.0000 - fn: 73.0000 - accuracy: 0.7708 - precision: 0.0597 - recall: 0.8123 - auc: 0.8743 - val_loss: 0.3086 - val_tp: 75.0000 - val_fp: 1247.0000 - val_tn: 9566.0000 - val_fn: 120.0000 - val_accuracy: 0.8758 - val_precision: 0.0567 - val_recall: 0.3846 - val_auc: 0.7758\n",
            "Epoch 51/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.4265 - tp: 326.0000 - fp: 4803.0000 - tn: 16821.0000 - fn: 66.0000 - accuracy: 0.7788 - precision: 0.0636 - recall: 0.8316 - auc: 0.8823 - val_loss: 0.4012 - val_tp: 106.0000 - val_fp: 1914.0000 - val_tn: 8899.0000 - val_fn: 89.0000 - val_accuracy: 0.8180 - val_precision: 0.0525 - val_recall: 0.5436 - val_auc: 0.7825\n",
            "Epoch 52/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.4401 - tp: 310.0000 - fp: 4935.0000 - tn: 16691.0000 - fn: 80.0000 - accuracy: 0.7722 - precision: 0.0591 - recall: 0.7949 - auc: 0.8739 - val_loss: 0.1838 - val_tp: 36.0000 - val_fp: 409.0000 - val_tn: 10404.0000 - val_fn: 159.0000 - val_accuracy: 0.9484 - val_precision: 0.0809 - val_recall: 0.1846 - val_auc: 0.7706\n",
            "Epoch 53/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.4354 - tp: 308.0000 - fp: 4654.0000 - tn: 16966.0000 - fn: 88.0000 - accuracy: 0.7846 - precision: 0.0621 - recall: 0.7778 - auc: 0.8789 - val_loss: 0.2084 - val_tp: 44.0000 - val_fp: 526.0000 - val_tn: 10287.0000 - val_fn: 151.0000 - val_accuracy: 0.9385 - val_precision: 0.0772 - val_recall: 0.2256 - val_auc: 0.7744\n",
            "Epoch 54/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.4431 - tp: 308.0000 - fp: 4816.0000 - tn: 16813.0000 - fn: 79.0000 - accuracy: 0.7777 - precision: 0.0601 - recall: 0.7959 - auc: 0.8733 - val_loss: 0.3026 - val_tp: 88.0000 - val_fp: 1257.0000 - val_tn: 9556.0000 - val_fn: 107.0000 - val_accuracy: 0.8761 - val_precision: 0.0654 - val_recall: 0.4513 - val_auc: 0.7914\n",
            "Epoch 55/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.4652 - tp: 298.0000 - fp: 5237.0000 - tn: 16390.0000 - fn: 91.0000 - accuracy: 0.7580 - precision: 0.0538 - recall: 0.7661 - auc: 0.8563 - val_loss: 0.1451 - val_tp: 28.0000 - val_fp: 296.0000 - val_tn: 10517.0000 - val_fn: 167.0000 - val_accuracy: 0.9579 - val_precision: 0.0864 - val_recall: 0.1436 - val_auc: 0.7611\n",
            "Epoch 56/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.4711 - tp: 295.0000 - fp: 5384.0000 - tn: 16242.0000 - fn: 95.0000 - accuracy: 0.7511 - precision: 0.0519 - recall: 0.7564 - auc: 0.8539 - val_loss: 0.1897 - val_tp: 45.0000 - val_fp: 434.0000 - val_tn: 10379.0000 - val_fn: 150.0000 - val_accuracy: 0.9469 - val_precision: 0.0939 - val_recall: 0.2308 - val_auc: 0.7760\n",
            "Epoch 57/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.4571 - tp: 301.0000 - fp: 5391.0000 - tn: 16236.0000 - fn: 88.0000 - accuracy: 0.7511 - precision: 0.0529 - recall: 0.7738 - auc: 0.8595 - val_loss: 0.2604 - val_tp: 64.0000 - val_fp: 766.0000 - val_tn: 10047.0000 - val_fn: 131.0000 - val_accuracy: 0.9185 - val_precision: 0.0771 - val_recall: 0.3282 - val_auc: 0.7736\n",
            "Epoch 58/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.4759 - tp: 304.0000 - fp: 4823.0000 - tn: 16801.0000 - fn: 88.0000 - accuracy: 0.7769 - precision: 0.0593 - recall: 0.7755 - auc: 0.8552 - val_loss: 0.4765 - val_tp: 82.0000 - val_fp: 1617.0000 - val_tn: 9196.0000 - val_fn: 113.0000 - val_accuracy: 0.8428 - val_precision: 0.0483 - val_recall: 0.4205 - val_auc: 0.6935\n",
            "Epoch 59/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4508 - tp: 317.0000 - fp: 5165.0000 - tn: 16463.0000 - fn: 71.0000 - accuracy: 0.7622 - precision: 0.0578 - recall: 0.8170 - auc: 0.8679 - val_loss: 0.1613 - val_tp: 31.0000 - val_fp: 253.0000 - val_tn: 10560.0000 - val_fn: 164.0000 - val_accuracy: 0.9621 - val_precision: 0.1092 - val_recall: 0.1590 - val_auc: 0.7736\n",
            "Epoch 60/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.4240 - tp: 316.0000 - fp: 4750.0000 - tn: 16870.0000 - fn: 80.0000 - accuracy: 0.7806 - precision: 0.0624 - recall: 0.7980 - auc: 0.8838 - val_loss: 0.1606 - val_tp: 28.0000 - val_fp: 311.0000 - val_tn: 10502.0000 - val_fn: 167.0000 - val_accuracy: 0.9566 - val_precision: 0.0826 - val_recall: 0.1436 - val_auc: 0.7734\n",
            "Epoch 61/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.3902 - tp: 324.0000 - fp: 4435.0000 - tn: 17190.0000 - fn: 67.0000 - accuracy: 0.7955 - precision: 0.0681 - recall: 0.8286 - auc: 0.9020 - val_loss: 0.2021 - val_tp: 43.0000 - val_fp: 497.0000 - val_tn: 10316.0000 - val_fn: 152.0000 - val_accuracy: 0.9410 - val_precision: 0.0796 - val_recall: 0.2205 - val_auc: 0.7737\n",
            "Epoch 62/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.3743 - tp: 332.0000 - fp: 4100.0000 - tn: 17525.0000 - fn: 59.0000 - accuracy: 0.8111 - precision: 0.0749 - recall: 0.8491 - auc: 0.9112 - val_loss: 0.2642 - val_tp: 57.0000 - val_fp: 858.0000 - val_tn: 9955.0000 - val_fn: 138.0000 - val_accuracy: 0.9095 - val_precision: 0.0623 - val_recall: 0.2923 - val_auc: 0.7641\n",
            "Epoch 63/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.3458 - tp: 337.0000 - fp: 3837.0000 - tn: 17789.0000 - fn: 53.0000 - accuracy: 0.8233 - precision: 0.0807 - recall: 0.8641 - auc: 0.9256 - val_loss: 0.1660 - val_tp: 30.0000 - val_fp: 346.0000 - val_tn: 10467.0000 - val_fn: 165.0000 - val_accuracy: 0.9536 - val_precision: 0.0798 - val_recall: 0.1538 - val_auc: 0.7650\n",
            "Epoch 64/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.3462 - tp: 345.0000 - fp: 3751.0000 - tn: 17869.0000 - fn: 51.0000 - accuracy: 0.8273 - precision: 0.0842 - recall: 0.8712 - auc: 0.9262 - val_loss: 0.1547 - val_tp: 27.0000 - val_fp: 305.0000 - val_tn: 10508.0000 - val_fn: 168.0000 - val_accuracy: 0.9570 - val_precision: 0.0813 - val_recall: 0.1385 - val_auc: 0.7683\n",
            "Epoch 65/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.3371 - tp: 343.0000 - fp: 3746.0000 - tn: 17877.0000 - fn: 50.0000 - accuracy: 0.8276 - precision: 0.0839 - recall: 0.8728 - auc: 0.9295 - val_loss: 0.1969 - val_tp: 44.0000 - val_fp: 528.0000 - val_tn: 10285.0000 - val_fn: 151.0000 - val_accuracy: 0.9383 - val_precision: 0.0769 - val_recall: 0.2256 - val_auc: 0.7624\n",
            "Epoch 66/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.3397 - tp: 334.0000 - fp: 3503.0000 - tn: 18124.0000 - fn: 55.0000 - accuracy: 0.8384 - precision: 0.0870 - recall: 0.8586 - auc: 0.9280 - val_loss: 0.1590 - val_tp: 29.0000 - val_fp: 302.0000 - val_tn: 10511.0000 - val_fn: 166.0000 - val_accuracy: 0.9575 - val_precision: 0.0876 - val_recall: 0.1487 - val_auc: 0.7653\n",
            "Epoch 67/100\n",
            "86/86 [==============================] - 14s 164ms/step - loss: 0.3445 - tp: 342.0000 - fp: 4065.0000 - tn: 17558.0000 - fn: 51.0000 - accuracy: 0.8130 - precision: 0.0776 - recall: 0.8702 - auc: 0.9245 - val_loss: 0.1412 - val_tp: 19.0000 - val_fp: 283.0000 - val_tn: 10530.0000 - val_fn: 176.0000 - val_accuracy: 0.9583 - val_precision: 0.0629 - val_recall: 0.0974 - val_auc: 0.7472\n",
            "Epoch 68/100\n",
            "86/86 [==============================] - 15s 174ms/step - loss: 0.3514 - tp: 323.0000 - fp: 3930.0000 - tn: 17698.0000 - fn: 65.0000 - accuracy: 0.8185 - precision: 0.0759 - recall: 0.8325 - auc: 0.9199 - val_loss: 0.1167 - val_tp: 15.0000 - val_fp: 159.0000 - val_tn: 10654.0000 - val_fn: 180.0000 - val_accuracy: 0.9692 - val_precision: 0.0862 - val_recall: 0.0769 - val_auc: 0.7684\n",
            "Epoch 69/100\n",
            "86/86 [==============================] - 16s 180ms/step - loss: 0.3593 - tp: 326.0000 - fp: 3941.0000 - tn: 17683.0000 - fn: 66.0000 - accuracy: 0.8180 - precision: 0.0764 - recall: 0.8316 - auc: 0.9180 - val_loss: 0.0866 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 10811.0000 - val_fn: 194.0000 - val_accuracy: 0.9822 - val_precision: 0.3333 - val_recall: 0.0051 - val_auc: 0.7464\n",
            "Epoch 70/100\n",
            "86/86 [==============================] - 15s 176ms/step - loss: 0.3744 - tp: 334.0000 - fp: 3993.0000 - tn: 17629.0000 - fn: 60.0000 - accuracy: 0.8159 - precision: 0.0772 - recall: 0.8477 - auc: 0.9132 - val_loss: 0.1684 - val_tp: 28.0000 - val_fp: 429.0000 - val_tn: 10384.0000 - val_fn: 167.0000 - val_accuracy: 0.9459 - val_precision: 0.0613 - val_recall: 0.1436 - val_auc: 0.7552\n",
            "Epoch 71/100\n",
            "86/86 [==============================] - 15s 179ms/step - loss: 0.3521 - tp: 332.0000 - fp: 3960.0000 - tn: 17665.0000 - fn: 59.0000 - accuracy: 0.8175 - precision: 0.0774 - recall: 0.8491 - auc: 0.9225 - val_loss: 0.2311 - val_tp: 55.0000 - val_fp: 789.0000 - val_tn: 10024.0000 - val_fn: 140.0000 - val_accuracy: 0.9156 - val_precision: 0.0652 - val_recall: 0.2821 - val_auc: 0.7666\n",
            "Epoch 72/100\n",
            "86/86 [==============================] - 15s 176ms/step - loss: 0.3783 - tp: 326.0000 - fp: 4027.0000 - tn: 17598.0000 - fn: 65.0000 - accuracy: 0.8141 - precision: 0.0749 - recall: 0.8338 - auc: 0.9084 - val_loss: 0.1050 - val_tp: 4.0000 - val_fp: 59.0000 - val_tn: 10754.0000 - val_fn: 191.0000 - val_accuracy: 0.9773 - val_precision: 0.0635 - val_recall: 0.0205 - val_auc: 0.7250\n",
            "Epoch 73/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.3686 - tp: 332.0000 - fp: 4070.0000 - tn: 17554.0000 - fn: 60.0000 - accuracy: 0.8124 - precision: 0.0754 - recall: 0.8469 - auc: 0.9141 - val_loss: 0.1431 - val_tp: 28.0000 - val_fp: 304.0000 - val_tn: 10509.0000 - val_fn: 167.0000 - val_accuracy: 0.9572 - val_precision: 0.0843 - val_recall: 0.1436 - val_auc: 0.7653\n",
            "Epoch 74/100\n",
            "86/86 [==============================] - 14s 169ms/step - loss: 0.3459 - tp: 333.0000 - fp: 3803.0000 - tn: 17822.0000 - fn: 58.0000 - accuracy: 0.8246 - precision: 0.0805 - recall: 0.8517 - auc: 0.9241 - val_loss: 0.2558 - val_tp: 61.0000 - val_fp: 1067.0000 - val_tn: 9746.0000 - val_fn: 134.0000 - val_accuracy: 0.8909 - val_precision: 0.0541 - val_recall: 0.3128 - val_auc: 0.7495\n",
            "Epoch 1/100\n",
            " 2/86 [..............................] - ETA: 6s - loss: 1.6538 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 505.0000 - fn: 7.0000 - accuracy: 0.9863 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4508WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0102s vs `on_train_batch_end` time: 0.1240s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0102s vs `on_train_batch_end` time: 0.1240s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "86/86 [==============================] - ETA: 0s - loss: 1.9094 - tp: 0.0000e+00 - fp: 2.0000 - tn: 21627.0000 - fn: 387.0000 - accuracy: 0.9823 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5706WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0049s vs `on_test_batch_end` time: 0.0599s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0049s vs `on_test_batch_end` time: 0.0599s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r86/86 [==============================] - 25s 291ms/step - loss: 1.9094 - tp: 0.0000e+00 - fp: 2.0000 - tn: 21627.0000 - fn: 387.0000 - accuracy: 0.9823 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5706 - val_loss: 0.0863 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 10812.0000 - val_fn: 196.0000 - val_accuracy: 0.9822 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6638\n",
            "Epoch 2/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 1.4960 - tp: 35.0000 - fp: 499.0000 - tn: 21128.0000 - fn: 354.0000 - accuracy: 0.9613 - precision: 0.0655 - recall: 0.0900 - auc: 0.6651 - val_loss: 0.0946 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 10812.0000 - val_fn: 196.0000 - val_accuracy: 0.9822 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6642\n",
            "Epoch 3/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 1.0105 - tp: 135.0000 - fp: 3216.0000 - tn: 18409.0000 - fn: 256.0000 - accuracy: 0.8423 - precision: 0.0403 - recall: 0.3453 - auc: 0.6932 - val_loss: 0.1027 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 10812.0000 - val_fn: 196.0000 - val_accuracy: 0.9822 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6507\n",
            "Epoch 4/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.7589 - tp: 193.0000 - fp: 5272.0000 - tn: 16358.0000 - fn: 193.0000 - accuracy: 0.7518 - precision: 0.0353 - recall: 0.5000 - auc: 0.7095 - val_loss: 0.1030 - val_tp: 0.0000e+00 - val_fp: 4.0000 - val_tn: 10808.0000 - val_fn: 196.0000 - val_accuracy: 0.9818 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6587\n",
            "Epoch 5/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.6782 - tp: 230.0000 - fp: 6557.0000 - tn: 15067.0000 - fn: 162.0000 - accuracy: 0.6948 - precision: 0.0339 - recall: 0.5867 - auc: 0.7220 - val_loss: 0.1002 - val_tp: 5.0000 - val_fp: 33.0000 - val_tn: 10779.0000 - val_fn: 191.0000 - val_accuracy: 0.9797 - val_precision: 0.1316 - val_recall: 0.0255 - val_auc: 0.7102\n",
            "Epoch 6/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.6836 - tp: 225.0000 - fp: 6036.0000 - tn: 15592.0000 - fn: 163.0000 - accuracy: 0.7184 - precision: 0.0359 - recall: 0.5799 - auc: 0.7241 - val_loss: 0.1384 - val_tp: 18.0000 - val_fp: 164.0000 - val_tn: 10648.0000 - val_fn: 178.0000 - val_accuracy: 0.9689 - val_precision: 0.0989 - val_recall: 0.0918 - val_auc: 0.7873\n",
            "Epoch 7/100\n",
            "86/86 [==============================] - 15s 175ms/step - loss: 0.7052 - tp: 224.0000 - fp: 5962.0000 - tn: 15665.0000 - fn: 165.0000 - accuracy: 0.7217 - precision: 0.0362 - recall: 0.5758 - auc: 0.7261 - val_loss: 0.1640 - val_tp: 30.0000 - val_fp: 439.0000 - val_tn: 10373.0000 - val_fn: 166.0000 - val_accuracy: 0.9450 - val_precision: 0.0640 - val_recall: 0.1531 - val_auc: 0.7135\n",
            "Epoch 8/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.6204 - tp: 245.0000 - fp: 5917.0000 - tn: 15711.0000 - fn: 143.0000 - accuracy: 0.7247 - precision: 0.0398 - recall: 0.6314 - auc: 0.7530 - val_loss: 0.5350 - val_tp: 106.0000 - val_fp: 2341.0000 - val_tn: 8471.0000 - val_fn: 90.0000 - val_accuracy: 0.7792 - val_precision: 0.0433 - val_recall: 0.5408 - val_auc: 0.7423\n",
            "Epoch 9/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.6270 - tp: 255.0000 - fp: 6256.0000 - tn: 15369.0000 - fn: 136.0000 - accuracy: 0.7097 - precision: 0.0392 - recall: 0.6522 - auc: 0.7538 - val_loss: 0.6555 - val_tp: 161.0000 - val_fp: 4302.0000 - val_tn: 6510.0000 - val_fn: 35.0000 - val_accuracy: 0.6060 - val_precision: 0.0361 - val_recall: 0.8214 - val_auc: 0.7842\n",
            "Epoch 10/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5790 - tp: 278.0000 - fp: 6884.0000 - tn: 14743.0000 - fn: 111.0000 - accuracy: 0.6823 - precision: 0.0388 - recall: 0.7147 - auc: 0.7656 - val_loss: 0.2546 - val_tp: 77.0000 - val_fp: 1192.0000 - val_tn: 9620.0000 - val_fn: 119.0000 - val_accuracy: 0.8809 - val_precision: 0.0607 - val_recall: 0.3929 - val_auc: 0.7687\n",
            "Epoch 11/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5829 - tp: 270.0000 - fp: 7051.0000 - tn: 14574.0000 - fn: 121.0000 - accuracy: 0.6742 - precision: 0.0369 - recall: 0.6905 - auc: 0.7628 - val_loss: 0.2625 - val_tp: 50.0000 - val_fp: 627.0000 - val_tn: 10185.0000 - val_fn: 146.0000 - val_accuracy: 0.9298 - val_precision: 0.0739 - val_recall: 0.2551 - val_auc: 0.7876\n",
            "Epoch 12/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.5727 - tp: 259.0000 - fp: 6716.0000 - tn: 14911.0000 - fn: 130.0000 - accuracy: 0.6890 - precision: 0.0371 - recall: 0.6658 - auc: 0.7634 - val_loss: 0.1803 - val_tp: 42.0000 - val_fp: 453.0000 - val_tn: 10359.0000 - val_fn: 154.0000 - val_accuracy: 0.9449 - val_precision: 0.0848 - val_recall: 0.2143 - val_auc: 0.7765\n",
            "Epoch 13/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5605 - tp: 278.0000 - fp: 6659.0000 - tn: 14965.0000 - fn: 114.0000 - accuracy: 0.6924 - precision: 0.0401 - recall: 0.7092 - auc: 0.7757 - val_loss: 0.2673 - val_tp: 74.0000 - val_fp: 1130.0000 - val_tn: 9682.0000 - val_fn: 122.0000 - val_accuracy: 0.8863 - val_precision: 0.0615 - val_recall: 0.3776 - val_auc: 0.7858\n",
            "Epoch 14/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5605 - tp: 277.0000 - fp: 6685.0000 - tn: 14941.0000 - fn: 113.0000 - accuracy: 0.6912 - precision: 0.0398 - recall: 0.7103 - auc: 0.7839 - val_loss: 0.1444 - val_tp: 22.0000 - val_fp: 228.0000 - val_tn: 10584.0000 - val_fn: 174.0000 - val_accuracy: 0.9635 - val_precision: 0.0880 - val_recall: 0.1122 - val_auc: 0.7460\n",
            "Epoch 15/100\n",
            "86/86 [==============================] - 14s 169ms/step - loss: 0.5366 - tp: 291.0000 - fp: 6557.0000 - tn: 15070.0000 - fn: 98.0000 - accuracy: 0.6977 - precision: 0.0425 - recall: 0.7481 - auc: 0.8017 - val_loss: 0.1299 - val_tp: 18.0000 - val_fp: 152.0000 - val_tn: 10660.0000 - val_fn: 178.0000 - val_accuracy: 0.9700 - val_precision: 0.1059 - val_recall: 0.0918 - val_auc: 0.7713\n",
            "Epoch 16/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5357 - tp: 284.0000 - fp: 6496.0000 - tn: 15129.0000 - fn: 107.0000 - accuracy: 0.7001 - precision: 0.0419 - recall: 0.7263 - auc: 0.7947 - val_loss: 0.1457 - val_tp: 28.0000 - val_fp: 284.0000 - val_tn: 10528.0000 - val_fn: 168.0000 - val_accuracy: 0.9589 - val_precision: 0.0897 - val_recall: 0.1429 - val_auc: 0.7739\n",
            "Epoch 17/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5377 - tp: 292.0000 - fp: 6704.0000 - tn: 14923.0000 - fn: 97.0000 - accuracy: 0.6911 - precision: 0.0417 - recall: 0.7506 - auc: 0.7949 - val_loss: 0.1537 - val_tp: 31.0000 - val_fp: 330.0000 - val_tn: 10482.0000 - val_fn: 165.0000 - val_accuracy: 0.9550 - val_precision: 0.0859 - val_recall: 0.1582 - val_auc: 0.7694\n",
            "Epoch 18/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5864 - tp: 289.0000 - fp: 6744.0000 - tn: 14883.0000 - fn: 100.0000 - accuracy: 0.6891 - precision: 0.0411 - recall: 0.7429 - auc: 0.7943 - val_loss: 0.4056 - val_tp: 107.0000 - val_fp: 1799.0000 - val_tn: 9013.0000 - val_fn: 89.0000 - val_accuracy: 0.8285 - val_precision: 0.0561 - val_recall: 0.5459 - val_auc: 0.7898\n",
            "Epoch 19/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5497 - tp: 274.0000 - fp: 6238.0000 - tn: 15389.0000 - fn: 115.0000 - accuracy: 0.7114 - precision: 0.0421 - recall: 0.7044 - auc: 0.7890 - val_loss: 0.2037 - val_tp: 52.0000 - val_fp: 561.0000 - val_tn: 10251.0000 - val_fn: 144.0000 - val_accuracy: 0.9360 - val_precision: 0.0848 - val_recall: 0.2653 - val_auc: 0.7931\n",
            "Epoch 20/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5351 - tp: 285.0000 - fp: 6514.0000 - tn: 15114.0000 - fn: 103.0000 - accuracy: 0.6994 - precision: 0.0419 - recall: 0.7345 - auc: 0.7958 - val_loss: 0.2876 - val_tp: 81.0000 - val_fp: 1421.0000 - val_tn: 9391.0000 - val_fn: 115.0000 - val_accuracy: 0.8605 - val_precision: 0.0539 - val_recall: 0.4133 - val_auc: 0.7881\n",
            "Epoch 21/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.5600 - tp: 280.0000 - fp: 7006.0000 - tn: 14620.0000 - fn: 110.0000 - accuracy: 0.6768 - precision: 0.0384 - recall: 0.7179 - auc: 0.7744 - val_loss: 0.2580 - val_tp: 74.0000 - val_fp: 1366.0000 - val_tn: 9446.0000 - val_fn: 122.0000 - val_accuracy: 0.8648 - val_precision: 0.0514 - val_recall: 0.3776 - val_auc: 0.7705\n",
            "Epoch 22/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5606 - tp: 287.0000 - fp: 6910.0000 - tn: 14714.0000 - fn: 105.0000 - accuracy: 0.6814 - precision: 0.0399 - recall: 0.7321 - auc: 0.7771 - val_loss: 0.3351 - val_tp: 97.0000 - val_fp: 1420.0000 - val_tn: 9392.0000 - val_fn: 99.0000 - val_accuracy: 0.8620 - val_precision: 0.0639 - val_recall: 0.4949 - val_auc: 0.7972\n",
            "Epoch 23/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5432 - tp: 283.0000 - fp: 6415.0000 - tn: 15208.0000 - fn: 110.0000 - accuracy: 0.7036 - precision: 0.0423 - recall: 0.7201 - auc: 0.7929 - val_loss: 0.1382 - val_tp: 19.0000 - val_fp: 191.0000 - val_tn: 10621.0000 - val_fn: 177.0000 - val_accuracy: 0.9666 - val_precision: 0.0905 - val_recall: 0.0969 - val_auc: 0.7841\n",
            "Epoch 24/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5888 - tp: 255.0000 - fp: 6441.0000 - tn: 15185.0000 - fn: 135.0000 - accuracy: 0.7013 - precision: 0.0381 - recall: 0.6538 - auc: 0.7621 - val_loss: 0.2770 - val_tp: 72.0000 - val_fp: 929.0000 - val_tn: 9883.0000 - val_fn: 124.0000 - val_accuracy: 0.9043 - val_precision: 0.0719 - val_recall: 0.3673 - val_auc: 0.7838\n",
            "Epoch 25/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.5462 - tp: 283.0000 - fp: 6754.0000 - tn: 14871.0000 - fn: 108.0000 - accuracy: 0.6883 - precision: 0.0402 - recall: 0.7238 - auc: 0.7895 - val_loss: 0.1363 - val_tp: 15.0000 - val_fp: 98.0000 - val_tn: 10714.0000 - val_fn: 181.0000 - val_accuracy: 0.9747 - val_precision: 0.1327 - val_recall: 0.0765 - val_auc: 0.7739\n",
            "Epoch 26/100\n",
            "86/86 [==============================] - 15s 173ms/step - loss: 0.5321 - tp: 293.0000 - fp: 6460.0000 - tn: 15166.0000 - fn: 97.0000 - accuracy: 0.7022 - precision: 0.0434 - recall: 0.7513 - auc: 0.8011 - val_loss: 0.1467 - val_tp: 20.0000 - val_fp: 144.0000 - val_tn: 10668.0000 - val_fn: 176.0000 - val_accuracy: 0.9709 - val_precision: 0.1220 - val_recall: 0.1020 - val_auc: 0.7880\n",
            "Epoch 27/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5290 - tp: 294.0000 - fp: 6485.0000 - tn: 15142.0000 - fn: 95.0000 - accuracy: 0.7011 - precision: 0.0434 - recall: 0.7558 - auc: 0.8031 - val_loss: 0.1339 - val_tp: 14.0000 - val_fp: 69.0000 - val_tn: 10743.0000 - val_fn: 182.0000 - val_accuracy: 0.9772 - val_precision: 0.1687 - val_recall: 0.0714 - val_auc: 0.7788\n",
            "Epoch 28/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.6235 - tp: 258.0000 - fp: 5636.0000 - tn: 15991.0000 - fn: 131.0000 - accuracy: 0.7381 - precision: 0.0438 - recall: 0.6632 - auc: 0.7761 - val_loss: 0.4695 - val_tp: 114.0000 - val_fp: 2216.0000 - val_tn: 8596.0000 - val_fn: 82.0000 - val_accuracy: 0.7912 - val_precision: 0.0489 - val_recall: 0.5816 - val_auc: 0.7709\n",
            "Epoch 29/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.6002 - tp: 262.0000 - fp: 5477.0000 - tn: 16146.0000 - fn: 131.0000 - accuracy: 0.7453 - precision: 0.0457 - recall: 0.6667 - auc: 0.7880 - val_loss: 0.2386 - val_tp: 46.0000 - val_fp: 559.0000 - val_tn: 10253.0000 - val_fn: 150.0000 - val_accuracy: 0.9356 - val_precision: 0.0760 - val_recall: 0.2347 - val_auc: 0.7798\n",
            "Epoch 30/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5387 - tp: 292.0000 - fp: 5933.0000 - tn: 15693.0000 - fn: 98.0000 - accuracy: 0.7261 - precision: 0.0469 - recall: 0.7487 - auc: 0.8099 - val_loss: 0.2054 - val_tp: 32.0000 - val_fp: 460.0000 - val_tn: 10352.0000 - val_fn: 164.0000 - val_accuracy: 0.9433 - val_precision: 0.0650 - val_recall: 0.1633 - val_auc: 0.7770\n",
            "Epoch 31/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5202 - tp: 292.0000 - fp: 6052.0000 - tn: 15573.0000 - fn: 99.0000 - accuracy: 0.7206 - precision: 0.0460 - recall: 0.7468 - auc: 0.8141 - val_loss: 0.2116 - val_tp: 38.0000 - val_fp: 488.0000 - val_tn: 10324.0000 - val_fn: 158.0000 - val_accuracy: 0.9413 - val_precision: 0.0722 - val_recall: 0.1939 - val_auc: 0.7828\n",
            "Epoch 32/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.5158 - tp: 299.0000 - fp: 6279.0000 - tn: 15347.0000 - fn: 91.0000 - accuracy: 0.7107 - precision: 0.0455 - recall: 0.7667 - auc: 0.8166 - val_loss: 0.1852 - val_tp: 28.0000 - val_fp: 351.0000 - val_tn: 10461.0000 - val_fn: 168.0000 - val_accuracy: 0.9529 - val_precision: 0.0739 - val_recall: 0.1429 - val_auc: 0.7808\n",
            "Epoch 33/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5054 - tp: 305.0000 - fp: 6163.0000 - tn: 15461.0000 - fn: 87.0000 - accuracy: 0.7161 - precision: 0.0472 - recall: 0.7781 - auc: 0.8266 - val_loss: 0.1803 - val_tp: 27.0000 - val_fp: 341.0000 - val_tn: 10471.0000 - val_fn: 169.0000 - val_accuracy: 0.9537 - val_precision: 0.0734 - val_recall: 0.1378 - val_auc: 0.7769\n",
            "Epoch 34/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5252 - tp: 291.0000 - fp: 6113.0000 - tn: 15512.0000 - fn: 100.0000 - accuracy: 0.7178 - precision: 0.0454 - recall: 0.7442 - auc: 0.8090 - val_loss: 0.1673 - val_tp: 23.0000 - val_fp: 265.0000 - val_tn: 10547.0000 - val_fn: 173.0000 - val_accuracy: 0.9602 - val_precision: 0.0799 - val_recall: 0.1173 - val_auc: 0.7783\n",
            "Epoch 35/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5107 - tp: 289.0000 - fp: 6006.0000 - tn: 15622.0000 - fn: 99.0000 - accuracy: 0.7227 - precision: 0.0459 - recall: 0.7448 - auc: 0.8204 - val_loss: 0.2248 - val_tp: 42.0000 - val_fp: 592.0000 - val_tn: 10220.0000 - val_fn: 154.0000 - val_accuracy: 0.9322 - val_precision: 0.0662 - val_recall: 0.2143 - val_auc: 0.7725\n",
            "Epoch 36/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.5183 - tp: 295.0000 - fp: 6247.0000 - tn: 15381.0000 - fn: 93.0000 - accuracy: 0.7120 - precision: 0.0451 - recall: 0.7603 - auc: 0.8163 - val_loss: 0.1279 - val_tp: 19.0000 - val_fp: 107.0000 - val_tn: 10705.0000 - val_fn: 177.0000 - val_accuracy: 0.9742 - val_precision: 0.1508 - val_recall: 0.0969 - val_auc: 0.7783\n",
            "Epoch 37/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5037 - tp: 299.0000 - fp: 6036.0000 - tn: 15591.0000 - fn: 90.0000 - accuracy: 0.7217 - precision: 0.0472 - recall: 0.7686 - auc: 0.8255 - val_loss: 0.1093 - val_tp: 8.0000 - val_fp: 50.0000 - val_tn: 10762.0000 - val_fn: 188.0000 - val_accuracy: 0.9784 - val_precision: 0.1379 - val_recall: 0.0408 - val_auc: 0.7796\n",
            "Epoch 38/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5018 - tp: 298.0000 - fp: 5856.0000 - tn: 15770.0000 - fn: 92.0000 - accuracy: 0.7298 - precision: 0.0484 - recall: 0.7641 - auc: 0.8319 - val_loss: 0.1570 - val_tp: 22.0000 - val_fp: 209.0000 - val_tn: 10603.0000 - val_fn: 174.0000 - val_accuracy: 0.9652 - val_precision: 0.0952 - val_recall: 0.1122 - val_auc: 0.7835\n",
            "Epoch 39/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5276 - tp: 289.0000 - fp: 5972.0000 - tn: 15651.0000 - fn: 104.0000 - accuracy: 0.7240 - precision: 0.0462 - recall: 0.7354 - auc: 0.8149 - val_loss: 0.1144 - val_tp: 12.0000 - val_fp: 37.0000 - val_tn: 10775.0000 - val_fn: 184.0000 - val_accuracy: 0.9799 - val_precision: 0.2449 - val_recall: 0.0612 - val_auc: 0.7727\n",
            "Epoch 40/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5118 - tp: 290.0000 - fp: 5949.0000 - tn: 15677.0000 - fn: 100.0000 - accuracy: 0.7252 - precision: 0.0465 - recall: 0.7436 - auc: 0.8221 - val_loss: 0.1411 - val_tp: 18.0000 - val_fp: 138.0000 - val_tn: 10674.0000 - val_fn: 178.0000 - val_accuracy: 0.9713 - val_precision: 0.1154 - val_recall: 0.0918 - val_auc: 0.7748\n",
            "Epoch 41/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5187 - tp: 282.0000 - fp: 6248.0000 - tn: 15380.0000 - fn: 106.0000 - accuracy: 0.7114 - precision: 0.0432 - recall: 0.7268 - auc: 0.8118 - val_loss: 0.1969 - val_tp: 33.0000 - val_fp: 255.0000 - val_tn: 10557.0000 - val_fn: 163.0000 - val_accuracy: 0.9620 - val_precision: 0.1146 - val_recall: 0.1684 - val_auc: 0.7743\n",
            "Epoch 42/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5003 - tp: 294.0000 - fp: 5998.0000 - tn: 15629.0000 - fn: 95.0000 - accuracy: 0.7232 - precision: 0.0467 - recall: 0.7558 - auc: 0.8266 - val_loss: 0.1932 - val_tp: 39.0000 - val_fp: 358.0000 - val_tn: 10454.0000 - val_fn: 157.0000 - val_accuracy: 0.9532 - val_precision: 0.0982 - val_recall: 0.1990 - val_auc: 0.7902\n",
            "Epoch 43/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.4804 - tp: 310.0000 - fp: 5398.0000 - tn: 16229.0000 - fn: 79.0000 - accuracy: 0.7512 - precision: 0.0543 - recall: 0.7969 - auc: 0.8458 - val_loss: 0.1663 - val_tp: 27.0000 - val_fp: 230.0000 - val_tn: 10582.0000 - val_fn: 169.0000 - val_accuracy: 0.9638 - val_precision: 0.1051 - val_recall: 0.1378 - val_auc: 0.7832\n",
            "Epoch 44/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.4823 - tp: 304.0000 - fp: 5721.0000 - tn: 15907.0000 - fn: 84.0000 - accuracy: 0.7363 - precision: 0.0505 - recall: 0.7835 - auc: 0.8405 - val_loss: 0.1235 - val_tp: 14.0000 - val_fp: 79.0000 - val_tn: 10733.0000 - val_fn: 182.0000 - val_accuracy: 0.9763 - val_precision: 0.1505 - val_recall: 0.0714 - val_auc: 0.7758\n",
            "Epoch 45/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4618 - tp: 301.0000 - fp: 5340.0000 - tn: 16286.0000 - fn: 89.0000 - accuracy: 0.7534 - precision: 0.0534 - recall: 0.7718 - auc: 0.8559 - val_loss: 0.1391 - val_tp: 17.0000 - val_fp: 140.0000 - val_tn: 10672.0000 - val_fn: 179.0000 - val_accuracy: 0.9710 - val_precision: 0.1083 - val_recall: 0.0867 - val_auc: 0.7680\n",
            "Epoch 46/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4366 - tp: 312.0000 - fp: 5241.0000 - tn: 16385.0000 - fn: 78.0000 - accuracy: 0.7584 - precision: 0.0562 - recall: 0.8000 - auc: 0.8730 - val_loss: 0.1671 - val_tp: 31.0000 - val_fp: 298.0000 - val_tn: 10514.0000 - val_fn: 165.0000 - val_accuracy: 0.9579 - val_precision: 0.0942 - val_recall: 0.1582 - val_auc: 0.7677\n",
            "Epoch 47/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.4326 - tp: 317.0000 - fp: 5427.0000 - tn: 16201.0000 - fn: 71.0000 - accuracy: 0.7503 - precision: 0.0552 - recall: 0.8170 - auc: 0.8737 - val_loss: 0.1147 - val_tp: 14.0000 - val_fp: 82.0000 - val_tn: 10730.0000 - val_fn: 182.0000 - val_accuracy: 0.9760 - val_precision: 0.1458 - val_recall: 0.0714 - val_auc: 0.7757\n",
            "Epoch 48/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.4321 - tp: 319.0000 - fp: 5141.0000 - tn: 16484.0000 - fn: 72.0000 - accuracy: 0.7632 - precision: 0.0584 - recall: 0.8159 - auc: 0.8762 - val_loss: 0.1424 - val_tp: 25.0000 - val_fp: 195.0000 - val_tn: 10617.0000 - val_fn: 171.0000 - val_accuracy: 0.9668 - val_precision: 0.1136 - val_recall: 0.1276 - val_auc: 0.7726\n",
            "Epoch 49/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.4398 - tp: 317.0000 - fp: 4833.0000 - tn: 16790.0000 - fn: 76.0000 - accuracy: 0.7770 - precision: 0.0616 - recall: 0.8066 - auc: 0.8731 - val_loss: 0.1371 - val_tp: 23.0000 - val_fp: 178.0000 - val_tn: 10634.0000 - val_fn: 173.0000 - val_accuracy: 0.9681 - val_precision: 0.1144 - val_recall: 0.1173 - val_auc: 0.7690\n",
            "Epoch 50/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.4199 - tp: 317.0000 - fp: 4831.0000 - tn: 16798.0000 - fn: 70.0000 - accuracy: 0.7774 - precision: 0.0616 - recall: 0.8191 - auc: 0.8834 - val_loss: 0.1558 - val_tp: 30.0000 - val_fp: 261.0000 - val_tn: 10551.0000 - val_fn: 166.0000 - val_accuracy: 0.9612 - val_precision: 0.1031 - val_recall: 0.1531 - val_auc: 0.7739\n",
            "Epoch 51/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4200 - tp: 330.0000 - fp: 4759.0000 - tn: 16863.0000 - fn: 64.0000 - accuracy: 0.7809 - precision: 0.0648 - recall: 0.8376 - auc: 0.8856 - val_loss: 0.1287 - val_tp: 18.0000 - val_fp: 142.0000 - val_tn: 10670.0000 - val_fn: 178.0000 - val_accuracy: 0.9709 - val_precision: 0.1125 - val_recall: 0.0918 - val_auc: 0.7726\n",
            "Epoch 52/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4281 - tp: 317.0000 - fp: 4860.0000 - tn: 16766.0000 - fn: 73.0000 - accuracy: 0.7759 - precision: 0.0612 - recall: 0.8128 - auc: 0.8807 - val_loss: 0.1091 - val_tp: 14.0000 - val_fp: 95.0000 - val_tn: 10717.0000 - val_fn: 182.0000 - val_accuracy: 0.9748 - val_precision: 0.1284 - val_recall: 0.0714 - val_auc: 0.7875\n",
            "Epoch 53/100\n",
            "86/86 [==============================] - 15s 178ms/step - loss: 0.4431 - tp: 306.0000 - fp: 5104.0000 - tn: 16522.0000 - fn: 84.0000 - accuracy: 0.7644 - precision: 0.0566 - recall: 0.7846 - auc: 0.8696 - val_loss: 0.0972 - val_tp: 8.0000 - val_fp: 24.0000 - val_tn: 10788.0000 - val_fn: 188.0000 - val_accuracy: 0.9807 - val_precision: 0.2500 - val_recall: 0.0408 - val_auc: 0.7735\n",
            "Epoch 54/100\n",
            "86/86 [==============================] - 15s 179ms/step - loss: 0.4638 - tp: 303.0000 - fp: 5476.0000 - tn: 16151.0000 - fn: 86.0000 - accuracy: 0.7474 - precision: 0.0524 - recall: 0.7789 - auc: 0.8555 - val_loss: 0.0887 - val_tp: 7.0000 - val_fp: 29.0000 - val_tn: 10783.0000 - val_fn: 189.0000 - val_accuracy: 0.9802 - val_precision: 0.1944 - val_recall: 0.0357 - val_auc: 0.7859\n",
            "Epoch 55/100\n",
            "86/86 [==============================] - 15s 180ms/step - loss: 0.4327 - tp: 321.0000 - fp: 5267.0000 - tn: 16356.0000 - fn: 72.0000 - accuracy: 0.7575 - precision: 0.0574 - recall: 0.8168 - auc: 0.8749 - val_loss: 0.1522 - val_tp: 24.0000 - val_fp: 234.0000 - val_tn: 10578.0000 - val_fn: 172.0000 - val_accuracy: 0.9631 - val_precision: 0.0930 - val_recall: 0.1224 - val_auc: 0.7628\n",
            "Epoch 56/100\n",
            "86/86 [==============================] - 15s 176ms/step - loss: 0.4711 - tp: 297.0000 - fp: 5413.0000 - tn: 16216.0000 - fn: 90.0000 - accuracy: 0.7500 - precision: 0.0520 - recall: 0.7674 - auc: 0.8508 - val_loss: 0.1227 - val_tp: 14.0000 - val_fp: 130.0000 - val_tn: 10682.0000 - val_fn: 182.0000 - val_accuracy: 0.9717 - val_precision: 0.0972 - val_recall: 0.0714 - val_auc: 0.7562\n",
            "Epoch 57/100\n",
            "86/86 [==============================] - 15s 176ms/step - loss: 0.4367 - tp: 312.0000 - fp: 4974.0000 - tn: 16653.0000 - fn: 77.0000 - accuracy: 0.7706 - precision: 0.0590 - recall: 0.8021 - auc: 0.8730 - val_loss: 0.1750 - val_tp: 30.0000 - val_fp: 406.0000 - val_tn: 10406.0000 - val_fn: 166.0000 - val_accuracy: 0.9480 - val_precision: 0.0688 - val_recall: 0.1531 - val_auc: 0.7522\n",
            "Epoch 58/100\n",
            "86/86 [==============================] - 15s 173ms/step - loss: 0.4227 - tp: 322.0000 - fp: 4896.0000 - tn: 16731.0000 - fn: 67.0000 - accuracy: 0.7746 - precision: 0.0617 - recall: 0.8278 - auc: 0.8830 - val_loss: 0.1269 - val_tp: 15.0000 - val_fp: 126.0000 - val_tn: 10686.0000 - val_fn: 181.0000 - val_accuracy: 0.9721 - val_precision: 0.1064 - val_recall: 0.0765 - val_auc: 0.7779\n",
            "Epoch 59/100\n",
            "86/86 [==============================] - 15s 173ms/step - loss: 0.4137 - tp: 318.0000 - fp: 4737.0000 - tn: 16892.0000 - fn: 69.0000 - accuracy: 0.7817 - precision: 0.0629 - recall: 0.8217 - auc: 0.8859 - val_loss: 0.1282 - val_tp: 21.0000 - val_fp: 189.0000 - val_tn: 10623.0000 - val_fn: 175.0000 - val_accuracy: 0.9669 - val_precision: 0.1000 - val_recall: 0.1071 - val_auc: 0.7659\n",
            "Epoch 60/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.4157 - tp: 327.0000 - fp: 4840.0000 - tn: 16786.0000 - fn: 63.0000 - accuracy: 0.7773 - precision: 0.0633 - recall: 0.8385 - auc: 0.8868 - val_loss: 0.1090 - val_tp: 10.0000 - val_fp: 84.0000 - val_tn: 10728.0000 - val_fn: 186.0000 - val_accuracy: 0.9755 - val_precision: 0.1064 - val_recall: 0.0510 - val_auc: 0.7646\n",
            "Epoch 61/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.3727 - tp: 334.0000 - fp: 4355.0000 - tn: 17273.0000 - fn: 54.0000 - accuracy: 0.7997 - precision: 0.0712 - recall: 0.8608 - auc: 0.9098 - val_loss: 0.1592 - val_tp: 24.0000 - val_fp: 304.0000 - val_tn: 10508.0000 - val_fn: 172.0000 - val_accuracy: 0.9568 - val_precision: 0.0732 - val_recall: 0.1224 - val_auc: 0.7596\n",
            "Epoch 62/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.3652 - tp: 336.0000 - fp: 4285.0000 - tn: 17341.0000 - fn: 54.0000 - accuracy: 0.8029 - precision: 0.0727 - recall: 0.8615 - auc: 0.9141 - val_loss: 0.1428 - val_tp: 23.0000 - val_fp: 258.0000 - val_tn: 10554.0000 - val_fn: 173.0000 - val_accuracy: 0.9608 - val_precision: 0.0819 - val_recall: 0.1173 - val_auc: 0.7494\n",
            "Epoch 63/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.3393 - tp: 342.0000 - fp: 3944.0000 - tn: 17680.0000 - fn: 50.0000 - accuracy: 0.8186 - precision: 0.0798 - recall: 0.8724 - auc: 0.9269 - val_loss: 0.1582 - val_tp: 29.0000 - val_fp: 325.0000 - val_tn: 10487.0000 - val_fn: 167.0000 - val_accuracy: 0.9553 - val_precision: 0.0819 - val_recall: 0.1480 - val_auc: 0.7502\n",
            "Epoch 64/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.3416 - tp: 339.0000 - fp: 3809.0000 - tn: 17815.0000 - fn: 53.0000 - accuracy: 0.8246 - precision: 0.0817 - recall: 0.8648 - auc: 0.9266 - val_loss: 0.1427 - val_tp: 25.0000 - val_fp: 267.0000 - val_tn: 10545.0000 - val_fn: 171.0000 - val_accuracy: 0.9602 - val_precision: 0.0856 - val_recall: 0.1276 - val_auc: 0.7575\n",
            "Epoch 65/100\n",
            "86/86 [==============================] - 15s 172ms/step - loss: 0.3362 - tp: 338.0000 - fp: 3736.0000 - tn: 17890.0000 - fn: 52.0000 - accuracy: 0.8279 - precision: 0.0830 - recall: 0.8667 - auc: 0.9286 - val_loss: 0.1370 - val_tp: 21.0000 - val_fp: 221.0000 - val_tn: 10591.0000 - val_fn: 175.0000 - val_accuracy: 0.9640 - val_precision: 0.0868 - val_recall: 0.1071 - val_auc: 0.7501\n",
            "Epoch 66/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.3340 - tp: 340.0000 - fp: 4103.0000 - tn: 17523.0000 - fn: 50.0000 - accuracy: 0.8114 - precision: 0.0765 - recall: 0.8718 - auc: 0.9291 - val_loss: 0.1560 - val_tp: 29.0000 - val_fp: 338.0000 - val_tn: 10474.0000 - val_fn: 167.0000 - val_accuracy: 0.9541 - val_precision: 0.0790 - val_recall: 0.1480 - val_auc: 0.7567\n",
            "Epoch 67/100\n",
            "86/86 [==============================] - 16s 181ms/step - loss: 0.3372 - tp: 335.0000 - fp: 3653.0000 - tn: 17970.0000 - fn: 58.0000 - accuracy: 0.8314 - precision: 0.0840 - recall: 0.8524 - auc: 0.9285 - val_loss: 0.1557 - val_tp: 30.0000 - val_fp: 352.0000 - val_tn: 10460.0000 - val_fn: 166.0000 - val_accuracy: 0.9529 - val_precision: 0.0785 - val_recall: 0.1531 - val_auc: 0.7524\n",
            "Epoch 68/100\n",
            "86/86 [==============================] - 15s 172ms/step - loss: 0.3438 - tp: 330.0000 - fp: 3734.0000 - tn: 17893.0000 - fn: 59.0000 - accuracy: 0.8277 - precision: 0.0812 - recall: 0.8483 - auc: 0.9247 - val_loss: 0.1325 - val_tp: 20.0000 - val_fp: 228.0000 - val_tn: 10584.0000 - val_fn: 176.0000 - val_accuracy: 0.9633 - val_precision: 0.0806 - val_recall: 0.1020 - val_auc: 0.7614\n",
            "Epoch 69/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.3594 - tp: 338.0000 - fp: 4255.0000 - tn: 17368.0000 - fn: 55.0000 - accuracy: 0.8042 - precision: 0.0736 - recall: 0.8601 - auc: 0.9152 - val_loss: 0.1258 - val_tp: 17.0000 - val_fp: 182.0000 - val_tn: 10630.0000 - val_fn: 179.0000 - val_accuracy: 0.9672 - val_precision: 0.0854 - val_recall: 0.0867 - val_auc: 0.7681\n",
            "Epoch 70/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.3395 - tp: 337.0000 - fp: 3913.0000 - tn: 17716.0000 - fn: 50.0000 - accuracy: 0.8200 - precision: 0.0793 - recall: 0.8708 - auc: 0.9262 - val_loss: 0.1032 - val_tp: 14.0000 - val_fp: 87.0000 - val_tn: 10725.0000 - val_fn: 182.0000 - val_accuracy: 0.9756 - val_precision: 0.1386 - val_recall: 0.0714 - val_auc: 0.7584\n",
            "Epoch 71/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.3529 - tp: 322.0000 - fp: 3822.0000 - tn: 17803.0000 - fn: 69.0000 - accuracy: 0.8233 - precision: 0.0777 - recall: 0.8235 - auc: 0.9201 - val_loss: 0.1237 - val_tp: 18.0000 - val_fp: 113.0000 - val_tn: 10699.0000 - val_fn: 178.0000 - val_accuracy: 0.9736 - val_precision: 0.1374 - val_recall: 0.0918 - val_auc: 0.7493\n",
            "Epoch 72/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.3529 - tp: 333.0000 - fp: 3988.0000 - tn: 17634.0000 - fn: 61.0000 - accuracy: 0.8161 - precision: 0.0771 - recall: 0.8452 - auc: 0.9213 - val_loss: 0.1557 - val_tp: 29.0000 - val_fp: 286.0000 - val_tn: 10526.0000 - val_fn: 167.0000 - val_accuracy: 0.9588 - val_precision: 0.0921 - val_recall: 0.1480 - val_auc: 0.7526\n",
            "Epoch 73/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.3664 - tp: 326.0000 - fp: 4099.0000 - tn: 17527.0000 - fn: 64.0000 - accuracy: 0.8109 - precision: 0.0737 - recall: 0.8359 - auc: 0.9120 - val_loss: 0.1060 - val_tp: 13.0000 - val_fp: 56.0000 - val_tn: 10756.0000 - val_fn: 183.0000 - val_accuracy: 0.9783 - val_precision: 0.1884 - val_recall: 0.0663 - val_auc: 0.7335\n",
            "Epoch 74/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.3509 - tp: 336.0000 - fp: 3905.0000 - tn: 17720.0000 - fn: 55.0000 - accuracy: 0.8201 - precision: 0.0792 - recall: 0.8593 - auc: 0.9221 - val_loss: 0.1090 - val_tp: 12.0000 - val_fp: 50.0000 - val_tn: 10762.0000 - val_fn: 184.0000 - val_accuracy: 0.9787 - val_precision: 0.1935 - val_recall: 0.0612 - val_auc: 0.7393\n",
            "Epoch 75/100\n",
            "86/86 [==============================] - 15s 172ms/step - loss: 0.3542 - tp: 329.0000 - fp: 4048.0000 - tn: 17577.0000 - fn: 62.0000 - accuracy: 0.8133 - precision: 0.0752 - recall: 0.8414 - auc: 0.9185 - val_loss: 0.1044 - val_tp: 10.0000 - val_fp: 47.0000 - val_tn: 10765.0000 - val_fn: 186.0000 - val_accuracy: 0.9788 - val_precision: 0.1754 - val_recall: 0.0510 - val_auc: 0.7560\n",
            "Epoch 76/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.3061 - tp: 347.0000 - fp: 3635.0000 - tn: 17990.0000 - fn: 44.0000 - accuracy: 0.8329 - precision: 0.0871 - recall: 0.8875 - auc: 0.9406 - val_loss: 0.1844 - val_tp: 35.0000 - val_fp: 320.0000 - val_tn: 10492.0000 - val_fn: 161.0000 - val_accuracy: 0.9563 - val_precision: 0.0986 - val_recall: 0.1786 - val_auc: 0.7304\n",
            "Epoch 77/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.2994 - tp: 348.0000 - fp: 3563.0000 - tn: 18066.0000 - fn: 39.0000 - accuracy: 0.8364 - precision: 0.0890 - recall: 0.8992 - auc: 0.9436 - val_loss: 0.1246 - val_tp: 21.0000 - val_fp: 140.0000 - val_tn: 10672.0000 - val_fn: 175.0000 - val_accuracy: 0.9714 - val_precision: 0.1304 - val_recall: 0.1071 - val_auc: 0.7440\n",
            "Epoch 78/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.2798 - tp: 349.0000 - fp: 3122.0000 - tn: 18502.0000 - fn: 43.0000 - accuracy: 0.8562 - precision: 0.1005 - recall: 0.8903 - auc: 0.9521 - val_loss: 0.1150 - val_tp: 19.0000 - val_fp: 111.0000 - val_tn: 10701.0000 - val_fn: 177.0000 - val_accuracy: 0.9738 - val_precision: 0.1462 - val_recall: 0.0969 - val_auc: 0.7495\n",
            "Epoch 79/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.2555 - tp: 363.0000 - fp: 2950.0000 - tn: 18674.0000 - fn: 29.0000 - accuracy: 0.8647 - precision: 0.1096 - recall: 0.9260 - auc: 0.9612 - val_loss: 0.1300 - val_tp: 24.0000 - val_fp: 191.0000 - val_tn: 10621.0000 - val_fn: 172.0000 - val_accuracy: 0.9670 - val_precision: 0.1116 - val_recall: 0.1224 - val_auc: 0.7403\n",
            "Epoch 80/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.2634 - tp: 353.0000 - fp: 3280.0000 - tn: 18346.0000 - fn: 37.0000 - accuracy: 0.8493 - precision: 0.0972 - recall: 0.9051 - auc: 0.9578 - val_loss: 0.1648 - val_tp: 35.0000 - val_fp: 342.0000 - val_tn: 10470.0000 - val_fn: 161.0000 - val_accuracy: 0.9543 - val_precision: 0.0928 - val_recall: 0.1786 - val_auc: 0.7328\n",
            "Epoch 81/100\n",
            "86/86 [==============================] - 15s 174ms/step - loss: 0.2517 - tp: 351.0000 - fp: 2725.0000 - tn: 18900.0000 - fn: 40.0000 - accuracy: 0.8744 - precision: 0.1141 - recall: 0.8977 - auc: 0.9615 - val_loss: 0.1550 - val_tp: 32.0000 - val_fp: 294.0000 - val_tn: 10518.0000 - val_fn: 164.0000 - val_accuracy: 0.9584 - val_precision: 0.0982 - val_recall: 0.1633 - val_auc: 0.7345\n",
            "Epoch 82/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.2417 - tp: 351.0000 - fp: 2711.0000 - tn: 18916.0000 - fn: 38.0000 - accuracy: 0.8751 - precision: 0.1146 - recall: 0.9023 - auc: 0.9650 - val_loss: 0.1640 - val_tp: 32.0000 - val_fp: 316.0000 - val_tn: 10496.0000 - val_fn: 164.0000 - val_accuracy: 0.9564 - val_precision: 0.0920 - val_recall: 0.1633 - val_auc: 0.7262\n",
            "Epoch 83/100\n",
            "86/86 [==============================] - 14s 169ms/step - loss: 0.2325 - tp: 359.0000 - fp: 2558.0000 - tn: 19067.0000 - fn: 32.0000 - accuracy: 0.8824 - precision: 0.1231 - recall: 0.9182 - auc: 0.9681 - val_loss: 0.1229 - val_tp: 22.0000 - val_fp: 134.0000 - val_tn: 10678.0000 - val_fn: 174.0000 - val_accuracy: 0.9720 - val_precision: 0.1410 - val_recall: 0.1122 - val_auc: 0.7428\n",
            "Epoch 84/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.2575 - tp: 350.0000 - fp: 2810.0000 - tn: 18815.0000 - fn: 41.0000 - accuracy: 0.8705 - precision: 0.1108 - recall: 0.8951 - auc: 0.9591 - val_loss: 0.0929 - val_tp: 5.0000 - val_fp: 39.0000 - val_tn: 10773.0000 - val_fn: 191.0000 - val_accuracy: 0.9791 - val_precision: 0.1136 - val_recall: 0.0255 - val_auc: 0.7459\n",
            "Epoch 85/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.2786 - tp: 341.0000 - fp: 2948.0000 - tn: 18676.0000 - fn: 51.0000 - accuracy: 0.8638 - precision: 0.1037 - recall: 0.8699 - auc: 0.9518 - val_loss: 0.0937 - val_tp: 5.0000 - val_fp: 34.0000 - val_tn: 10778.0000 - val_fn: 191.0000 - val_accuracy: 0.9796 - val_precision: 0.1282 - val_recall: 0.0255 - val_auc: 0.7381\n",
            "Epoch 86/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.2743 - tp: 337.0000 - fp: 2966.0000 - tn: 18658.0000 - fn: 55.0000 - accuracy: 0.8628 - precision: 0.1020 - recall: 0.8597 - auc: 0.9526 - val_loss: 0.2090 - val_tp: 48.0000 - val_fp: 591.0000 - val_tn: 10221.0000 - val_fn: 148.0000 - val_accuracy: 0.9329 - val_precision: 0.0751 - val_recall: 0.2449 - val_auc: 0.7253\n",
            "Epoch 87/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.2921 - tp: 344.0000 - fp: 3104.0000 - tn: 18523.0000 - fn: 45.0000 - accuracy: 0.8570 - precision: 0.0998 - recall: 0.8843 - auc: 0.9465 - val_loss: 0.2228 - val_tp: 42.0000 - val_fp: 532.0000 - val_tn: 10280.0000 - val_fn: 154.0000 - val_accuracy: 0.9377 - val_precision: 0.0732 - val_recall: 0.2143 - val_auc: 0.7230\n",
            "Epoch 88/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.3071 - tp: 337.0000 - fp: 3308.0000 - tn: 18316.0000 - fn: 55.0000 - accuracy: 0.8472 - precision: 0.0925 - recall: 0.8597 - auc: 0.9397 - val_loss: 0.2307 - val_tp: 41.0000 - val_fp: 680.0000 - val_tn: 10132.0000 - val_fn: 155.0000 - val_accuracy: 0.9241 - val_precision: 0.0569 - val_recall: 0.2092 - val_auc: 0.7045\n",
            "Epoch 89/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.3028 - tp: 339.0000 - fp: 3468.0000 - tn: 18158.0000 - fn: 51.0000 - accuracy: 0.8402 - precision: 0.0890 - recall: 0.8692 - auc: 0.9414 - val_loss: 0.1286 - val_tp: 33.0000 - val_fp: 250.0000 - val_tn: 10562.0000 - val_fn: 163.0000 - val_accuracy: 0.9625 - val_precision: 0.1166 - val_recall: 0.1684 - val_auc: 0.7588\n",
            "Epoch 90/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.2680 - tp: 347.0000 - fp: 3053.0000 - tn: 18574.0000 - fn: 42.0000 - accuracy: 0.8594 - precision: 0.1021 - recall: 0.8920 - auc: 0.9544 - val_loss: 0.1200 - val_tp: 18.0000 - val_fp: 146.0000 - val_tn: 10666.0000 - val_fn: 178.0000 - val_accuracy: 0.9706 - val_precision: 0.1098 - val_recall: 0.0918 - val_auc: 0.7501\n",
            "Epoch 91/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.2469 - tp: 350.0000 - fp: 2708.0000 - tn: 18921.0000 - fn: 37.0000 - accuracy: 0.8753 - precision: 0.1145 - recall: 0.9044 - auc: 0.9618 - val_loss: 0.1348 - val_tp: 27.0000 - val_fp: 223.0000 - val_tn: 10589.0000 - val_fn: 169.0000 - val_accuracy: 0.9644 - val_precision: 0.1080 - val_recall: 0.1378 - val_auc: 0.7423\n",
            "Epoch 92/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.2521 - tp: 352.0000 - fp: 2767.0000 - tn: 18857.0000 - fn: 40.0000 - accuracy: 0.8725 - precision: 0.1129 - recall: 0.8980 - auc: 0.9600 - val_loss: 0.0912 - val_tp: 1.0000 - val_fp: 16.0000 - val_tn: 10796.0000 - val_fn: 195.0000 - val_accuracy: 0.9808 - val_precision: 0.0588 - val_recall: 0.0051 - val_auc: 0.7412\n",
            "Epoch 93/100\n",
            "86/86 [==============================] - 16s 182ms/step - loss: 0.2290 - tp: 363.0000 - fp: 2835.0000 - tn: 18791.0000 - fn: 27.0000 - accuracy: 0.8700 - precision: 0.1135 - recall: 0.9308 - auc: 0.9670 - val_loss: 0.1328 - val_tp: 25.0000 - val_fp: 235.0000 - val_tn: 10577.0000 - val_fn: 171.0000 - val_accuracy: 0.9631 - val_precision: 0.0962 - val_recall: 0.1276 - val_auc: 0.7483\n",
            "Epoch 94/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.2190 - tp: 356.0000 - fp: 2402.0000 - tn: 19226.0000 - fn: 32.0000 - accuracy: 0.8894 - precision: 0.1291 - recall: 0.9175 - auc: 0.9710 - val_loss: 0.1104 - val_tp: 16.0000 - val_fp: 119.0000 - val_tn: 10693.0000 - val_fn: 180.0000 - val_accuracy: 0.9728 - val_precision: 0.1185 - val_recall: 0.0816 - val_auc: 0.7347\n",
            "Epoch 95/100\n",
            "86/86 [==============================] - 16s 190ms/step - loss: 0.2007 - tp: 363.0000 - fp: 2177.0000 - tn: 19449.0000 - fn: 27.0000 - accuracy: 0.8999 - precision: 0.1429 - recall: 0.9308 - auc: 0.9760 - val_loss: 0.1530 - val_tp: 35.0000 - val_fp: 340.0000 - val_tn: 10472.0000 - val_fn: 161.0000 - val_accuracy: 0.9545 - val_precision: 0.0933 - val_recall: 0.1786 - val_auc: 0.7413\n",
            "Epoch 96/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.2030 - tp: 356.0000 - fp: 2241.0000 - tn: 19386.0000 - fn: 33.0000 - accuracy: 0.8967 - precision: 0.1371 - recall: 0.9152 - auc: 0.9750 - val_loss: 0.1336 - val_tp: 28.0000 - val_fp: 236.0000 - val_tn: 10576.0000 - val_fn: 168.0000 - val_accuracy: 0.9633 - val_precision: 0.1061 - val_recall: 0.1429 - val_auc: 0.7377\n",
            "Epoch 97/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.2059 - tp: 358.0000 - fp: 2279.0000 - tn: 19350.0000 - fn: 29.0000 - accuracy: 0.8952 - precision: 0.1358 - recall: 0.9251 - auc: 0.9744 - val_loss: 0.1128 - val_tp: 18.0000 - val_fp: 126.0000 - val_tn: 10686.0000 - val_fn: 178.0000 - val_accuracy: 0.9724 - val_precision: 0.1250 - val_recall: 0.0918 - val_auc: 0.7327\n",
            "Epoch 98/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.2043 - tp: 355.0000 - fp: 2464.0000 - tn: 19163.0000 - fn: 34.0000 - accuracy: 0.8865 - precision: 0.1259 - recall: 0.9126 - auc: 0.9744 - val_loss: 0.1207 - val_tp: 20.0000 - val_fp: 139.0000 - val_tn: 10673.0000 - val_fn: 176.0000 - val_accuracy: 0.9714 - val_precision: 0.1258 - val_recall: 0.1020 - val_auc: 0.7323\n",
            "Epoch 99/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.1957 - tp: 360.0000 - fp: 2127.0000 - tn: 19498.0000 - fn: 31.0000 - accuracy: 0.9020 - precision: 0.1448 - recall: 0.9207 - auc: 0.9772 - val_loss: 0.0975 - val_tp: 12.0000 - val_fp: 69.0000 - val_tn: 10743.0000 - val_fn: 184.0000 - val_accuracy: 0.9770 - val_precision: 0.1481 - val_recall: 0.0612 - val_auc: 0.7388\n",
            "Epoch 100/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.2082 - tp: 351.0000 - fp: 2232.0000 - tn: 19398.0000 - fn: 35.0000 - accuracy: 0.8970 - precision: 0.1359 - recall: 0.9093 - auc: 0.9729 - val_loss: 0.1108 - val_tp: 21.0000 - val_fp: 149.0000 - val_tn: 10663.0000 - val_fn: 175.0000 - val_accuracy: 0.9706 - val_precision: 0.1235 - val_recall: 0.1071 - val_auc: 0.7705\n",
            "Epoch 1/100\n",
            " 2/86 [..............................] - ETA: 5s - loss: 2.1989 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 503.0000 - fn: 9.0000 - accuracy: 0.9824 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5279WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0105s vs `on_train_batch_end` time: 0.1090s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0105s vs `on_train_batch_end` time: 0.1090s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "86/86 [==============================] - ETA: 0s - loss: 2.0174 - tp: 1.0000 - fp: 9.0000 - tn: 21616.0000 - fn: 390.0000 - accuracy: 0.9819 - precision: 0.1000 - recall: 0.0026 - auc: 0.5385WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0045s vs `on_test_batch_end` time: 0.0583s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0045s vs `on_test_batch_end` time: 0.0583s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r86/86 [==============================] - 25s 294ms/step - loss: 2.0174 - tp: 1.0000 - fp: 9.0000 - tn: 21616.0000 - fn: 390.0000 - accuracy: 0.9819 - precision: 0.1000 - recall: 0.0026 - auc: 0.5385 - val_loss: 0.0856 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 10816.0000 - val_fn: 192.0000 - val_accuracy: 0.9826 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6621\n",
            "Epoch 2/100\n",
            "86/86 [==============================] - 15s 177ms/step - loss: 1.6001 - tp: 22.0000 - fp: 507.0000 - tn: 21114.0000 - fn: 373.0000 - accuracy: 0.9600 - precision: 0.0416 - recall: 0.0557 - auc: 0.6455 - val_loss: 0.0838 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 10816.0000 - val_fn: 192.0000 - val_accuracy: 0.9826 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6734\n",
            "Epoch 3/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 1.0812 - tp: 134.0000 - fp: 3002.0000 - tn: 18622.0000 - fn: 258.0000 - accuracy: 0.8519 - precision: 0.0427 - recall: 0.3418 - auc: 0.6805 - val_loss: 0.1048 - val_tp: 0.0000e+00 - val_fp: 16.0000 - val_tn: 10800.0000 - val_fn: 192.0000 - val_accuracy: 0.9811 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7121\n",
            "Epoch 4/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.7903 - tp: 209.0000 - fp: 4971.0000 - tn: 16655.0000 - fn: 181.0000 - accuracy: 0.7660 - precision: 0.0403 - recall: 0.5359 - auc: 0.7265 - val_loss: 0.3738 - val_tp: 81.0000 - val_fp: 1181.0000 - val_tn: 9635.0000 - val_fn: 111.0000 - val_accuracy: 0.8826 - val_precision: 0.0642 - val_recall: 0.4219 - val_auc: 0.7428\n",
            "Epoch 5/100\n",
            "86/86 [==============================] - 14s 165ms/step - loss: 0.7475 - tp: 212.0000 - fp: 5073.0000 - tn: 16551.0000 - fn: 180.0000 - accuracy: 0.7614 - precision: 0.0401 - recall: 0.5408 - auc: 0.7248 - val_loss: 0.2364 - val_tp: 61.0000 - val_fp: 627.0000 - val_tn: 10189.0000 - val_fn: 131.0000 - val_accuracy: 0.9311 - val_precision: 0.0887 - val_recall: 0.3177 - val_auc: 0.7666\n",
            "Epoch 6/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.6280 - tp: 259.0000 - fp: 6459.0000 - tn: 15162.0000 - fn: 136.0000 - accuracy: 0.7004 - precision: 0.0386 - recall: 0.6557 - auc: 0.7448 - val_loss: 0.2729 - val_tp: 67.0000 - val_fp: 658.0000 - val_tn: 10158.0000 - val_fn: 125.0000 - val_accuracy: 0.9289 - val_precision: 0.0924 - val_recall: 0.3490 - val_auc: 0.7801\n",
            "Epoch 7/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.6507 - tp: 240.0000 - fp: 6399.0000 - tn: 15226.0000 - fn: 151.0000 - accuracy: 0.7025 - precision: 0.0362 - recall: 0.6138 - auc: 0.7330 - val_loss: 0.6403 - val_tp: 121.0000 - val_fp: 3510.0000 - val_tn: 7306.0000 - val_fn: 71.0000 - val_accuracy: 0.6747 - val_precision: 0.0333 - val_recall: 0.6302 - val_auc: 0.7112\n",
            "Epoch 8/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.7321 - tp: 234.0000 - fp: 5767.0000 - tn: 15857.0000 - fn: 158.0000 - accuracy: 0.7309 - precision: 0.0390 - recall: 0.5969 - auc: 0.7245 - val_loss: 1.5856 - val_tp: 186.0000 - val_fp: 7361.0000 - val_tn: 3455.0000 - val_fn: 6.0000 - val_accuracy: 0.3308 - val_precision: 0.0246 - val_recall: 0.9688 - val_auc: 0.7691\n",
            "Epoch 9/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.6574 - tp: 247.0000 - fp: 6116.0000 - tn: 15509.0000 - fn: 144.0000 - accuracy: 0.7157 - precision: 0.0388 - recall: 0.6317 - auc: 0.7452 - val_loss: 0.6357 - val_tp: 124.0000 - val_fp: 3440.0000 - val_tn: 7376.0000 - val_fn: 68.0000 - val_accuracy: 0.6813 - val_precision: 0.0348 - val_recall: 0.6458 - val_auc: 0.7218\n",
            "Epoch 10/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.6918 - tp: 246.0000 - fp: 5935.0000 - tn: 15689.0000 - fn: 146.0000 - accuracy: 0.7238 - precision: 0.0398 - recall: 0.6276 - auc: 0.7319 - val_loss: 0.3709 - val_tp: 74.0000 - val_fp: 988.0000 - val_tn: 9828.0000 - val_fn: 118.0000 - val_accuracy: 0.8995 - val_precision: 0.0697 - val_recall: 0.3854 - val_auc: 0.7642\n",
            "Epoch 11/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.6189 - tp: 255.0000 - fp: 6181.0000 - tn: 15442.0000 - fn: 138.0000 - accuracy: 0.7130 - precision: 0.0396 - recall: 0.6489 - auc: 0.7489 - val_loss: 0.4619 - val_tp: 110.0000 - val_fp: 1760.0000 - val_tn: 9056.0000 - val_fn: 82.0000 - val_accuracy: 0.8327 - val_precision: 0.0588 - val_recall: 0.5729 - val_auc: 0.7604\n",
            "Epoch 12/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.6038 - tp: 263.0000 - fp: 6611.0000 - tn: 15011.0000 - fn: 131.0000 - accuracy: 0.6938 - precision: 0.0383 - recall: 0.6675 - auc: 0.7504 - val_loss: 0.4340 - val_tp: 112.0000 - val_fp: 1912.0000 - val_tn: 8904.0000 - val_fn: 80.0000 - val_accuracy: 0.8190 - val_precision: 0.0553 - val_recall: 0.5833 - val_auc: 0.7847\n",
            "Epoch 13/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5935 - tp: 266.0000 - fp: 6793.0000 - tn: 14828.0000 - fn: 129.0000 - accuracy: 0.6856 - precision: 0.0377 - recall: 0.6734 - auc: 0.7555 - val_loss: 0.2551 - val_tp: 57.0000 - val_fp: 504.0000 - val_tn: 10312.0000 - val_fn: 135.0000 - val_accuracy: 0.9420 - val_precision: 0.1016 - val_recall: 0.2969 - val_auc: 0.7910\n",
            "Epoch 14/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.6106 - tp: 285.0000 - fp: 6679.0000 - tn: 14945.0000 - fn: 107.0000 - accuracy: 0.6918 - precision: 0.0409 - recall: 0.7270 - auc: 0.7669 - val_loss: 0.3509 - val_tp: 83.0000 - val_fp: 1107.0000 - val_tn: 9709.0000 - val_fn: 109.0000 - val_accuracy: 0.8895 - val_precision: 0.0697 - val_recall: 0.4323 - val_auc: 0.7832\n",
            "Epoch 15/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.6078 - tp: 267.0000 - fp: 6400.0000 - tn: 15224.0000 - fn: 125.0000 - accuracy: 0.7036 - precision: 0.0400 - recall: 0.6811 - auc: 0.7689 - val_loss: 0.2724 - val_tp: 66.0000 - val_fp: 629.0000 - val_tn: 10187.0000 - val_fn: 126.0000 - val_accuracy: 0.9314 - val_precision: 0.0950 - val_recall: 0.3438 - val_auc: 0.8018\n",
            "Epoch 16/100\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.5737 - tp: 278.0000 - fp: 6568.0000 - tn: 15054.0000 - fn: 116.0000 - accuracy: 0.6964 - precision: 0.0406 - recall: 0.7056 - auc: 0.7765 - val_loss: 0.2009 - val_tp: 40.0000 - val_fp: 306.0000 - val_tn: 10510.0000 - val_fn: 152.0000 - val_accuracy: 0.9584 - val_precision: 0.1156 - val_recall: 0.2083 - val_auc: 0.7996\n",
            "Epoch 17/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5865 - tp: 274.0000 - fp: 6933.0000 - tn: 14692.0000 - fn: 117.0000 - accuracy: 0.6798 - precision: 0.0380 - recall: 0.7008 - auc: 0.7630 - val_loss: 0.2377 - val_tp: 61.0000 - val_fp: 556.0000 - val_tn: 10260.0000 - val_fn: 131.0000 - val_accuracy: 0.9376 - val_precision: 0.0989 - val_recall: 0.3177 - val_auc: 0.7957\n",
            "Epoch 18/100\n",
            "86/86 [==============================] - 14s 167ms/step - loss: 0.5558 - tp: 286.0000 - fp: 6697.0000 - tn: 14924.0000 - fn: 109.0000 - accuracy: 0.6909 - precision: 0.0410 - recall: 0.7241 - auc: 0.7864 - val_loss: 0.2738 - val_tp: 66.0000 - val_fp: 688.0000 - val_tn: 10128.0000 - val_fn: 126.0000 - val_accuracy: 0.9261 - val_precision: 0.0875 - val_recall: 0.3438 - val_auc: 0.7971\n",
            "Epoch 19/100\n",
            "86/86 [==============================] - 14s 168ms/step - loss: 0.5433 - tp: 280.0000 - fp: 6408.0000 - tn: 15218.0000 - fn: 110.0000 - accuracy: 0.7039 - precision: 0.0419 - recall: 0.7179 - auc: 0.7950 - val_loss: 0.2238 - val_tp: 47.0000 - val_fp: 355.0000 - val_tn: 10461.0000 - val_fn: 145.0000 - val_accuracy: 0.9546 - val_precision: 0.1169 - val_recall: 0.2448 - val_auc: 0.7953\n",
            "Epoch 20/100\n",
            "86/86 [==============================] - 19s 220ms/step - loss: 0.6213 - tp: 271.0000 - fp: 6646.0000 - tn: 14977.0000 - fn: 122.0000 - accuracy: 0.6926 - precision: 0.0392 - recall: 0.6896 - auc: 0.7629 - val_loss: 0.1579 - val_tp: 25.0000 - val_fp: 267.0000 - val_tn: 10549.0000 - val_fn: 167.0000 - val_accuracy: 0.9606 - val_precision: 0.0856 - val_recall: 0.1302 - val_auc: 0.7737\n",
            "Epoch 21/100\n",
            "86/86 [==============================] - 15s 170ms/step - loss: 0.5712 - tp: 270.0000 - fp: 6709.0000 - tn: 14911.0000 - fn: 126.0000 - accuracy: 0.6895 - precision: 0.0387 - recall: 0.6818 - auc: 0.7720 - val_loss: 0.2115 - val_tp: 59.0000 - val_fp: 703.0000 - val_tn: 10113.0000 - val_fn: 133.0000 - val_accuracy: 0.9241 - val_precision: 0.0774 - val_recall: 0.3073 - val_auc: 0.7763\n",
            "Epoch 22/100\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.5897 - tp: 265.0000 - fp: 6328.0000 - tn: 15294.0000 - fn: 129.0000 - accuracy: 0.7067 - precision: 0.0402 - recall: 0.6726 - auc: 0.7747 - val_loss: 0.1800 - val_tp: 32.0000 - val_fp: 267.0000 - val_tn: 10549.0000 - val_fn: 160.0000 - val_accuracy: 0.9612 - val_precision: 0.1070 - val_recall: 0.1667 - val_auc: 0.7986\n",
            "Epoch 23/100\n",
            "86/86 [==============================] - 15s 169ms/step - loss: 0.5833 - tp: 266.0000 - fp: 6753.0000 - tn: 14873.0000 - fn: 124.0000 - accuracy: 0.6876 - precision: 0.0379 - recall: 0.6821 - auc: 0.7646 - val_loss: 0.2002 - val_tp: 42.0000 - val_fp: 508.0000 - val_tn: 10308.0000 - val_fn: 150.0000 - val_accuracy: 0.9402 - val_precision: 0.0764 - val_recall: 0.2188 - val_auc: 0.7761\n",
            "Epoch 24/100\n",
            "86/86 [==============================] - 14s 169ms/step - loss: 0.5789 - tp: 274.0000 - fp: 6610.0000 - tn: 15015.0000 - fn: 117.0000 - accuracy: 0.6944 - precision: 0.0398 - recall: 0.7008 - auc: 0.7758 - val_loss: 0.2959 - val_tp: 86.0000 - val_fp: 1194.0000 - val_tn: 9622.0000 - val_fn: 106.0000 - val_accuracy: 0.8819 - val_precision: 0.0672 - val_recall: 0.4479 - val_auc: 0.7704\n",
            "Epoch 25/100\n",
            "86/86 [==============================] - ETA: 0s - loss: 0.5825 - tp: 275.0000 - fp: 6542.0000 - tn: 15076.0000 - fn: 123.0000 - accuracy: 0.6973 - precision: 0.0403 - recall: 0.6910 - auc: 0.7725"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQIi4AVbDTtw"
      },
      "source": [
        "print(\"jacek\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9WTqAA7Hd97",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "log_dir = get_log_dir(CONFIG)\n",
        "zip_name = os.path.basename(log_dir) + '.zip'\n",
        "!zip -r $zip_name $log_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ij3oPfp3ZkG-"
      },
      "source": [
        "i = 2\n",
        "plt.plot(logs['auc'][i])\n",
        "plt.plot(logs['val_auc'][i])\n",
        "suma = 0\n",
        "for k in [0,1,2]:\n",
        " suma += np.max(logs['val_auc'][k])\n",
        "suma/3\n",
        "np.max(logs['val_auc'][i])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}