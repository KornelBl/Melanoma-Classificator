{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kopia notatnika Untitled",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "takW5YtZd2w4",
        "pycharm": {
          "is_executing": false
        }
      },
      "source": [
        "import os, re, time, json, math\n",
        "import datetime\n",
        "import PIL.Image, PIL.ImageFont, PIL.ImageDraw\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import google\n",
        "from matplotlib import pyplot as plt\n",
        "print(\"Tensorflow version \" + tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3wLMTBEUOw_",
        "pycharm": {
          "is_executing": false
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "from tf_records_generator import get_dataset, count_data_items\n",
        "from efficientNet_B0 import EffNet0, freeze_blocks\n",
        "from log_files import save_config, save_fold_iter_history, get_log_dir, save_logs_pickle, generate_columns\n",
        "from kfold import get_kfold_split\n",
        "from clr_schedule import CyclicLR"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-tkqnadn5x2",
        "pycharm": {
          "is_executing": false
        }
      },
      "source": [
        "CONFIG = dict(\n",
        "    log_prefix = \"CLR_\",\n",
        "    effnet_version = 0,\n",
        "    input_shape=(256, 256, 3),\n",
        "    image_resolution=256,\n",
        "    trainable_base=False,\n",
        "    time=datetime.datetime.now().strftime(\"_%d_%m_%Y_%H_%M\"),\n",
        "    use_patient_data=True,\n",
        "    inner_blocks_frozen=4,\n",
        "\n",
        "    lr_min=0.0001,\n",
        "    lr_max=0.1,\n",
        "    lr_decay=None,\n",
        "    clr_step_coefficient = 8,\n",
        "    \n",
        "    replicas=8,\n",
        "    steps_per_epoch=None,\n",
        "    validation_steps=None,\n",
        "    batch_size=40,\n",
        "    epochs=100,\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    \n",
        "    output_bias=np.log([584/32542]),\n",
        "    weight_for_0 = (1 / 32542)*(32542+584)/2.0,\n",
        "    weight_for_1 = (1 / 584)*(32542+584)/2.0\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ps8i099nqD0",
        "pycharm": {
          "is_executing": false
        }
      },
      "source": [
        "IS_COLAB_BACKEND = 'COLAB_GPU' in os.environ  # this is always set on Colab, the value is 0 or 1 depending on GPU presence\n",
        "if IS_COLAB_BACKEND:\n",
        "  from google.colab import auth\n",
        "  # Authenticates the Colab machine and also the TPU using your\n",
        "  # credentials so that they can access your private GCS buckets.\n",
        "  auth.authenticate_user()\n",
        "  data_dir = 'gs://dataset_files/'\n",
        "else:\n",
        "  data_dir = 'dataset/'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS5omUmCnxAs",
        "pycharm": {
          "is_executing": false
        }
      },
      "source": [
        "# Detect hardware\n",
        "try:\n",
        "  tpu_resolver = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
        "except ValueError:\n",
        "  tpu_resolver = None\n",
        "  gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
        "\n",
        "# Select appropriate distribution strategy\n",
        "if tpu_resolver:\n",
        "  tf.config.experimental_connect_to_cluster(tpu_resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu_resolver)\n",
        "  strategy = tf.distribute.TPUStrategy(tpu_resolver)\n",
        "  print('Running on TPU ', tpu_resolver.cluster_spec().as_dict()['worker'])\n",
        "elif len(gpus) > 1:\n",
        "  strategy = tf.distribute.MirroredStrategy([gpu.name for gpu in gpus])\n",
        "  print('Running on multiple GPUs ', [gpu.name for gpu in gpus])\n",
        "elif len(gpus) == 1:\n",
        "  strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "  print('Running on single GPU ', gpus[0].name)\n",
        "else:\n",
        "  strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "  print('Running on CPU')\n",
        "  \n",
        "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)\n",
        "CONFIG[\"replicas\"] = strategy.num_replicas_in_sync\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZm9JTxir68V",
        "pycharm": {
          "is_executing": false
        }
      },
      "source": [
        "path = data_dir + str(CONFIG[\"image_resolution\"])\n",
        "files_train = np.sort(np.array(tf.io.gfile.glob(path + '/train*.tfrec')))\n",
        "files_test = np.sort(np.array(tf.io.gfile.glob(path + '/test*.tfrec')))\n",
        "\n",
        "\n",
        "test_ds = get_dataset(files_test, CONFIG)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC-WNOmKUIuB",
        "pycharm": {
          "is_executing": false
        }
      },
      "source": [
        "def make_model(config:dict, strategy)    :\n",
        "    with strategy.scope():\n",
        "      model = EffNet0(config=config, trainable_base=config['trainable_base'])\n",
        "\n",
        "      model.compile(optimizer=keras.optimizers.Adam(), loss=config[\"loss\"], \n",
        "                    metrics=[\n",
        "                                  keras.metrics.TruePositives(name='tp'),\n",
        "                                  keras.metrics.FalsePositives(name='fp'),\n",
        "                                  keras.metrics.TrueNegatives(name='tn'),\n",
        "                                  keras.metrics.FalseNegatives(name='fn'), \n",
        "                                  keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "                                  keras.metrics.Precision(name='precision'),\n",
        "                                  keras.metrics.Recall(name='recall'),\n",
        "                                  keras.metrics.AUC(name='auc'),\n",
        "                            ]\n",
        "    )\n",
        "    return model\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": false
        },
        "id": "Y5E4-HaXAAmN"
      },
      "source": [
        "kfold_split = get_kfold_split(files_train,3)\n",
        "save_config(CONFIG)\n",
        "logs = pd.DataFrame()\n",
        "for iter, files in kfold_split.items():\n",
        "    train_ds = get_dataset(files['train'],CONFIG, patient_info=True,repeat=True) \n",
        "    val_ds = get_dataset(files['validation'], CONFIG, patient_info=True,repeat=True)\n",
        "    if CONFIG['steps_per_epoch'] is None:\n",
        "        CONFIG['steps_per_epoch'] = math.ceil(count_data_items(files[\"train\"])/(CONFIG[\"batch_size\"]*CONFIG[\"replicas\"]))\n",
        "    if CONFIG['validation_steps'] is None:\n",
        "        CONFIG['validation_steps'] = math.ceil(count_data_items(files[\"validation\"])/(CONFIG[\"batch_size\"]*CONFIG[\"replicas\"]))\n",
        "\n",
        "    clr = CyclicLR(base_lr=CONFIG[\"lr_min\"], max_lr=CONFIG[\"lr_max\"],\n",
        "                                step_size=CONFIG['steps_per_epoch']*CONFIG['clr_step_coefficient'], mode='triangular')\n",
        "    \n",
        "    model = make_model(CONFIG, strategy=strategy)\n",
        "    history = model.fit(train_ds,class_weight={0:CONFIG[\"weight_for_0\"],1:CONFIG[\"weight_for_1\"]},\n",
        "                        validation_data=val_ds,validation_batch_size=CONFIG[\"batch_size\"]*CONFIG[\"replicas\"],\n",
        "                        batch_size=CONFIG[\"batch_size\"]*CONFIG[\"replicas\"], epochs=CONFIG[\"epochs\"],\n",
        "                        steps_per_epoch=CONFIG['steps_per_epoch'],validation_steps=CONFIG['validation_steps'],\n",
        "                        callbacks=[clr])\n",
        "    \n",
        "    if logs.empty:\n",
        "        logs = generate_columns(logs,history.history)\n",
        "    logs = logs.append(history.history, ignore_index=True)\n",
        "    \n",
        "save_logs_pickle(logs,CONFIG)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9WTqAA7Hd97",
        "pycharm": {
          "name": "#%%\n"
        },
        "outputId": "57f9e6a7-d981-4ea2-e60d-9872a738d417",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "log_dir = get_log_dir(CONFIG)\n",
        "zip_name = os.path.basename(log_dir)\n",
        "!zip -r $zip_name $log_dir"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: logs/CLR_4_EffN0_256_07_11_2020_23_39/ (stored 0%)\n",
            "  adding: logs/CLR_4_EffN0_256_07_11_2020_23_39/config.json (deflated 37%)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}